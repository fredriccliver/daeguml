{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "\n",
    "train = pd.read_csv(\"../data/titanic/train.csv\")\n",
    "test = pd.read_csv(\"../data/titanic/test.csv\")\n",
    "train = train.append(test) ## test 데이터도 학습에 이용.\n",
    "\n",
    "# inplace=True 로 해야 모든 컬럼에 대해 fillna 가 이뤄짐.\n",
    "# train.fillna(0, inplace=True) \n",
    "# test.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 8)\n",
      "(418, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  Pclass  SibSp  0_x  1  2  0_y\n",
       "0  22.0   7.2500      0       3      1    0  0  1    1\n",
       "1  38.0  71.2833      0       1      1    1  0  0    0\n",
       "2  26.0   7.9250      0       3      0    0  0  1    0\n",
       "3  35.0  53.1000      0       1      1    0  0  1    0\n",
       "4  35.0   8.0500      0       3      0    0  0  1    1"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# cols = PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "\n",
    "# 데이터 전처리 : 학습에 필요없는 column 제거.\n",
    "train.pop('Name'), test.pop('Name')\n",
    "train.pop('Ticket'), test.pop('Ticket')\n",
    "train.pop('Cabin'), test.pop('Cabin')\n",
    "train.pop('PassengerId'), test.pop('PassengerId') # 제거하지 않으면 passengerId 가 높을수록 predicton value 가 높은 현상\n",
    "\n",
    "train.dropna(inplace=True)\n",
    "# test.dropna(inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# 데이터 전처리 : One Hot Encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "enc = encoder.fit(train[['Embarked']].astype(str))\n",
    "train = pd.merge(train, pd.DataFrame(enc.transform(train[['Embarked']].astype(str))) , right_index=True, left_index=True)\n",
    "test = pd.merge(test, pd.DataFrame(enc.transform(test[['Embarked']].astype(str))) , right_index=True, left_index=True)\n",
    "enc = encoder.fit(train[['Sex']].astype(str))\n",
    "train = pd.merge(train, pd.DataFrame(enc.transform(train[['Sex']].astype(str))) , right_index=True, left_index=True)\n",
    "test = pd.merge(test, pd.DataFrame(enc.transform(test[['Sex']].astype(str))) , right_index=True, left_index=True)\n",
    "train.pop('Embarked'), test.pop('Embarked')\n",
    "train.pop('Sex'), test.pop('Sex')\n",
    "\n",
    "# label\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "# feature\n",
    "train.pop('Survived')\n",
    "x_train = train\n",
    "x_test = test\n",
    "\n",
    "x_train.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import DBSCAN\n",
    "# outlier_detection = DBSCAN(\n",
    "#     eps = 0.5,\n",
    "#     metric=\"euclidean\",\n",
    "#     n_jobs = -1)\n",
    "# clusters = outlier_detection.fit_predict(train[['Fare']])\n",
    "# clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live :  182\n",
      "death :  264\n",
      "생존률 :  0.4080717488789238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0       0.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       0.0"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live = len(y_train[y_train['Survived']==1])\n",
    "death = len(y_train[y_train['Survived']==0])\n",
    "print(\"live : \" , live)\n",
    "print(\"death : \" , death)\n",
    "print(\n",
    "    \"생존률 : \" , live / (live + death)\n",
    ")\n",
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  0_x  1  2  0_y\n",
       "0       3  34.5      0      0   7.8292    0  1  0    1\n",
       "1       3  47.0      1      0   7.0000    0  0  1    0\n",
       "2       2  62.0      0      0   9.6875    0  1  0    1\n",
       "3       3  27.0      0      0   8.6625    0  0  1    1\n",
       "4       3  22.0      1      1  12.2875    0  0  1    0"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x1a4b071940>>\n",
      "Train on 356 samples, validate on 90 samples\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 8s 22ms/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 0s 278us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 0s 267us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 0s 262us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 0s 312us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 0s 243us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 0s 275us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 0s 273us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 0s 273us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 0s 257us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 0s 247us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 0s 260us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 0s 248us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 0s 256us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 0s 249us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 0s 275us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 0s 249us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 0s 258us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 0s 256us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 0s 280us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 0s 278us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 0s 277us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 0s 264us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 0s 279us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 0s 264us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 0s 259us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 0s 218us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 0s 210us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 0s 225us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 0s 207us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 0s 274us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 0s 288us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 0s 301us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 0s 290us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 0s 247us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 0s 254us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 0s 265us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 0s 289us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 0s 252us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 0s 263us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 0s 247us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 0s 253us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 0s 253us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 0s 250us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 0s 259us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 0s 247us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 0s 210us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 0s 220us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 0s 274us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 0s 261us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 0s 270us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 0s 249us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 0s 259us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 0s 260us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 0s 253us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 0s 251us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 0s 278us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 0s 262us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 0s 256us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 0s 254us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 0s 250us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 0s 269us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(9, kernel_initializer = 'uniform',activation='relu', input_dim=len(x_train.columns)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(9, kernel_initializer = 'uniform',activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer = 'uniform',activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer = 'uniform',activation='sigmoid'))\n",
    "\n",
    "# opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# opt = optimizers.Adam(lr=0.001, beta_1=0.5, beta_2=0.99, epsilon=None, decay=0.0, amsgrad=False)\n",
    "opt = optimizers.Adam(lr=0.0000005)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "print(model.summary)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=100, batch_size=30,validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='lower left')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49985027],\n",
       "       [ 0.49984497],\n",
       "       [ 0.49983495],\n",
       "       [ 0.49985328],\n",
       "       [ 0.49985477],\n",
       "       [ 0.49986371],\n",
       "       [ 0.49985263],\n",
       "       [ 0.49984974],\n",
       "       [ 0.4998602 ],\n",
       "       [ 0.49985406],\n",
       "       [        nan],\n",
       "       [ 0.49983305],\n",
       "       [ 0.49983966],\n",
       "       [ 0.49981713],\n",
       "       [ 0.49982488],\n",
       "       [ 0.49985033],\n",
       "       [ 0.49984443],\n",
       "       [ 0.49985775],\n",
       "       [ 0.4998537 ],\n",
       "       [ 0.49984509],\n",
       "       [ 0.49981737],\n",
       "       [ 0.49986503],\n",
       "       [        nan],\n",
       "       [ 0.4998458 ],\n",
       "       [ 0.49977165],\n",
       "       [ 0.49983162],\n",
       "       [ 0.49984443],\n",
       "       [ 0.49985674],\n",
       "       [ 0.49983639],\n",
       "       [        nan],\n",
       "       [ 0.4998284 ],\n",
       "       [ 0.49985054],\n",
       "       [ 0.49984211],\n",
       "       [        nan],\n",
       "       [ 0.49983901],\n",
       "       [ 0.49985984],\n",
       "       [        nan],\n",
       "       [ 0.49985817],\n",
       "       [ 0.49985448],\n",
       "       [        nan],\n",
       "       [ 0.4998396 ],\n",
       "       [        nan],\n",
       "       [ 0.49984747],\n",
       "       [ 0.49984956],\n",
       "       [ 0.4998287 ],\n",
       "       [ 0.49985531],\n",
       "       [ 0.49983168],\n",
       "       [        nan],\n",
       "       [ 0.49980944],\n",
       "       [ 0.49984139],\n",
       "       [ 0.49984473],\n",
       "       [ 0.49985054],\n",
       "       [ 0.49985525],\n",
       "       [ 0.49979159],\n",
       "       [        nan],\n",
       "       [ 0.4998596 ],\n",
       "       [ 0.49985021],\n",
       "       [ 0.49985555],\n",
       "       [        nan],\n",
       "       [ 0.49978313],\n",
       "       [ 0.49986175],\n",
       "       [ 0.49984795],\n",
       "       [ 0.49986103],\n",
       "       [ 0.49985698],\n",
       "       [ 0.49980667],\n",
       "       [        nan],\n",
       "       [ 0.49985972],\n",
       "       [ 0.49982911],\n",
       "       [ 0.49984521],\n",
       "       [ 0.49976248],\n",
       "       [ 0.49985555],\n",
       "       [ 0.49985853],\n",
       "       [ 0.49985293],\n",
       "       [ 0.49984771],\n",
       "       [ 0.49979666],\n",
       "       [ 0.4997991 ],\n",
       "       [        nan],\n",
       "       [ 0.49982429],\n",
       "       [ 0.4998498 ],\n",
       "       [ 0.49985555],\n",
       "       [ 0.49986771],\n",
       "       [ 0.49976861],\n",
       "       [ 0.49983048],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985364],\n",
       "       [ 0.49986091],\n",
       "       [        nan],\n",
       "       [ 0.49987176],\n",
       "       [ 0.49985507],\n",
       "       [        nan],\n",
       "       [ 0.49984318],\n",
       "       [        nan],\n",
       "       [ 0.49985138],\n",
       "       [ 0.49985543],\n",
       "       [ 0.49979529],\n",
       "       [ 0.49985304],\n",
       "       [ 0.4998593 ],\n",
       "       [ 0.4998509 ],\n",
       "       [ 0.49982834],\n",
       "       [ 0.49984974],\n",
       "       [        nan],\n",
       "       [ 0.49985477],\n",
       "       [ 0.49985722],\n",
       "       [ 0.4998489 ],\n",
       "       [ 0.49985746],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49986008],\n",
       "       [ 0.49983841],\n",
       "       [        nan],\n",
       "       [ 0.49983948],\n",
       "       [ 0.49985972],\n",
       "       [ 0.4997716 ],\n",
       "       [ 0.49985793],\n",
       "       [        nan],\n",
       "       [ 0.4998726 ],\n",
       "       [ 0.49983019],\n",
       "       [ 0.49984735],\n",
       "       [ 0.49986514],\n",
       "       [        nan],\n",
       "       [ 0.49983448],\n",
       "       [ 0.49985465],\n",
       "       [        nan],\n",
       "       [ 0.49985972],\n",
       "       [ 0.49985769],\n",
       "       [        nan],\n",
       "       [ 0.4998399 ],\n",
       "       [ 0.49985591],\n",
       "       [ 0.49985138],\n",
       "       [ 0.49982506],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.4998464 ],\n",
       "       [ 0.49985608],\n",
       "       [ 0.499854  ],\n",
       "       [ 0.49985328],\n",
       "       [ 0.49985668],\n",
       "       [ 0.49983114],\n",
       "       [ 0.49985519],\n",
       "       [ 0.49981457],\n",
       "       [ 0.49976122],\n",
       "       [ 0.49984914],\n",
       "       [ 0.49983639],\n",
       "       [ 0.49984556],\n",
       "       [        nan],\n",
       "       [ 0.49985757],\n",
       "       [        nan],\n",
       "       [ 0.49984628],\n",
       "       [ 0.49983829],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49984372],\n",
       "       [ 0.49985722],\n",
       "       [ 0.49985638],\n",
       "       [ 0.49980089],\n",
       "       [ 0.49985686],\n",
       "       [ 0.49983639],\n",
       "       [ 0.49985033],\n",
       "       [        nan],\n",
       "       [ 0.49986687],\n",
       "       [ 0.49985287],\n",
       "       [        nan],\n",
       "       [ 0.4998405 ],\n",
       "       [ 0.49984968],\n",
       "       [ 0.49982578],\n",
       "       [ 0.4998534 ],\n",
       "       [        nan],\n",
       "       [ 0.49985716],\n",
       "       [        nan],\n",
       "       [ 0.49985376],\n",
       "       [ 0.49985442],\n",
       "       [        nan],\n",
       "       [ 0.49983335],\n",
       "       [ 0.49985614],\n",
       "       [ 0.49985322],\n",
       "       [ 0.4998188 ],\n",
       "       [ 0.49983799],\n",
       "       [ 0.49980381],\n",
       "       [ 0.4998498 ],\n",
       "       [ 0.49982649],\n",
       "       [ 0.49985108],\n",
       "       [        nan],\n",
       "       [ 0.49979523],\n",
       "       [ 0.49984032],\n",
       "       [ 0.49985579],\n",
       "       [ 0.4998599 ],\n",
       "       [        nan],\n",
       "       [ 0.49984115],\n",
       "       [ 0.49984282],\n",
       "       [        nan],\n",
       "       [ 0.49986461],\n",
       "       [ 0.49983096],\n",
       "       [ 0.49986401],\n",
       "       [ 0.49985126],\n",
       "       [ 0.49984264],\n",
       "       [ 0.49986103],\n",
       "       [ 0.4998565 ],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.4998745 ],\n",
       "       [ 0.49978253],\n",
       "       [ 0.49986508],\n",
       "       [ 0.49985483],\n",
       "       [        nan],\n",
       "       [ 0.49985009],\n",
       "       [ 0.49985567],\n",
       "       [ 0.49984288],\n",
       "       [ 0.49985531],\n",
       "       [ 0.49984497],\n",
       "       [        nan],\n",
       "       [ 0.49984699],\n",
       "       [ 0.49981946],\n",
       "       [ 0.4998464 ],\n",
       "       [ 0.499834  ],\n",
       "       [        nan],\n",
       "       [ 0.49979076],\n",
       "       [ 0.49978325],\n",
       "       [        nan],\n",
       "       [ 0.49984771],\n",
       "       [ 0.49985841],\n",
       "       [ 0.49985716],\n",
       "       [ 0.49985853],\n",
       "       [ 0.49982512],\n",
       "       [        nan],\n",
       "       [ 0.49985686],\n",
       "       [        nan],\n",
       "       [ 0.49983937],\n",
       "       [ 0.49984461],\n",
       "       [ 0.49985161],\n",
       "       [ 0.49985573],\n",
       "       [ 0.49985912],\n",
       "       [        nan],\n",
       "       [ 0.49982816],\n",
       "       [ 0.49985936],\n",
       "       [ 0.49980626],\n",
       "       [ 0.49985853],\n",
       "       [ 0.49985924],\n",
       "       [ 0.49981147],\n",
       "       [ 0.49982327],\n",
       "       [ 0.4998306 ],\n",
       "       [ 0.49980706],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49983257],\n",
       "       [ 0.49985525],\n",
       "       [ 0.49983364],\n",
       "       [ 0.49984735],\n",
       "       [        nan],\n",
       "       [ 0.49987105],\n",
       "       [ 0.49985936],\n",
       "       [ 0.49982184],\n",
       "       [ 0.49985537],\n",
       "       [ 0.49984878],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985334],\n",
       "       [ 0.49985912],\n",
       "       [ 0.49985853],\n",
       "       [ 0.49984175],\n",
       "       [ 0.49985853],\n",
       "       [ 0.49984723],\n",
       "       [ 0.49987355],\n",
       "       [ 0.49984866],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49986145],\n",
       "       [ 0.49982184],\n",
       "       [        nan],\n",
       "       [ 0.49982226],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985537],\n",
       "       [ 0.49985221],\n",
       "       [ 0.4998371 ],\n",
       "       [ 0.49984735],\n",
       "       [ 0.4998574 ],\n",
       "       [ 0.49985644],\n",
       "       [ 0.49987403],\n",
       "       [        nan],\n",
       "       [ 0.49986479],\n",
       "       [ 0.49987075],\n",
       "       [ 0.49985078],\n",
       "       [        nan],\n",
       "       [ 0.49983925],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985376],\n",
       "       [        nan],\n",
       "       [ 0.49981481],\n",
       "       [ 0.49984711],\n",
       "       [ 0.49985465],\n",
       "       [ 0.49986628],\n",
       "       [        nan],\n",
       "       [ 0.4998439 ],\n",
       "       [ 0.49985316],\n",
       "       [ 0.49985185],\n",
       "       [        nan],\n",
       "       [ 0.49983573],\n",
       "       [ 0.49985567],\n",
       "       [        nan],\n",
       "       [ 0.49981606],\n",
       "       [ 0.49981624],\n",
       "       [ 0.49987534],\n",
       "       [ 0.49981022],\n",
       "       [ 0.49983555],\n",
       "       [ 0.49986067],\n",
       "       [ 0.49985704],\n",
       "       [        nan],\n",
       "       [ 0.49984908],\n",
       "       [ 0.49979886],\n",
       "       [ 0.49986061],\n",
       "       [ 0.49979433],\n",
       "       [ 0.49986002],\n",
       "       [ 0.49985412],\n",
       "       [ 0.49985221],\n",
       "       [ 0.49985477],\n",
       "       [ 0.49985495],\n",
       "       [ 0.49985328],\n",
       "       [ 0.49984479],\n",
       "       [ 0.49979469],\n",
       "       [ 0.49985752],\n",
       "       [ 0.49985793],\n",
       "       [ 0.49982083],\n",
       "       [ 0.49984771],\n",
       "       [ 0.49985757],\n",
       "       [ 0.49982679],\n",
       "       [ 0.4998371 ],\n",
       "       [        nan],\n",
       "       [ 0.49985591],\n",
       "       [ 0.49985406],\n",
       "       [ 0.49984783],\n",
       "       [ 0.49984807],\n",
       "       [ 0.49984914],\n",
       "       [ 0.49985078],\n",
       "       [        nan],\n",
       "       [ 0.49986091],\n",
       "       [ 0.49985221],\n",
       "       [        nan],\n",
       "       [ 0.49970514],\n",
       "       [        nan],\n",
       "       [ 0.49986222],\n",
       "       [ 0.49985328],\n",
       "       [ 0.49984843],\n",
       "       [ 0.49985483],\n",
       "       [ 0.49984652],\n",
       "       [ 0.49982488],\n",
       "       [ 0.49985483],\n",
       "       [ 0.49984616],\n",
       "       [ 0.49982125],\n",
       "       [ 0.49987236],\n",
       "       [ 0.49982959],\n",
       "       [ 0.49981481],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49984771],\n",
       "       [ 0.49984521],\n",
       "       [ 0.49984771],\n",
       "       [ 0.49984652],\n",
       "       [ 0.49985328],\n",
       "       [ 0.49984336],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985009],\n",
       "       [ 0.49982589],\n",
       "       [ 0.4998492 ],\n",
       "       [ 0.49985757],\n",
       "       [ 0.49981916],\n",
       "       [ 0.49985847],\n",
       "       [ 0.49983889],\n",
       "       [ 0.49981356],\n",
       "       [ 0.49977562],\n",
       "       [ 0.49985686],\n",
       "       [ 0.49985799],\n",
       "       [ 0.49982029],\n",
       "       [ 0.49986467],\n",
       "       [        nan],\n",
       "       [ 0.49985424],\n",
       "       [        nan],\n",
       "       [ 0.49985769],\n",
       "       [        nan],\n",
       "       [ 0.49984169],\n",
       "       [ 0.49985614],\n",
       "       [ 0.49983221],\n",
       "       [ 0.49985746],\n",
       "       [ 0.49986652],\n",
       "       [ 0.49983782],\n",
       "       [ 0.49982458],\n",
       "       [ 0.4998621 ],\n",
       "       [ 0.49984109],\n",
       "       [ 0.49984622],\n",
       "       [ 0.49984938],\n",
       "       [ 0.49985626],\n",
       "       [ 0.49981791],\n",
       "       [ 0.49985769],\n",
       "       [ 0.49985209],\n",
       "       [ 0.49981374],\n",
       "       [ 0.4998402 ],\n",
       "       [ 0.49984509],\n",
       "       [ 0.49985436],\n",
       "       [ 0.49983352],\n",
       "       [ 0.4998571 ],\n",
       "       [ 0.49985614],\n",
       "       [ 0.49978372],\n",
       "       [        nan],\n",
       "       [ 0.49987152],\n",
       "       [        nan],\n",
       "       [ 0.499825  ],\n",
       "       [ 0.49985364],\n",
       "       [        nan],\n",
       "       [ 0.49981886],\n",
       "       [ 0.49984962],\n",
       "       [        nan],\n",
       "       [        nan]], dtype=float32)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live :  0\n",
      "death :  418\n",
      "생존율 :  0.0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(x_test)\n",
    "live = len([x for x in pred.ravel() if x==1])\n",
    "death = len([x for x in pred.ravel() if x==0])\n",
    "print(\"live : \" , live)\n",
    "print(\"death : \" , death)\n",
    "print(\"생존율 : \", live / (live + death))\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../data/titanic/gender_submission.csv\")\n",
    "df_pred[['Survived']] = pred\n",
    "# df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
