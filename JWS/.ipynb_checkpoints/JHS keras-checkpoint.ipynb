{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#%% import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import pydot\n",
    "# from pylab import *\n",
    "from keras import models, layers, optimizers, metrics, utils, callbacks\n",
    "\n",
    "#%% csv 불러오기\n",
    "training = pd.read_csv('../data/titanic/train.csv')\n",
    "testing = pd.read_csv('../data/titanic/test.csv')\n",
    "\n",
    "#%% 데이터 요약\n",
    "# msno.matrix(training)\n",
    "# plt.show()\n",
    "print(training.shape)\n",
    "print(training.describe())\n",
    "print(training.dtypes)\n",
    "print(training.keys())\n",
    "print(testing.keys())\n",
    "\n",
    "#%% 데이터 분할\n",
    "# x_train (학습에 쓸 문제), y_train (학습에 쓴 문제 정답)\n",
    "# x_test (제출할 문제), y_test (추론해야 하는 것. 제출할 정답)\n",
    "x_train = training.drop(columns=['Survived'])\n",
    "y_train = training['Survived']\n",
    "x_test = testing.copy()\n",
    "\n",
    "#%% column 추가 (내 아이디어 아님)\n",
    "x_train['People'] = x_train['SibSp'] + x_train['Parch'] + 1\n",
    "x_train['IsAlone'] = x_train['People'].apply(lambda x: 1 if x == 1 else 0)\n",
    "x_train['HasCabin'] = x_train['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "\n",
    "x_test['People'] = x_test['SibSp'] + x_test['Parch'] + 1\n",
    "x_test['IsAlone'] = x_test['People'].apply(lambda x: 1 if x == 1 else 0)\n",
    "x_test['HasCabin'] = x_test['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "\n",
    "#%% 결측치 제거 (mean? median?)\n",
    "x_train['Age'] = x_train['Age'].fillna(x_train['Age'].mean())\n",
    "x_test['Age'] = x_test['Age'].fillna(x_test['Age'].mean())\n",
    "\n",
    "x_train['Embarked'] = x_train['Embarked'].fillna('S')\n",
    "\n",
    "x_test['Fare'] = x_test['Fare'].fillna(testing['Fare'].mean())\n",
    "\n",
    "#%% one-hot encoding\n",
    "x_train['Sex'] = x_train['Sex'].map({'male': 0, 'female': 1})\n",
    "x_train['Embarked'] = x_train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "x_test['Sex'] = x_test['Sex'].map({'male': 0, 'female': 1})\n",
    "x_test['Embarked'] = x_test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "#%% 예측에 안 쓸 칼럼 제거\n",
    "x_train = x_train.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "x_test = x_test.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "712/712 [==============================] - 0s 545us/step - loss: 0.6987 - acc: 0.5478 - val_loss: 0.6906 - val_acc: 0.6648\n",
      "Epoch 2/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.6960 - acc: 0.5772 - val_loss: 0.6897 - val_acc: 0.6425\n",
      "Epoch 3/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.6826 - acc: 0.5941 - val_loss: 0.6883 - val_acc: 0.6425\n",
      "Epoch 4/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.6785 - acc: 0.6096 - val_loss: 0.6876 - val_acc: 0.6425\n",
      "Epoch 5/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.6706 - acc: 0.6152 - val_loss: 0.6467 - val_acc: 0.6425\n",
      "Epoch 6/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.6590 - acc: 0.6138 - val_loss: 0.6141 - val_acc: 0.6425\n",
      "Epoch 7/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.6602 - acc: 0.6208 - val_loss: 0.6008 - val_acc: 0.6425\n",
      "Epoch 8/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.6537 - acc: 0.6180 - val_loss: 0.6081 - val_acc: 0.6425\n",
      "Epoch 9/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.6424 - acc: 0.6292 - val_loss: 0.5976 - val_acc: 0.6872\n",
      "Epoch 10/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.6426 - acc: 0.6194 - val_loss: 0.5670 - val_acc: 0.7151\n",
      "Epoch 11/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.6399 - acc: 0.6348 - val_loss: 0.5677 - val_acc: 0.7151\n",
      "Epoch 12/1000\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.6245 - acc: 0.6531 - val_loss: 0.5640 - val_acc: 0.6983\n",
      "Epoch 13/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6404 - acc: 0.6489 - val_loss: 0.5684 - val_acc: 0.7151\n",
      "Epoch 14/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.6219 - acc: 0.6531 - val_loss: 0.5592 - val_acc: 0.7207\n",
      "Epoch 15/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.6240 - acc: 0.6657 - val_loss: 0.5560 - val_acc: 0.7207\n",
      "Epoch 16/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.6418 - acc: 0.6812 - val_loss: 0.5582 - val_acc: 0.7207\n",
      "Epoch 17/1000\n",
      "712/712 [==============================] - 0s 52us/step - loss: 0.6357 - acc: 0.6699 - val_loss: 0.5656 - val_acc: 0.7151\n",
      "Epoch 18/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.6399 - acc: 0.6517 - val_loss: 0.5687 - val_acc: 0.7151\n",
      "Epoch 19/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.6306 - acc: 0.6742 - val_loss: 0.5583 - val_acc: 0.7207\n",
      "Epoch 20/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.6327 - acc: 0.6601 - val_loss: 0.5648 - val_acc: 0.7207\n",
      "Epoch 21/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.6269 - acc: 0.6615 - val_loss: 0.5610 - val_acc: 0.7095\n",
      "Epoch 22/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.6263 - acc: 0.6615 - val_loss: 0.5683 - val_acc: 0.7039\n",
      "Epoch 23/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.6206 - acc: 0.6615 - val_loss: 0.5567 - val_acc: 0.7039\n",
      "Epoch 24/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.6279 - acc: 0.6545 - val_loss: 0.5596 - val_acc: 0.7207\n",
      "Epoch 25/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.6154 - acc: 0.6517 - val_loss: 0.5541 - val_acc: 0.7095\n",
      "Epoch 26/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.6182 - acc: 0.6671 - val_loss: 0.5617 - val_acc: 0.7095\n",
      "Epoch 27/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.6143 - acc: 0.6601 - val_loss: 0.5472 - val_acc: 0.7151\n",
      "Epoch 28/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.6048 - acc: 0.6671 - val_loss: 0.5570 - val_acc: 0.7095\n",
      "Epoch 29/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.6081 - acc: 0.6587 - val_loss: 0.5512 - val_acc: 0.7095\n",
      "Epoch 30/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.6019 - acc: 0.6812 - val_loss: 0.5512 - val_acc: 0.7095\n",
      "Epoch 31/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.6187 - acc: 0.6868 - val_loss: 0.5577 - val_acc: 0.7207\n",
      "Epoch 32/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.6018 - acc: 0.6784 - val_loss: 0.5621 - val_acc: 0.7207\n",
      "Epoch 33/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.6058 - acc: 0.6784 - val_loss: 0.5395 - val_acc: 0.7263\n",
      "Epoch 34/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.6074 - acc: 0.6770 - val_loss: 0.5473 - val_acc: 0.7318\n",
      "Epoch 35/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.6054 - acc: 0.6910 - val_loss: 0.5418 - val_acc: 0.7374\n",
      "Epoch 36/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5990 - acc: 0.6798 - val_loss: 0.5319 - val_acc: 0.7374\n",
      "Epoch 37/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.5932 - acc: 0.6756 - val_loss: 0.5239 - val_acc: 0.7374\n",
      "Epoch 38/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.5895 - acc: 0.6826 - val_loss: 0.5247 - val_acc: 0.7374\n",
      "Epoch 39/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.5883 - acc: 0.6896 - val_loss: 0.5168 - val_acc: 0.7430\n",
      "Epoch 40/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.5833 - acc: 0.6840 - val_loss: 0.5247 - val_acc: 0.7374\n",
      "Epoch 41/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.5860 - acc: 0.6938 - val_loss: 0.5112 - val_acc: 0.7430\n",
      "Epoch 42/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.5807 - acc: 0.7008 - val_loss: 0.5055 - val_acc: 0.7486\n",
      "Epoch 43/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.5809 - acc: 0.6938 - val_loss: 0.5267 - val_acc: 0.7654\n",
      "Epoch 44/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.5824 - acc: 0.7037 - val_loss: 0.4970 - val_acc: 0.7542\n",
      "Epoch 45/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.5767 - acc: 0.6896 - val_loss: 0.4950 - val_acc: 0.7486\n",
      "Epoch 46/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.5810 - acc: 0.7093 - val_loss: 0.5083 - val_acc: 0.7654\n",
      "Epoch 47/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.5701 - acc: 0.7121 - val_loss: 0.4862 - val_acc: 0.7542\n",
      "Epoch 48/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.5616 - acc: 0.7079 - val_loss: 0.4823 - val_acc: 0.7709\n",
      "Epoch 49/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.5759 - acc: 0.6910 - val_loss: 0.4867 - val_acc: 0.7709\n",
      "Epoch 50/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.5523 - acc: 0.7177 - val_loss: 0.4863 - val_acc: 0.7933\n",
      "Epoch 51/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.5658 - acc: 0.7079 - val_loss: 0.4787 - val_acc: 0.7821\n",
      "Epoch 52/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.5690 - acc: 0.7149 - val_loss: 0.4803 - val_acc: 0.7765\n",
      "Epoch 53/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.5643 - acc: 0.7205 - val_loss: 0.4680 - val_acc: 0.7709\n",
      "Epoch 54/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5384 - acc: 0.7247 - val_loss: 0.4612 - val_acc: 0.7709\n",
      "Epoch 55/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5498 - acc: 0.7233 - val_loss: 0.4555 - val_acc: 0.7709\n",
      "Epoch 56/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.5479 - acc: 0.7191 - val_loss: 0.4934 - val_acc: 0.8045\n",
      "Epoch 57/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5594 - acc: 0.7219 - val_loss: 0.4661 - val_acc: 0.8156\n",
      "Epoch 58/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5586 - acc: 0.7121 - val_loss: 0.4688 - val_acc: 0.8045\n",
      "Epoch 59/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.5410 - acc: 0.7626 - val_loss: 0.4743 - val_acc: 0.8212\n",
      "Epoch 60/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.5533 - acc: 0.7360 - val_loss: 0.4654 - val_acc: 0.8268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.5412 - acc: 0.7416 - val_loss: 0.4461 - val_acc: 0.7989\n",
      "Epoch 62/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.5403 - acc: 0.7570 - val_loss: 0.4547 - val_acc: 0.8045\n",
      "Epoch 63/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.5312 - acc: 0.7528 - val_loss: 0.4414 - val_acc: 0.8101\n",
      "Epoch 64/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5213 - acc: 0.7486 - val_loss: 0.4488 - val_acc: 0.8268\n",
      "Epoch 65/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.5414 - acc: 0.7430 - val_loss: 0.4502 - val_acc: 0.8324\n",
      "Epoch 66/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5317 - acc: 0.7598 - val_loss: 0.4469 - val_acc: 0.8268\n",
      "Epoch 67/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5205 - acc: 0.7669 - val_loss: 0.4482 - val_acc: 0.8212\n",
      "Epoch 68/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.5244 - acc: 0.7711 - val_loss: 0.4470 - val_acc: 0.8045\n",
      "Epoch 69/1000\n",
      "712/712 [==============================] - 0s 29us/step - loss: 0.5386 - acc: 0.7430 - val_loss: 0.4445 - val_acc: 0.8101\n",
      "Epoch 70/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.5315 - acc: 0.7556 - val_loss: 0.4383 - val_acc: 0.8268\n",
      "Epoch 71/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.5234 - acc: 0.7711 - val_loss: 0.4339 - val_acc: 0.8212\n",
      "Epoch 72/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.5308 - acc: 0.7711 - val_loss: 0.4348 - val_acc: 0.8212\n",
      "Epoch 73/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.5317 - acc: 0.7514 - val_loss: 0.4390 - val_acc: 0.8268\n",
      "Epoch 74/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5155 - acc: 0.7626 - val_loss: 0.4308 - val_acc: 0.8380\n",
      "Epoch 75/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5136 - acc: 0.7683 - val_loss: 0.4523 - val_acc: 0.8045\n",
      "Epoch 76/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.5295 - acc: 0.7640 - val_loss: 0.4255 - val_acc: 0.8324\n",
      "Epoch 77/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.5052 - acc: 0.7711 - val_loss: 0.4364 - val_acc: 0.8156\n",
      "Epoch 78/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5158 - acc: 0.7739 - val_loss: 0.4264 - val_acc: 0.8212\n",
      "Epoch 79/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5174 - acc: 0.7683 - val_loss: 0.4292 - val_acc: 0.8268\n",
      "Epoch 80/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.5229 - acc: 0.7556 - val_loss: 0.4436 - val_acc: 0.8380\n",
      "Epoch 81/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5012 - acc: 0.7767 - val_loss: 0.4338 - val_acc: 0.8324\n",
      "Epoch 82/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.5188 - acc: 0.7739 - val_loss: 0.4236 - val_acc: 0.8324\n",
      "Epoch 83/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5259 - acc: 0.7654 - val_loss: 0.4308 - val_acc: 0.8268\n",
      "Epoch 84/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.5223 - acc: 0.7669 - val_loss: 0.4507 - val_acc: 0.8268\n",
      "Epoch 85/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5164 - acc: 0.7725 - val_loss: 0.4312 - val_acc: 0.8268\n",
      "Epoch 86/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5136 - acc: 0.7823 - val_loss: 0.4465 - val_acc: 0.8156\n",
      "Epoch 87/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5179 - acc: 0.7683 - val_loss: 0.4183 - val_acc: 0.8380\n",
      "Epoch 88/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.5114 - acc: 0.7851 - val_loss: 0.4338 - val_acc: 0.8212\n",
      "Epoch 89/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.5277 - acc: 0.7514 - val_loss: 0.4323 - val_acc: 0.8436\n",
      "Epoch 90/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.5186 - acc: 0.7669 - val_loss: 0.4658 - val_acc: 0.8324\n",
      "Epoch 91/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.5186 - acc: 0.7598 - val_loss: 0.4195 - val_acc: 0.8324\n",
      "Epoch 92/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5026 - acc: 0.7893 - val_loss: 0.4265 - val_acc: 0.8268\n",
      "Epoch 93/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5207 - acc: 0.7711 - val_loss: 0.4090 - val_acc: 0.8324\n",
      "Epoch 94/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5031 - acc: 0.7837 - val_loss: 0.4202 - val_acc: 0.8268\n",
      "Epoch 95/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.5083 - acc: 0.7809 - val_loss: 0.4212 - val_acc: 0.8212\n",
      "Epoch 96/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.5149 - acc: 0.7711 - val_loss: 0.4442 - val_acc: 0.8212\n",
      "Epoch 97/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4990 - acc: 0.7767 - val_loss: 0.4322 - val_acc: 0.8212\n",
      "Epoch 98/1000\n",
      "712/712 [==============================] - 0s 30us/step - loss: 0.4877 - acc: 0.7879 - val_loss: 0.4295 - val_acc: 0.8212\n",
      "Epoch 99/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4950 - acc: 0.7739 - val_loss: 0.3919 - val_acc: 0.8212\n",
      "Epoch 100/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.5046 - acc: 0.7683 - val_loss: 0.4600 - val_acc: 0.7709\n",
      "Epoch 101/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.5009 - acc: 0.7781 - val_loss: 0.4187 - val_acc: 0.8268\n",
      "Epoch 102/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4877 - acc: 0.7781 - val_loss: 0.4200 - val_acc: 0.8268\n",
      "Epoch 103/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4862 - acc: 0.7893 - val_loss: 0.3984 - val_acc: 0.8268\n",
      "Epoch 104/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4906 - acc: 0.7781 - val_loss: 0.4021 - val_acc: 0.8324\n",
      "Epoch 105/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4966 - acc: 0.7739 - val_loss: 0.4226 - val_acc: 0.8324\n",
      "Epoch 106/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4888 - acc: 0.7837 - val_loss: 0.4094 - val_acc: 0.8324\n",
      "Epoch 107/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4925 - acc: 0.7879 - val_loss: 0.3966 - val_acc: 0.8268\n",
      "Epoch 108/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4910 - acc: 0.7753 - val_loss: 0.4006 - val_acc: 0.8324\n",
      "Epoch 109/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4795 - acc: 0.7963 - val_loss: 0.4084 - val_acc: 0.8324\n",
      "Epoch 110/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4926 - acc: 0.7823 - val_loss: 0.4284 - val_acc: 0.8324\n",
      "Epoch 111/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4817 - acc: 0.7837 - val_loss: 0.3977 - val_acc: 0.8380\n",
      "Epoch 112/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4790 - acc: 0.7879 - val_loss: 0.4080 - val_acc: 0.8324\n",
      "Epoch 113/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4774 - acc: 0.7893 - val_loss: 0.3951 - val_acc: 0.8324\n",
      "Epoch 114/1000\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4763 - acc: 0.7963 - val_loss: 0.4108 - val_acc: 0.8380\n",
      "Epoch 115/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4838 - acc: 0.7697 - val_loss: 0.3974 - val_acc: 0.8324\n",
      "Epoch 116/1000\n",
      "712/712 [==============================] - 0s 50us/step - loss: 0.4896 - acc: 0.7949 - val_loss: 0.4343 - val_acc: 0.8268\n",
      "Epoch 117/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4856 - acc: 0.7809 - val_loss: 0.4476 - val_acc: 0.8156\n",
      "Epoch 118/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4830 - acc: 0.7907 - val_loss: 0.4077 - val_acc: 0.8324\n",
      "Epoch 119/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4738 - acc: 0.7837 - val_loss: 0.4005 - val_acc: 0.8324\n",
      "Epoch 120/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4737 - acc: 0.7893 - val_loss: 0.3964 - val_acc: 0.8212\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 31us/step - loss: 0.4785 - acc: 0.7851 - val_loss: 0.4079 - val_acc: 0.8268\n",
      "Epoch 122/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4763 - acc: 0.7823 - val_loss: 0.4043 - val_acc: 0.8324\n",
      "Epoch 123/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4707 - acc: 0.7893 - val_loss: 0.3988 - val_acc: 0.8324\n",
      "Epoch 124/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4849 - acc: 0.7865 - val_loss: 0.4076 - val_acc: 0.8324\n",
      "Epoch 125/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4797 - acc: 0.7935 - val_loss: 0.3839 - val_acc: 0.8324\n",
      "Epoch 126/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4813 - acc: 0.7767 - val_loss: 0.3782 - val_acc: 0.8380\n",
      "Epoch 127/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4680 - acc: 0.7879 - val_loss: 0.4066 - val_acc: 0.8268\n",
      "Epoch 128/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4888 - acc: 0.7963 - val_loss: 0.3993 - val_acc: 0.8380\n",
      "Epoch 129/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4755 - acc: 0.7837 - val_loss: 0.3758 - val_acc: 0.8380\n",
      "Epoch 130/1000\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4838 - acc: 0.7907 - val_loss: 0.4323 - val_acc: 0.8212\n",
      "Epoch 131/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4843 - acc: 0.7739 - val_loss: 0.4270 - val_acc: 0.7933\n",
      "Epoch 132/1000\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4800 - acc: 0.7669 - val_loss: 0.4009 - val_acc: 0.8324\n",
      "Epoch 133/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4768 - acc: 0.7823 - val_loss: 0.3964 - val_acc: 0.8324\n",
      "Epoch 134/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4716 - acc: 0.7851 - val_loss: 0.3986 - val_acc: 0.8380\n",
      "Epoch 135/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4615 - acc: 0.8020 - val_loss: 0.3788 - val_acc: 0.8436\n",
      "Epoch 136/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4452 - acc: 0.8132 - val_loss: 0.3894 - val_acc: 0.8268\n",
      "Epoch 137/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4774 - acc: 0.7837 - val_loss: 0.3868 - val_acc: 0.8324\n",
      "Epoch 138/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4534 - acc: 0.7907 - val_loss: 0.4029 - val_acc: 0.8212\n",
      "Epoch 139/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4807 - acc: 0.7851 - val_loss: 0.3916 - val_acc: 0.8268\n",
      "Epoch 140/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4661 - acc: 0.7879 - val_loss: 0.4039 - val_acc: 0.8324\n",
      "Epoch 141/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4773 - acc: 0.7753 - val_loss: 0.3911 - val_acc: 0.8380\n",
      "Epoch 142/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4695 - acc: 0.7795 - val_loss: 0.3845 - val_acc: 0.8380\n",
      "Epoch 143/1000\n",
      "712/712 [==============================] - 0s 50us/step - loss: 0.4677 - acc: 0.7865 - val_loss: 0.3811 - val_acc: 0.8492\n",
      "Epoch 144/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4815 - acc: 0.7795 - val_loss: 0.4100 - val_acc: 0.7933\n",
      "Epoch 145/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4597 - acc: 0.7935 - val_loss: 0.3735 - val_acc: 0.8156\n",
      "Epoch 146/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4712 - acc: 0.7837 - val_loss: 0.3852 - val_acc: 0.8380\n",
      "Epoch 147/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4609 - acc: 0.7935 - val_loss: 0.3995 - val_acc: 0.8436\n",
      "Epoch 148/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4649 - acc: 0.7921 - val_loss: 0.3905 - val_acc: 0.8324\n",
      "Epoch 149/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4675 - acc: 0.7809 - val_loss: 0.3953 - val_acc: 0.8324\n",
      "Epoch 150/1000\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4673 - acc: 0.7879 - val_loss: 0.3882 - val_acc: 0.8436\n",
      "Epoch 151/1000\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4566 - acc: 0.7963 - val_loss: 0.3871 - val_acc: 0.8380\n",
      "Epoch 152/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4709 - acc: 0.7935 - val_loss: 0.3763 - val_acc: 0.8324\n",
      "Epoch 153/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4867 - acc: 0.7809 - val_loss: 0.3953 - val_acc: 0.8268\n",
      "Epoch 154/1000\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4718 - acc: 0.7837 - val_loss: 0.4017 - val_acc: 0.8212\n",
      "Epoch 155/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4471 - acc: 0.7949 - val_loss: 0.3751 - val_acc: 0.8492\n",
      "Epoch 156/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4696 - acc: 0.7851 - val_loss: 0.3936 - val_acc: 0.8268\n",
      "Epoch 157/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4396 - acc: 0.8062 - val_loss: 0.3719 - val_acc: 0.8380\n",
      "Epoch 158/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4652 - acc: 0.7753 - val_loss: 0.3797 - val_acc: 0.8436\n",
      "Epoch 159/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4636 - acc: 0.7795 - val_loss: 0.4205 - val_acc: 0.8268\n",
      "Epoch 160/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4804 - acc: 0.7739 - val_loss: 0.4043 - val_acc: 0.8436\n",
      "Epoch 161/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4584 - acc: 0.7949 - val_loss: 0.3997 - val_acc: 0.8324\n",
      "Epoch 162/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4680 - acc: 0.7767 - val_loss: 0.3992 - val_acc: 0.8268\n",
      "Epoch 163/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4588 - acc: 0.7893 - val_loss: 0.4079 - val_acc: 0.8268\n",
      "Epoch 164/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4538 - acc: 0.8048 - val_loss: 0.3978 - val_acc: 0.8436\n",
      "Epoch 165/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4566 - acc: 0.8020 - val_loss: 0.3768 - val_acc: 0.8380\n",
      "Epoch 166/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4600 - acc: 0.7963 - val_loss: 0.3647 - val_acc: 0.8436\n",
      "Epoch 167/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4448 - acc: 0.7978 - val_loss: 0.3964 - val_acc: 0.8324\n",
      "Epoch 168/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4642 - acc: 0.7978 - val_loss: 0.3811 - val_acc: 0.8380\n",
      "Epoch 169/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4678 - acc: 0.7823 - val_loss: 0.3755 - val_acc: 0.8492\n",
      "Epoch 170/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4426 - acc: 0.8048 - val_loss: 0.3849 - val_acc: 0.8380\n",
      "Epoch 171/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4462 - acc: 0.7949 - val_loss: 0.4133 - val_acc: 0.8212\n",
      "Epoch 172/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4654 - acc: 0.8006 - val_loss: 0.3901 - val_acc: 0.8324\n",
      "Epoch 173/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4488 - acc: 0.7907 - val_loss: 0.3868 - val_acc: 0.8492\n",
      "Epoch 174/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4604 - acc: 0.7907 - val_loss: 0.3724 - val_acc: 0.8212\n",
      "Epoch 175/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4453 - acc: 0.7992 - val_loss: 0.4008 - val_acc: 0.8380\n",
      "Epoch 176/1000\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4719 - acc: 0.7921 - val_loss: 0.3915 - val_acc: 0.8492\n",
      "Epoch 177/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4678 - acc: 0.7992 - val_loss: 0.3890 - val_acc: 0.8212\n",
      "Epoch 178/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4407 - acc: 0.8006 - val_loss: 0.3805 - val_acc: 0.8436\n",
      "Epoch 179/1000\n",
      "712/712 [==============================] - 0s 50us/step - loss: 0.4532 - acc: 0.8020 - val_loss: 0.3643 - val_acc: 0.8324\n",
      "Epoch 180/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4550 - acc: 0.7935 - val_loss: 0.3656 - val_acc: 0.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4473 - acc: 0.8062 - val_loss: 0.3950 - val_acc: 0.8380\n",
      "Epoch 182/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4578 - acc: 0.7963 - val_loss: 0.3997 - val_acc: 0.8268\n",
      "Epoch 183/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4553 - acc: 0.7963 - val_loss: 0.3806 - val_acc: 0.8380\n",
      "Epoch 184/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4666 - acc: 0.7949 - val_loss: 0.3750 - val_acc: 0.8380\n",
      "Epoch 185/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4525 - acc: 0.8006 - val_loss: 0.3955 - val_acc: 0.8380\n",
      "Epoch 186/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4607 - acc: 0.8006 - val_loss: 0.3859 - val_acc: 0.8212\n",
      "Epoch 187/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4559 - acc: 0.7935 - val_loss: 0.3814 - val_acc: 0.8380\n",
      "Epoch 188/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4467 - acc: 0.8006 - val_loss: 0.3851 - val_acc: 0.8436\n",
      "Epoch 189/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4606 - acc: 0.7879 - val_loss: 0.3806 - val_acc: 0.8547\n",
      "Epoch 190/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4330 - acc: 0.8020 - val_loss: 0.4052 - val_acc: 0.7933\n",
      "Epoch 191/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4741 - acc: 0.7823 - val_loss: 0.3938 - val_acc: 0.8436\n",
      "Epoch 192/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4595 - acc: 0.7865 - val_loss: 0.3890 - val_acc: 0.8268\n",
      "Epoch 193/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4522 - acc: 0.7907 - val_loss: 0.3733 - val_acc: 0.8547\n",
      "Epoch 194/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4380 - acc: 0.8034 - val_loss: 0.3704 - val_acc: 0.8380\n",
      "Epoch 195/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4512 - acc: 0.7978 - val_loss: 0.3753 - val_acc: 0.8324\n",
      "Epoch 196/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4423 - acc: 0.8048 - val_loss: 0.3809 - val_acc: 0.8547\n",
      "Epoch 197/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4673 - acc: 0.7809 - val_loss: 0.3855 - val_acc: 0.8492\n",
      "Epoch 198/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4489 - acc: 0.7992 - val_loss: 0.3888 - val_acc: 0.8380\n",
      "Epoch 199/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4560 - acc: 0.7935 - val_loss: 0.3826 - val_acc: 0.8436\n",
      "Epoch 200/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4495 - acc: 0.8020 - val_loss: 0.3830 - val_acc: 0.8268\n",
      "Epoch 201/1000\n",
      "712/712 [==============================] - 0s 50us/step - loss: 0.4521 - acc: 0.7907 - val_loss: 0.3812 - val_acc: 0.8436\n",
      "Epoch 202/1000\n",
      "712/712 [==============================] - 0s 52us/step - loss: 0.4520 - acc: 0.7949 - val_loss: 0.4003 - val_acc: 0.8324\n",
      "Epoch 203/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4390 - acc: 0.8104 - val_loss: 0.3985 - val_acc: 0.8436\n",
      "Epoch 204/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4468 - acc: 0.8118 - val_loss: 0.3940 - val_acc: 0.8492\n",
      "Epoch 205/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4546 - acc: 0.7879 - val_loss: 0.3778 - val_acc: 0.8268\n",
      "Epoch 206/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4517 - acc: 0.7767 - val_loss: 0.3783 - val_acc: 0.8212\n",
      "Epoch 207/1000\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4403 - acc: 0.7963 - val_loss: 0.3867 - val_acc: 0.8212\n",
      "Epoch 208/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4483 - acc: 0.8006 - val_loss: 0.3693 - val_acc: 0.8380\n",
      "Epoch 209/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4369 - acc: 0.8034 - val_loss: 0.3866 - val_acc: 0.8324\n",
      "Epoch 210/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4441 - acc: 0.8034 - val_loss: 0.3944 - val_acc: 0.8324\n",
      "Epoch 211/1000\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.4616 - acc: 0.8006 - val_loss: 0.3788 - val_acc: 0.8547\n",
      "Epoch 212/1000\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4419 - acc: 0.7963 - val_loss: 0.3665 - val_acc: 0.8380\n",
      "Epoch 213/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4560 - acc: 0.7949 - val_loss: 0.3972 - val_acc: 0.8436\n",
      "Epoch 214/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4528 - acc: 0.8076 - val_loss: 0.3729 - val_acc: 0.8492\n",
      "Epoch 215/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4424 - acc: 0.8076 - val_loss: 0.3967 - val_acc: 0.8324\n",
      "Epoch 216/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4621 - acc: 0.7978 - val_loss: 0.3769 - val_acc: 0.8324\n",
      "Epoch 217/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4446 - acc: 0.7935 - val_loss: 0.3673 - val_acc: 0.8492\n",
      "Epoch 218/1000\n",
      "712/712 [==============================] - 0s 30us/step - loss: 0.4396 - acc: 0.8020 - val_loss: 0.4033 - val_acc: 0.8380\n",
      "Epoch 219/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4547 - acc: 0.7865 - val_loss: 0.3967 - val_acc: 0.8268\n",
      "Epoch 220/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4392 - acc: 0.8118 - val_loss: 0.3646 - val_acc: 0.8547\n",
      "Epoch 221/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4493 - acc: 0.7921 - val_loss: 0.3822 - val_acc: 0.8492\n",
      "Epoch 222/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4418 - acc: 0.8020 - val_loss: 0.3851 - val_acc: 0.8436\n",
      "Epoch 223/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4552 - acc: 0.7907 - val_loss: 0.3908 - val_acc: 0.8212\n",
      "Epoch 224/1000\n",
      "712/712 [==============================] - 0s 29us/step - loss: 0.4352 - acc: 0.8090 - val_loss: 0.3811 - val_acc: 0.8492\n",
      "Epoch 225/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4345 - acc: 0.8048 - val_loss: 0.3779 - val_acc: 0.8380\n",
      "Epoch 226/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4348 - acc: 0.8006 - val_loss: 0.3774 - val_acc: 0.8436\n",
      "Epoch 227/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4465 - acc: 0.7949 - val_loss: 0.4172 - val_acc: 0.8212\n",
      "Epoch 228/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4394 - acc: 0.7935 - val_loss: 0.3814 - val_acc: 0.8492\n",
      "Epoch 229/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4469 - acc: 0.8034 - val_loss: 0.3874 - val_acc: 0.8380\n",
      "Epoch 230/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4471 - acc: 0.7893 - val_loss: 0.3762 - val_acc: 0.8436\n",
      "Epoch 231/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4400 - acc: 0.7963 - val_loss: 0.3872 - val_acc: 0.8380\n",
      "Epoch 232/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4405 - acc: 0.8006 - val_loss: 0.3775 - val_acc: 0.8380\n",
      "Epoch 233/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4452 - acc: 0.7879 - val_loss: 0.3800 - val_acc: 0.8268\n",
      "Epoch 234/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4398 - acc: 0.7949 - val_loss: 0.3752 - val_acc: 0.8268\n",
      "Epoch 235/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4388 - acc: 0.8034 - val_loss: 0.3833 - val_acc: 0.8492\n",
      "Epoch 236/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4358 - acc: 0.8090 - val_loss: 0.3751 - val_acc: 0.8380\n",
      "Epoch 237/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4436 - acc: 0.8076 - val_loss: 0.3762 - val_acc: 0.8436\n",
      "Epoch 238/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4353 - acc: 0.8048 - val_loss: 0.3884 - val_acc: 0.8324\n",
      "Epoch 239/1000\n",
      "712/712 [==============================] - 0s 30us/step - loss: 0.4408 - acc: 0.8020 - val_loss: 0.3724 - val_acc: 0.8380\n",
      "Epoch 240/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4439 - acc: 0.7978 - val_loss: 0.3776 - val_acc: 0.8492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4532 - acc: 0.8076 - val_loss: 0.3638 - val_acc: 0.8547\n",
      "Epoch 242/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4456 - acc: 0.7921 - val_loss: 0.3647 - val_acc: 0.8603\n",
      "Epoch 243/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4502 - acc: 0.7963 - val_loss: 0.3616 - val_acc: 0.8603\n",
      "Epoch 244/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4318 - acc: 0.8006 - val_loss: 0.3940 - val_acc: 0.8436\n",
      "Epoch 245/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4319 - acc: 0.7935 - val_loss: 0.3769 - val_acc: 0.8492\n",
      "Epoch 246/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4414 - acc: 0.7978 - val_loss: 0.3572 - val_acc: 0.8212\n",
      "Epoch 247/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4338 - acc: 0.8006 - val_loss: 0.3631 - val_acc: 0.8547\n",
      "Epoch 248/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4430 - acc: 0.8034 - val_loss: 0.3755 - val_acc: 0.8547\n",
      "Epoch 249/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4304 - acc: 0.7963 - val_loss: 0.4009 - val_acc: 0.8380\n",
      "Epoch 250/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4348 - acc: 0.8020 - val_loss: 0.3867 - val_acc: 0.8380\n",
      "Epoch 251/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4574 - acc: 0.7809 - val_loss: 0.3700 - val_acc: 0.8547\n",
      "Epoch 252/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4329 - acc: 0.8020 - val_loss: 0.3859 - val_acc: 0.8492\n",
      "Epoch 253/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4337 - acc: 0.8076 - val_loss: 0.3615 - val_acc: 0.8547\n",
      "Epoch 254/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4474 - acc: 0.8132 - val_loss: 0.3576 - val_acc: 0.8659\n",
      "Epoch 255/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4410 - acc: 0.7949 - val_loss: 0.3783 - val_acc: 0.8603\n",
      "Epoch 256/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4332 - acc: 0.8118 - val_loss: 0.3825 - val_acc: 0.8547\n",
      "Epoch 257/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4436 - acc: 0.8006 - val_loss: 0.3863 - val_acc: 0.8492\n",
      "Epoch 258/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4480 - acc: 0.7963 - val_loss: 0.3769 - val_acc: 0.8436\n",
      "Epoch 259/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4346 - acc: 0.8062 - val_loss: 0.3781 - val_acc: 0.8436\n",
      "Epoch 260/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4466 - acc: 0.8062 - val_loss: 0.3673 - val_acc: 0.8492\n",
      "Epoch 261/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4352 - acc: 0.7935 - val_loss: 0.3743 - val_acc: 0.8380\n",
      "Epoch 262/1000\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4448 - acc: 0.7921 - val_loss: 0.3723 - val_acc: 0.8380\n",
      "Epoch 263/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4395 - acc: 0.8132 - val_loss: 0.3927 - val_acc: 0.8492\n",
      "Epoch 264/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4560 - acc: 0.7963 - val_loss: 0.3932 - val_acc: 0.8268\n",
      "Epoch 265/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4286 - acc: 0.8104 - val_loss: 0.3865 - val_acc: 0.8436\n",
      "Epoch 266/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4396 - acc: 0.8118 - val_loss: 0.3773 - val_acc: 0.8492\n",
      "Epoch 267/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4435 - acc: 0.7992 - val_loss: 0.4044 - val_acc: 0.8268\n",
      "Epoch 268/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4325 - acc: 0.7963 - val_loss: 0.4089 - val_acc: 0.8324\n",
      "Epoch 269/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4396 - acc: 0.7879 - val_loss: 0.3793 - val_acc: 0.8492\n",
      "Epoch 270/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4468 - acc: 0.8048 - val_loss: 0.3890 - val_acc: 0.8212\n",
      "Epoch 271/1000\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4419 - acc: 0.7921 - val_loss: 0.3691 - val_acc: 0.8603\n",
      "Epoch 272/1000\n",
      "712/712 [==============================] - 0s 54us/step - loss: 0.4484 - acc: 0.7949 - val_loss: 0.3677 - val_acc: 0.8547\n",
      "Epoch 273/1000\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4147 - acc: 0.8118 - val_loss: 0.3842 - val_acc: 0.8603\n",
      "Epoch 274/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4306 - acc: 0.8160 - val_loss: 0.3662 - val_acc: 0.8659\n",
      "Epoch 275/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4351 - acc: 0.8062 - val_loss: 0.3721 - val_acc: 0.8547\n",
      "Epoch 276/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4231 - acc: 0.8146 - val_loss: 0.4014 - val_acc: 0.8380\n",
      "Epoch 277/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4435 - acc: 0.7963 - val_loss: 0.3630 - val_acc: 0.8492\n",
      "Epoch 278/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4375 - acc: 0.8034 - val_loss: 0.3769 - val_acc: 0.8436\n",
      "Epoch 279/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4272 - acc: 0.8146 - val_loss: 0.3629 - val_acc: 0.8436\n",
      "Epoch 280/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4454 - acc: 0.7963 - val_loss: 0.3685 - val_acc: 0.8547\n",
      "Epoch 281/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4332 - acc: 0.7978 - val_loss: 0.3549 - val_acc: 0.8492\n",
      "Epoch 282/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4309 - acc: 0.7949 - val_loss: 0.3690 - val_acc: 0.8771\n",
      "Epoch 283/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4313 - acc: 0.8062 - val_loss: 0.4200 - val_acc: 0.8268\n",
      "Epoch 284/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4561 - acc: 0.8006 - val_loss: 0.3628 - val_acc: 0.8659\n",
      "Epoch 285/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4322 - acc: 0.8090 - val_loss: 0.3683 - val_acc: 0.8547\n",
      "Epoch 286/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4406 - acc: 0.7992 - val_loss: 0.3700 - val_acc: 0.8436\n",
      "Epoch 287/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4281 - acc: 0.8076 - val_loss: 0.3760 - val_acc: 0.8436\n",
      "Epoch 288/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4403 - acc: 0.8104 - val_loss: 0.3658 - val_acc: 0.8492\n",
      "Epoch 289/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4340 - acc: 0.8006 - val_loss: 0.3683 - val_acc: 0.8715\n",
      "Epoch 290/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4308 - acc: 0.7992 - val_loss: 0.3796 - val_acc: 0.8436\n",
      "Epoch 291/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4359 - acc: 0.8076 - val_loss: 0.3659 - val_acc: 0.8436\n",
      "Epoch 292/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4422 - acc: 0.7963 - val_loss: 0.3901 - val_acc: 0.8492\n",
      "Epoch 293/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4363 - acc: 0.7949 - val_loss: 0.3606 - val_acc: 0.8659\n",
      "Epoch 294/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4357 - acc: 0.8076 - val_loss: 0.3626 - val_acc: 0.8547\n",
      "Epoch 295/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4257 - acc: 0.8076 - val_loss: 0.3581 - val_acc: 0.8603\n",
      "Epoch 296/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4447 - acc: 0.7992 - val_loss: 0.3750 - val_acc: 0.8380\n",
      "Epoch 297/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4397 - acc: 0.8118 - val_loss: 0.4011 - val_acc: 0.8380\n",
      "Epoch 298/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4379 - acc: 0.8020 - val_loss: 0.4281 - val_acc: 0.8436\n",
      "Epoch 299/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4314 - acc: 0.7978 - val_loss: 0.3696 - val_acc: 0.8603\n",
      "Epoch 300/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4184 - acc: 0.8174 - val_loss: 0.3681 - val_acc: 0.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4355 - acc: 0.8160 - val_loss: 0.3880 - val_acc: 0.8547\n",
      "Epoch 302/1000\n",
      "712/712 [==============================] - 0s 50us/step - loss: 0.4124 - acc: 0.8174 - val_loss: 0.3819 - val_acc: 0.8492\n",
      "Epoch 303/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4325 - acc: 0.8104 - val_loss: 0.3628 - val_acc: 0.8771\n",
      "Epoch 304/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4452 - acc: 0.7907 - val_loss: 0.3542 - val_acc: 0.8603\n",
      "Epoch 305/1000\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4359 - acc: 0.7893 - val_loss: 0.3802 - val_acc: 0.8547\n",
      "Epoch 306/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4207 - acc: 0.8104 - val_loss: 0.3790 - val_acc: 0.8436\n",
      "Epoch 307/1000\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4429 - acc: 0.8006 - val_loss: 0.3883 - val_acc: 0.8547\n",
      "Epoch 308/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4142 - acc: 0.8132 - val_loss: 0.3657 - val_acc: 0.8380\n",
      "Epoch 309/1000\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.4272 - acc: 0.7992 - val_loss: 0.3670 - val_acc: 0.8603\n",
      "Epoch 310/1000\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4345 - acc: 0.8118 - val_loss: 0.3785 - val_acc: 0.8436\n",
      "Epoch 311/1000\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4229 - acc: 0.8062 - val_loss: 0.3671 - val_acc: 0.8547\n",
      "Epoch 312/1000\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.4273 - acc: 0.8076 - val_loss: 0.3797 - val_acc: 0.8547\n",
      "Epoch 313/1000\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4159 - acc: 0.8118 - val_loss: 0.3612 - val_acc: 0.8492\n",
      "Epoch 314/1000\n",
      "712/712 [==============================] - 0s 51us/step - loss: 0.4322 - acc: 0.7921 - val_loss: 0.3649 - val_acc: 0.8603\n",
      "Epoch 315/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4379 - acc: 0.7921 - val_loss: 0.3765 - val_acc: 0.8380\n",
      "Epoch 316/1000\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4149 - acc: 0.8160 - val_loss: 0.3840 - val_acc: 0.8436\n",
      "Epoch 317/1000\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4185 - acc: 0.8062 - val_loss: 0.3563 - val_acc: 0.8547\n",
      "Epoch 318/1000\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4310 - acc: 0.7992 - val_loss: 0.3735 - val_acc: 0.8436\n",
      "Epoch 319/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4328 - acc: 0.8006 - val_loss: 0.3636 - val_acc: 0.8659\n",
      "Epoch 320/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4105 - acc: 0.8188 - val_loss: 0.3987 - val_acc: 0.8547\n",
      "Epoch 321/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4230 - acc: 0.8048 - val_loss: 0.4300 - val_acc: 0.8436\n",
      "Epoch 322/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4477 - acc: 0.7992 - val_loss: 0.3875 - val_acc: 0.8436\n",
      "Epoch 323/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4222 - acc: 0.8076 - val_loss: 0.3577 - val_acc: 0.8715\n",
      "Epoch 324/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4200 - acc: 0.8132 - val_loss: 0.3917 - val_acc: 0.8603\n",
      "Epoch 325/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4336 - acc: 0.8020 - val_loss: 0.3584 - val_acc: 0.8547\n",
      "Epoch 326/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4319 - acc: 0.7893 - val_loss: 0.3627 - val_acc: 0.8715\n",
      "Epoch 327/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4235 - acc: 0.8174 - val_loss: 0.3781 - val_acc: 0.8436\n",
      "Epoch 328/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4051 - acc: 0.8132 - val_loss: 0.3681 - val_acc: 0.8436\n",
      "Epoch 329/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4330 - acc: 0.8104 - val_loss: 0.3741 - val_acc: 0.8492\n",
      "Epoch 330/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4189 - acc: 0.8076 - val_loss: 0.3758 - val_acc: 0.8715\n",
      "Epoch 331/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4324 - acc: 0.7963 - val_loss: 0.3624 - val_acc: 0.8436\n",
      "Epoch 332/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4263 - acc: 0.8076 - val_loss: 0.3596 - val_acc: 0.8492\n",
      "Epoch 333/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4207 - acc: 0.8062 - val_loss: 0.3652 - val_acc: 0.8436\n",
      "Epoch 334/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4392 - acc: 0.8076 - val_loss: 0.3697 - val_acc: 0.8492\n",
      "Epoch 335/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4280 - acc: 0.8146 - val_loss: 0.3755 - val_acc: 0.8547\n",
      "Epoch 336/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4189 - acc: 0.8132 - val_loss: 0.3619 - val_acc: 0.8547\n",
      "Epoch 337/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4184 - acc: 0.8188 - val_loss: 0.3512 - val_acc: 0.8715\n",
      "Epoch 338/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4165 - acc: 0.8132 - val_loss: 0.3791 - val_acc: 0.8492\n",
      "Epoch 339/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4176 - acc: 0.8048 - val_loss: 0.3790 - val_acc: 0.8436\n",
      "Epoch 340/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4173 - acc: 0.8118 - val_loss: 0.3723 - val_acc: 0.8827\n",
      "Epoch 341/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4212 - acc: 0.8118 - val_loss: 0.3538 - val_acc: 0.8547\n",
      "Epoch 342/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4292 - acc: 0.8104 - val_loss: 0.3723 - val_acc: 0.8547\n",
      "Epoch 343/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4114 - acc: 0.8160 - val_loss: 0.3672 - val_acc: 0.8547\n",
      "Epoch 344/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4359 - acc: 0.8090 - val_loss: 0.3815 - val_acc: 0.8492\n",
      "Epoch 345/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4257 - acc: 0.8104 - val_loss: 0.3776 - val_acc: 0.8492\n",
      "Epoch 346/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4245 - acc: 0.8104 - val_loss: 0.3622 - val_acc: 0.8603\n",
      "Epoch 347/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4384 - acc: 0.8006 - val_loss: 0.3720 - val_acc: 0.8715\n",
      "Epoch 348/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4188 - acc: 0.8104 - val_loss: 0.3568 - val_acc: 0.8492\n",
      "Epoch 349/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4227 - acc: 0.8020 - val_loss: 0.3579 - val_acc: 0.8771\n",
      "Epoch 350/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4305 - acc: 0.8174 - val_loss: 0.3785 - val_acc: 0.8436\n",
      "Epoch 351/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4200 - acc: 0.8174 - val_loss: 0.3817 - val_acc: 0.8492\n",
      "Epoch 352/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4336 - acc: 0.8062 - val_loss: 0.3659 - val_acc: 0.8547\n",
      "Epoch 353/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4184 - acc: 0.8146 - val_loss: 0.3859 - val_acc: 0.8436\n",
      "Epoch 354/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4210 - acc: 0.8062 - val_loss: 0.3629 - val_acc: 0.8603\n",
      "Epoch 355/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4115 - acc: 0.8020 - val_loss: 0.3579 - val_acc: 0.8659\n",
      "Epoch 356/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4228 - acc: 0.8020 - val_loss: 0.3492 - val_acc: 0.8547\n",
      "Epoch 357/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4196 - acc: 0.7992 - val_loss: 0.4130 - val_acc: 0.8436\n",
      "Epoch 358/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4300 - acc: 0.8118 - val_loss: 0.3778 - val_acc: 0.8492\n",
      "Epoch 359/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4270 - acc: 0.8006 - val_loss: 0.3599 - val_acc: 0.8547\n",
      "Epoch 360/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4207 - acc: 0.7992 - val_loss: 0.3794 - val_acc: 0.8492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4150 - acc: 0.8160 - val_loss: 0.3549 - val_acc: 0.8827\n",
      "Epoch 362/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4153 - acc: 0.8090 - val_loss: 0.3874 - val_acc: 0.8436\n",
      "Epoch 363/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4090 - acc: 0.8062 - val_loss: 0.3856 - val_acc: 0.8492\n",
      "Epoch 364/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4140 - acc: 0.8160 - val_loss: 0.3725 - val_acc: 0.8492\n",
      "Epoch 365/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4268 - acc: 0.8118 - val_loss: 0.3587 - val_acc: 0.8492\n",
      "Epoch 366/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4158 - acc: 0.8090 - val_loss: 0.3726 - val_acc: 0.8547\n",
      "Epoch 367/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4149 - acc: 0.7992 - val_loss: 0.3958 - val_acc: 0.8212\n",
      "Epoch 368/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4112 - acc: 0.8118 - val_loss: 0.3568 - val_acc: 0.8603\n",
      "Epoch 369/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.4107 - acc: 0.8132 - val_loss: 0.3627 - val_acc: 0.8715\n",
      "Epoch 370/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4151 - acc: 0.8230 - val_loss: 0.3538 - val_acc: 0.8659\n",
      "Epoch 371/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4124 - acc: 0.8146 - val_loss: 0.3538 - val_acc: 0.8715\n",
      "Epoch 372/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4049 - acc: 0.8132 - val_loss: 0.3687 - val_acc: 0.8547\n",
      "Epoch 373/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4170 - acc: 0.8118 - val_loss: 0.3647 - val_acc: 0.8492\n",
      "Epoch 374/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4292 - acc: 0.8118 - val_loss: 0.3701 - val_acc: 0.8771\n",
      "Epoch 375/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4352 - acc: 0.8104 - val_loss: 0.3724 - val_acc: 0.8603\n",
      "Epoch 376/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4065 - acc: 0.8174 - val_loss: 0.4071 - val_acc: 0.8268\n",
      "Epoch 377/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4277 - acc: 0.8104 - val_loss: 0.3480 - val_acc: 0.8827\n",
      "Epoch 378/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3995 - acc: 0.8244 - val_loss: 0.3592 - val_acc: 0.8659\n",
      "Epoch 379/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4194 - acc: 0.8118 - val_loss: 0.3814 - val_acc: 0.8547\n",
      "Epoch 380/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4273 - acc: 0.8062 - val_loss: 0.3832 - val_acc: 0.8547\n",
      "Epoch 381/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4089 - acc: 0.8258 - val_loss: 0.3503 - val_acc: 0.8715\n",
      "Epoch 382/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4269 - acc: 0.8104 - val_loss: 0.3861 - val_acc: 0.8436\n",
      "Epoch 383/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4146 - acc: 0.8258 - val_loss: 0.3586 - val_acc: 0.8715\n",
      "Epoch 384/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4327 - acc: 0.8160 - val_loss: 0.3914 - val_acc: 0.8547\n",
      "Epoch 385/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4216 - acc: 0.8090 - val_loss: 0.3819 - val_acc: 0.8380\n",
      "Epoch 386/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4136 - acc: 0.8076 - val_loss: 0.3885 - val_acc: 0.8436\n",
      "Epoch 387/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4206 - acc: 0.8174 - val_loss: 0.3639 - val_acc: 0.8547\n",
      "Epoch 388/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4117 - acc: 0.8160 - val_loss: 0.3967 - val_acc: 0.8547\n",
      "Epoch 389/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4216 - acc: 0.8216 - val_loss: 0.3602 - val_acc: 0.8547\n",
      "Epoch 390/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4149 - acc: 0.8202 - val_loss: 0.3839 - val_acc: 0.8268\n",
      "Epoch 391/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4167 - acc: 0.8160 - val_loss: 0.3575 - val_acc: 0.8715\n",
      "Epoch 392/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4246 - acc: 0.8048 - val_loss: 0.3494 - val_acc: 0.8659\n",
      "Epoch 393/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4100 - acc: 0.8132 - val_loss: 0.3940 - val_acc: 0.8436\n",
      "Epoch 394/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4344 - acc: 0.8034 - val_loss: 0.3522 - val_acc: 0.8492\n",
      "Epoch 395/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4141 - acc: 0.8090 - val_loss: 0.3556 - val_acc: 0.8603\n",
      "Epoch 396/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.4246 - acc: 0.8048 - val_loss: 0.3600 - val_acc: 0.8436\n",
      "Epoch 397/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4047 - acc: 0.8020 - val_loss: 0.3765 - val_acc: 0.8380\n",
      "Epoch 398/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4063 - acc: 0.8132 - val_loss: 0.3734 - val_acc: 0.8436\n",
      "Epoch 399/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4078 - acc: 0.8160 - val_loss: 0.3597 - val_acc: 0.8659\n",
      "Epoch 400/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4095 - acc: 0.8006 - val_loss: 0.3590 - val_acc: 0.8603\n",
      "Epoch 401/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4120 - acc: 0.8202 - val_loss: 0.3972 - val_acc: 0.8547\n",
      "Epoch 402/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4187 - acc: 0.8062 - val_loss: 0.3673 - val_acc: 0.8547\n",
      "Epoch 403/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4148 - acc: 0.8160 - val_loss: 0.3612 - val_acc: 0.8492\n",
      "Epoch 404/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4110 - acc: 0.8062 - val_loss: 0.3695 - val_acc: 0.8324\n",
      "Epoch 405/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4102 - acc: 0.8188 - val_loss: 0.3605 - val_acc: 0.8324\n",
      "Epoch 406/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4136 - acc: 0.8160 - val_loss: 0.3707 - val_acc: 0.8603\n",
      "Epoch 407/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4220 - acc: 0.8174 - val_loss: 0.3412 - val_acc: 0.8492\n",
      "Epoch 408/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4239 - acc: 0.8090 - val_loss: 0.3678 - val_acc: 0.8547\n",
      "Epoch 409/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3981 - acc: 0.8188 - val_loss: 0.3499 - val_acc: 0.8827\n",
      "Epoch 410/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4161 - acc: 0.8160 - val_loss: 0.3619 - val_acc: 0.8436\n",
      "Epoch 411/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4122 - acc: 0.8034 - val_loss: 0.3524 - val_acc: 0.8659\n",
      "Epoch 412/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4015 - acc: 0.8146 - val_loss: 0.3537 - val_acc: 0.8603\n",
      "Epoch 413/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4056 - acc: 0.8160 - val_loss: 0.3415 - val_acc: 0.8659\n",
      "Epoch 414/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4084 - acc: 0.8174 - val_loss: 0.3618 - val_acc: 0.8827\n",
      "Epoch 415/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4235 - acc: 0.8048 - val_loss: 0.3671 - val_acc: 0.8827\n",
      "Epoch 416/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4048 - acc: 0.8132 - val_loss: 0.3625 - val_acc: 0.8603\n",
      "Epoch 417/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3980 - acc: 0.8090 - val_loss: 0.3562 - val_acc: 0.8715\n",
      "Epoch 418/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4143 - acc: 0.8174 - val_loss: 0.3599 - val_acc: 0.8883\n",
      "Epoch 419/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4054 - acc: 0.8118 - val_loss: 0.3628 - val_acc: 0.8659\n",
      "Epoch 420/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3962 - acc: 0.8160 - val_loss: 0.3696 - val_acc: 0.8659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4125 - acc: 0.8160 - val_loss: 0.3652 - val_acc: 0.8547\n",
      "Epoch 422/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4081 - acc: 0.8090 - val_loss: 0.3727 - val_acc: 0.8380\n",
      "Epoch 423/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4132 - acc: 0.7921 - val_loss: 0.4112 - val_acc: 0.8156\n",
      "Epoch 424/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4089 - acc: 0.8244 - val_loss: 0.3673 - val_acc: 0.8659\n",
      "Epoch 425/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4123 - acc: 0.8174 - val_loss: 0.3458 - val_acc: 0.8547\n",
      "Epoch 426/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4208 - acc: 0.8357 - val_loss: 0.3727 - val_acc: 0.8268\n",
      "Epoch 427/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4193 - acc: 0.8272 - val_loss: 0.3620 - val_acc: 0.8603\n",
      "Epoch 428/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4038 - acc: 0.8174 - val_loss: 0.3672 - val_acc: 0.8492\n",
      "Epoch 429/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4062 - acc: 0.8118 - val_loss: 0.3552 - val_acc: 0.8492\n",
      "Epoch 430/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4038 - acc: 0.8160 - val_loss: 0.3572 - val_acc: 0.8659\n",
      "Epoch 431/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4120 - acc: 0.8146 - val_loss: 0.3517 - val_acc: 0.8603\n",
      "Epoch 432/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4167 - acc: 0.8146 - val_loss: 0.3622 - val_acc: 0.8547\n",
      "Epoch 433/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3961 - acc: 0.8174 - val_loss: 0.3525 - val_acc: 0.8659\n",
      "Epoch 434/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4084 - acc: 0.8188 - val_loss: 0.3494 - val_acc: 0.8771\n",
      "Epoch 435/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4050 - acc: 0.8202 - val_loss: 0.4193 - val_acc: 0.8492\n",
      "Epoch 436/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4094 - acc: 0.8160 - val_loss: 0.3642 - val_acc: 0.8659\n",
      "Epoch 437/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4077 - acc: 0.8076 - val_loss: 0.3478 - val_acc: 0.8827\n",
      "Epoch 438/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4122 - acc: 0.8090 - val_loss: 0.3556 - val_acc: 0.8603\n",
      "Epoch 439/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4097 - acc: 0.8160 - val_loss: 0.3621 - val_acc: 0.8380\n",
      "Epoch 440/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4110 - acc: 0.8118 - val_loss: 0.3800 - val_acc: 0.8324\n",
      "Epoch 441/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4021 - acc: 0.8244 - val_loss: 0.3605 - val_acc: 0.8492\n",
      "Epoch 442/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4068 - acc: 0.8132 - val_loss: 0.3589 - val_acc: 0.8547\n",
      "Epoch 443/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4250 - acc: 0.8146 - val_loss: 0.3834 - val_acc: 0.8492\n",
      "Epoch 444/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4204 - acc: 0.8048 - val_loss: 0.3580 - val_acc: 0.8547\n",
      "Epoch 445/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4079 - acc: 0.8216 - val_loss: 0.3927 - val_acc: 0.8380\n",
      "Epoch 446/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4038 - acc: 0.8188 - val_loss: 0.3553 - val_acc: 0.8659\n",
      "Epoch 447/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4038 - acc: 0.8188 - val_loss: 0.3565 - val_acc: 0.8827\n",
      "Epoch 448/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4107 - acc: 0.8160 - val_loss: 0.3756 - val_acc: 0.8771\n",
      "Epoch 449/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3992 - acc: 0.8062 - val_loss: 0.3634 - val_acc: 0.8659\n",
      "Epoch 450/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4201 - acc: 0.8104 - val_loss: 0.3641 - val_acc: 0.8380\n",
      "Epoch 451/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3999 - acc: 0.8258 - val_loss: 0.3742 - val_acc: 0.8380\n",
      "Epoch 452/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3913 - acc: 0.8343 - val_loss: 0.3792 - val_acc: 0.8380\n",
      "Epoch 453/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4054 - acc: 0.8202 - val_loss: 0.3582 - val_acc: 0.8436\n",
      "Epoch 454/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3984 - acc: 0.8357 - val_loss: 0.3974 - val_acc: 0.8212\n",
      "Epoch 455/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4176 - acc: 0.8132 - val_loss: 0.3975 - val_acc: 0.8436\n",
      "Epoch 456/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4021 - acc: 0.8188 - val_loss: 0.3922 - val_acc: 0.8436\n",
      "Epoch 457/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4187 - acc: 0.8006 - val_loss: 0.3727 - val_acc: 0.8436\n",
      "Epoch 458/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3991 - acc: 0.8104 - val_loss: 0.3956 - val_acc: 0.8380\n",
      "Epoch 459/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3954 - acc: 0.8230 - val_loss: 0.3488 - val_acc: 0.8659\n",
      "Epoch 460/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4157 - acc: 0.8188 - val_loss: 0.3594 - val_acc: 0.8436\n",
      "Epoch 461/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3981 - acc: 0.8216 - val_loss: 0.3747 - val_acc: 0.8492\n",
      "Epoch 462/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4115 - acc: 0.8048 - val_loss: 0.3412 - val_acc: 0.8547\n",
      "Epoch 463/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4050 - acc: 0.8076 - val_loss: 0.3581 - val_acc: 0.8436\n",
      "Epoch 464/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3901 - acc: 0.8160 - val_loss: 0.3874 - val_acc: 0.8380\n",
      "Epoch 465/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4042 - acc: 0.8034 - val_loss: 0.3965 - val_acc: 0.8268\n",
      "Epoch 466/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4090 - acc: 0.8020 - val_loss: 0.3717 - val_acc: 0.8436\n",
      "Epoch 467/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4026 - acc: 0.8132 - val_loss: 0.3544 - val_acc: 0.8380\n",
      "Epoch 468/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4044 - acc: 0.8104 - val_loss: 0.3496 - val_acc: 0.8492\n",
      "Epoch 469/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4174 - acc: 0.8062 - val_loss: 0.3502 - val_acc: 0.8380\n",
      "Epoch 470/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4085 - acc: 0.8174 - val_loss: 0.3662 - val_acc: 0.8436\n",
      "Epoch 471/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4089 - acc: 0.8048 - val_loss: 0.3496 - val_acc: 0.8547\n",
      "Epoch 472/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4068 - acc: 0.8174 - val_loss: 0.3431 - val_acc: 0.8771\n",
      "Epoch 473/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4103 - acc: 0.8188 - val_loss: 0.3501 - val_acc: 0.8715\n",
      "Epoch 474/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4090 - acc: 0.7978 - val_loss: 0.3608 - val_acc: 0.8547\n",
      "Epoch 475/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4091 - acc: 0.8090 - val_loss: 0.3606 - val_acc: 0.8380\n",
      "Epoch 476/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3941 - acc: 0.8216 - val_loss: 0.3413 - val_acc: 0.8827\n",
      "Epoch 477/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4119 - acc: 0.8104 - val_loss: 0.3552 - val_acc: 0.8715\n",
      "Epoch 478/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4132 - acc: 0.8076 - val_loss: 0.3521 - val_acc: 0.8547\n",
      "Epoch 479/1000\n",
      "712/712 [==============================] - 0s 30us/step - loss: 0.3893 - acc: 0.8202 - val_loss: 0.3727 - val_acc: 0.8547\n",
      "Epoch 480/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4176 - acc: 0.8146 - val_loss: 0.3703 - val_acc: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4106 - acc: 0.8132 - val_loss: 0.3507 - val_acc: 0.8603\n",
      "Epoch 482/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4064 - acc: 0.8020 - val_loss: 0.3529 - val_acc: 0.8715\n",
      "Epoch 483/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4045 - acc: 0.8076 - val_loss: 0.3781 - val_acc: 0.8492\n",
      "Epoch 484/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4026 - acc: 0.8160 - val_loss: 0.3599 - val_acc: 0.8771\n",
      "Epoch 485/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4134 - acc: 0.8034 - val_loss: 0.3740 - val_acc: 0.8436\n",
      "Epoch 486/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4115 - acc: 0.8244 - val_loss: 0.3554 - val_acc: 0.8715\n",
      "Epoch 487/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4200 - acc: 0.8160 - val_loss: 0.3608 - val_acc: 0.8436\n",
      "Epoch 488/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4161 - acc: 0.7992 - val_loss: 0.3944 - val_acc: 0.8436\n",
      "Epoch 489/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3920 - acc: 0.8230 - val_loss: 0.3509 - val_acc: 0.8603\n",
      "Epoch 490/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4040 - acc: 0.8146 - val_loss: 0.3549 - val_acc: 0.8827\n",
      "Epoch 491/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4118 - acc: 0.8146 - val_loss: 0.3687 - val_acc: 0.8436\n",
      "Epoch 492/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4105 - acc: 0.8034 - val_loss: 0.3618 - val_acc: 0.8436\n",
      "Epoch 493/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4045 - acc: 0.8062 - val_loss: 0.3728 - val_acc: 0.8380\n",
      "Epoch 494/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4017 - acc: 0.8076 - val_loss: 0.3475 - val_acc: 0.8547\n",
      "Epoch 495/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3990 - acc: 0.8258 - val_loss: 0.3681 - val_acc: 0.8492\n",
      "Epoch 496/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3161 - acc: 0.843 - 0s 32us/step - loss: 0.3899 - acc: 0.8132 - val_loss: 0.3999 - val_acc: 0.8436\n",
      "Epoch 497/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4022 - acc: 0.8188 - val_loss: 0.3679 - val_acc: 0.8492\n",
      "Epoch 498/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4013 - acc: 0.8132 - val_loss: 0.3569 - val_acc: 0.8547\n",
      "Epoch 499/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3934 - acc: 0.8244 - val_loss: 0.3608 - val_acc: 0.8436\n",
      "Epoch 500/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4056 - acc: 0.8090 - val_loss: 0.3631 - val_acc: 0.8436\n",
      "Epoch 501/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4142 - acc: 0.8076 - val_loss: 0.3688 - val_acc: 0.8547\n",
      "Epoch 502/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3969 - acc: 0.8202 - val_loss: 0.3494 - val_acc: 0.8659\n",
      "Epoch 503/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4000 - acc: 0.8006 - val_loss: 0.3982 - val_acc: 0.8380\n",
      "Epoch 504/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3944 - acc: 0.8090 - val_loss: 0.3434 - val_acc: 0.8659\n",
      "Epoch 505/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3884 - acc: 0.8230 - val_loss: 0.3592 - val_acc: 0.8492\n",
      "Epoch 506/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4106 - acc: 0.8146 - val_loss: 0.3505 - val_acc: 0.8827\n",
      "Epoch 507/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4114 - acc: 0.8216 - val_loss: 0.3645 - val_acc: 0.8492\n",
      "Epoch 508/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4188 - acc: 0.7963 - val_loss: 0.3841 - val_acc: 0.8380\n",
      "Epoch 509/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4099 - acc: 0.7978 - val_loss: 0.3474 - val_acc: 0.8715\n",
      "Epoch 510/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4023 - acc: 0.8216 - val_loss: 0.3557 - val_acc: 0.8492\n",
      "Epoch 511/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4029 - acc: 0.8118 - val_loss: 0.3623 - val_acc: 0.8715\n",
      "Epoch 512/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3864 - acc: 0.8202 - val_loss: 0.3429 - val_acc: 0.8771\n",
      "Epoch 513/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4068 - acc: 0.7992 - val_loss: 0.3546 - val_acc: 0.8547\n",
      "Epoch 514/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3941 - acc: 0.8202 - val_loss: 0.3770 - val_acc: 0.8436\n",
      "Epoch 515/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4032 - acc: 0.8034 - val_loss: 0.3638 - val_acc: 0.8436\n",
      "Epoch 516/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4040 - acc: 0.8132 - val_loss: 0.3571 - val_acc: 0.8771\n",
      "Epoch 517/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3935 - acc: 0.8216 - val_loss: 0.3385 - val_acc: 0.8827\n",
      "Epoch 518/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4137 - acc: 0.8160 - val_loss: 0.3602 - val_acc: 0.8547\n",
      "Epoch 519/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4091 - acc: 0.8132 - val_loss: 0.3401 - val_acc: 0.8771\n",
      "Epoch 520/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3948 - acc: 0.8188 - val_loss: 0.3455 - val_acc: 0.8659\n",
      "Epoch 521/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3746 - acc: 0.8216 - val_loss: 0.3368 - val_acc: 0.8883\n",
      "Epoch 522/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4115 - acc: 0.8104 - val_loss: 0.3602 - val_acc: 0.8492\n",
      "Epoch 523/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3917 - acc: 0.8188 - val_loss: 0.3792 - val_acc: 0.8659\n",
      "Epoch 524/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3966 - acc: 0.8329 - val_loss: 0.3706 - val_acc: 0.8492\n",
      "Epoch 525/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4001 - acc: 0.8062 - val_loss: 0.3492 - val_acc: 0.8771\n",
      "Epoch 526/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4030 - acc: 0.8146 - val_loss: 0.3511 - val_acc: 0.8827\n",
      "Epoch 527/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3888 - acc: 0.8118 - val_loss: 0.3387 - val_acc: 0.8883\n",
      "Epoch 528/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4005 - acc: 0.8216 - val_loss: 0.3412 - val_acc: 0.8827\n",
      "Epoch 529/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3999 - acc: 0.8090 - val_loss: 0.3603 - val_acc: 0.8492\n",
      "Epoch 530/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3940 - acc: 0.8006 - val_loss: 0.3540 - val_acc: 0.8436\n",
      "Epoch 531/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3993 - acc: 0.8216 - val_loss: 0.3624 - val_acc: 0.8547\n",
      "Epoch 532/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4038 - acc: 0.8104 - val_loss: 0.3769 - val_acc: 0.8436\n",
      "Epoch 533/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4145 - acc: 0.8174 - val_loss: 0.3402 - val_acc: 0.8715\n",
      "Epoch 534/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3909 - acc: 0.8357 - val_loss: 0.3541 - val_acc: 0.8715\n",
      "Epoch 535/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4086 - acc: 0.8216 - val_loss: 0.3932 - val_acc: 0.8492\n",
      "Epoch 536/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3817 - acc: 0.8287 - val_loss: 0.3709 - val_acc: 0.8715\n",
      "Epoch 537/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3936 - acc: 0.8272 - val_loss: 0.3821 - val_acc: 0.8603\n",
      "Epoch 538/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4066 - acc: 0.8020 - val_loss: 0.3865 - val_acc: 0.8436\n",
      "Epoch 539/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3971 - acc: 0.8174 - val_loss: 0.3440 - val_acc: 0.8603\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 36us/step - loss: 0.3923 - acc: 0.8244 - val_loss: 0.3457 - val_acc: 0.8492\n",
      "Epoch 541/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4285 - acc: 0.8104 - val_loss: 0.3858 - val_acc: 0.8436\n",
      "Epoch 542/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4027 - acc: 0.8006 - val_loss: 0.3587 - val_acc: 0.8492\n",
      "Epoch 543/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3875 - acc: 0.8329 - val_loss: 0.3456 - val_acc: 0.8771\n",
      "Epoch 544/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4144 - acc: 0.8174 - val_loss: 0.3378 - val_acc: 0.8659\n",
      "Epoch 545/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4010 - acc: 0.8315 - val_loss: 0.3448 - val_acc: 0.8771\n",
      "Epoch 546/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3932 - acc: 0.8258 - val_loss: 0.3625 - val_acc: 0.8547\n",
      "Epoch 547/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4046 - acc: 0.8258 - val_loss: 0.3610 - val_acc: 0.8659\n",
      "Epoch 548/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3989 - acc: 0.8244 - val_loss: 0.3636 - val_acc: 0.8547\n",
      "Epoch 549/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3887 - acc: 0.8160 - val_loss: 0.3551 - val_acc: 0.8436\n",
      "Epoch 550/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3898 - acc: 0.8343 - val_loss: 0.3700 - val_acc: 0.8380\n",
      "Epoch 551/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4036 - acc: 0.8230 - val_loss: 0.3430 - val_acc: 0.8547\n",
      "Epoch 552/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3991 - acc: 0.8244 - val_loss: 0.3771 - val_acc: 0.8380\n",
      "Epoch 553/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3924 - acc: 0.8104 - val_loss: 0.3386 - val_acc: 0.8827\n",
      "Epoch 554/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3926 - acc: 0.8244 - val_loss: 0.3482 - val_acc: 0.8939\n",
      "Epoch 555/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3917 - acc: 0.8371 - val_loss: 0.3835 - val_acc: 0.8492\n",
      "Epoch 556/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4126 - acc: 0.8160 - val_loss: 0.3805 - val_acc: 0.8268\n",
      "Epoch 557/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4012 - acc: 0.8160 - val_loss: 0.3566 - val_acc: 0.8436\n",
      "Epoch 558/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3869 - acc: 0.8329 - val_loss: 0.3883 - val_acc: 0.8547\n",
      "Epoch 559/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4207 - acc: 0.8230 - val_loss: 0.3893 - val_acc: 0.8492\n",
      "Epoch 560/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3917 - acc: 0.8301 - val_loss: 0.3456 - val_acc: 0.8715\n",
      "Epoch 561/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4032 - acc: 0.8104 - val_loss: 0.3733 - val_acc: 0.8436\n",
      "Epoch 562/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3969 - acc: 0.8258 - val_loss: 0.3386 - val_acc: 0.8659\n",
      "Epoch 563/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4029 - acc: 0.8188 - val_loss: 0.3761 - val_acc: 0.8324\n",
      "Epoch 564/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.3976 - acc: 0.8258 - val_loss: 0.3705 - val_acc: 0.8212\n",
      "Epoch 565/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3915 - acc: 0.8244 - val_loss: 0.3596 - val_acc: 0.8436\n",
      "Epoch 566/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3965 - acc: 0.8258 - val_loss: 0.3361 - val_acc: 0.8492\n",
      "Epoch 567/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3911 - acc: 0.8343 - val_loss: 0.3555 - val_acc: 0.8492\n",
      "Epoch 568/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3919 - acc: 0.8385 - val_loss: 0.3688 - val_acc: 0.8324\n",
      "Epoch 569/1000\n",
      "712/712 [==============================] - 0s 43us/step - loss: 0.3946 - acc: 0.8118 - val_loss: 0.3678 - val_acc: 0.8492\n",
      "Epoch 570/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3891 - acc: 0.8272 - val_loss: 0.3849 - val_acc: 0.8492\n",
      "Epoch 571/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4129 - acc: 0.8202 - val_loss: 0.3680 - val_acc: 0.8380\n",
      "Epoch 572/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.3885 - acc: 0.8118 - val_loss: 0.3793 - val_acc: 0.8492\n",
      "Epoch 573/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4184 - acc: 0.8118 - val_loss: 0.3635 - val_acc: 0.8380\n",
      "Epoch 574/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3931 - acc: 0.8258 - val_loss: 0.3663 - val_acc: 0.8492\n",
      "Epoch 575/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4014 - acc: 0.8287 - val_loss: 0.3483 - val_acc: 0.8771\n",
      "Epoch 576/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3994 - acc: 0.8272 - val_loss: 0.3629 - val_acc: 0.8547\n",
      "Epoch 577/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3892 - acc: 0.8146 - val_loss: 0.3505 - val_acc: 0.8547\n",
      "Epoch 578/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3843 - acc: 0.8244 - val_loss: 0.3843 - val_acc: 0.8268\n",
      "Epoch 579/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3985 - acc: 0.8315 - val_loss: 0.3656 - val_acc: 0.8547\n",
      "Epoch 580/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3930 - acc: 0.8188 - val_loss: 0.3561 - val_acc: 0.8436\n",
      "Epoch 581/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4088 - acc: 0.8174 - val_loss: 0.3627 - val_acc: 0.8547\n",
      "Epoch 582/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3978 - acc: 0.8188 - val_loss: 0.3960 - val_acc: 0.8324\n",
      "Epoch 583/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4112 - acc: 0.8132 - val_loss: 0.3727 - val_acc: 0.8268\n",
      "Epoch 584/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4005 - acc: 0.8216 - val_loss: 0.3794 - val_acc: 0.8380\n",
      "Epoch 585/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4062 - acc: 0.8202 - val_loss: 0.3444 - val_acc: 0.8771\n",
      "Epoch 586/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3939 - acc: 0.8230 - val_loss: 0.3712 - val_acc: 0.8603\n",
      "Epoch 587/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3881 - acc: 0.8258 - val_loss: 0.3596 - val_acc: 0.8436\n",
      "Epoch 588/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3947 - acc: 0.8329 - val_loss: 0.3829 - val_acc: 0.8380\n",
      "Epoch 589/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4080 - acc: 0.8118 - val_loss: 0.3522 - val_acc: 0.8547\n",
      "Epoch 590/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4012 - acc: 0.8244 - val_loss: 0.3569 - val_acc: 0.8492\n",
      "Epoch 591/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4051 - acc: 0.8104 - val_loss: 0.3506 - val_acc: 0.8603\n",
      "Epoch 592/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3880 - acc: 0.8287 - val_loss: 0.3488 - val_acc: 0.8771\n",
      "Epoch 593/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3991 - acc: 0.8272 - val_loss: 0.3965 - val_acc: 0.8380\n",
      "Epoch 594/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3974 - acc: 0.8216 - val_loss: 0.3709 - val_acc: 0.8547\n",
      "Epoch 595/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4032 - acc: 0.8216 - val_loss: 0.3647 - val_acc: 0.8492\n",
      "Epoch 596/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3867 - acc: 0.8287 - val_loss: 0.3546 - val_acc: 0.8603\n",
      "Epoch 597/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3999 - acc: 0.8301 - val_loss: 0.3863 - val_acc: 0.8436\n",
      "Epoch 598/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3804 - acc: 0.8357 - val_loss: 0.3648 - val_acc: 0.8268\n",
      "Epoch 599/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4067 - acc: 0.8118 - val_loss: 0.3415 - val_acc: 0.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3968 - acc: 0.8230 - val_loss: 0.3676 - val_acc: 0.8212\n",
      "Epoch 601/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3811 - acc: 0.8287 - val_loss: 0.3601 - val_acc: 0.8436\n",
      "Epoch 602/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3886 - acc: 0.8301 - val_loss: 0.3834 - val_acc: 0.8324\n",
      "Epoch 603/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4010 - acc: 0.8090 - val_loss: 0.3458 - val_acc: 0.8659\n",
      "Epoch 604/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4043 - acc: 0.8174 - val_loss: 0.3377 - val_acc: 0.8659\n",
      "Epoch 605/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3997 - acc: 0.8258 - val_loss: 0.3307 - val_acc: 0.8659\n",
      "Epoch 606/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3977 - acc: 0.8216 - val_loss: 0.3643 - val_acc: 0.8603\n",
      "Epoch 607/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3942 - acc: 0.8371 - val_loss: 0.3456 - val_acc: 0.8492\n",
      "Epoch 608/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3843 - acc: 0.8371 - val_loss: 0.3515 - val_acc: 0.8492\n",
      "Epoch 609/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3916 - acc: 0.8357 - val_loss: 0.3402 - val_acc: 0.8715\n",
      "Epoch 610/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3993 - acc: 0.8287 - val_loss: 0.3573 - val_acc: 0.8603\n",
      "Epoch 611/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4058 - acc: 0.8244 - val_loss: 0.3580 - val_acc: 0.8603\n",
      "Epoch 612/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3925 - acc: 0.8343 - val_loss: 0.3912 - val_acc: 0.8771\n",
      "Epoch 613/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3831 - acc: 0.8301 - val_loss: 0.3457 - val_acc: 0.8603\n",
      "Epoch 614/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4030 - acc: 0.8090 - val_loss: 0.3543 - val_acc: 0.8603\n",
      "Epoch 615/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3778 - acc: 0.8385 - val_loss: 0.3533 - val_acc: 0.8603\n",
      "Epoch 616/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3909 - acc: 0.8118 - val_loss: 0.3556 - val_acc: 0.8603\n",
      "Epoch 617/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4009 - acc: 0.8371 - val_loss: 0.4121 - val_acc: 0.8212\n",
      "Epoch 618/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3836 - acc: 0.8371 - val_loss: 0.3507 - val_acc: 0.8603\n",
      "Epoch 619/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3978 - acc: 0.8244 - val_loss: 0.3397 - val_acc: 0.8436\n",
      "Epoch 620/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3924 - acc: 0.8329 - val_loss: 0.3817 - val_acc: 0.8603\n",
      "Epoch 621/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4174 - acc: 0.8174 - val_loss: 0.3593 - val_acc: 0.8659\n",
      "Epoch 622/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3925 - acc: 0.8272 - val_loss: 0.3583 - val_acc: 0.8436\n",
      "Epoch 623/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3821 - acc: 0.8399 - val_loss: 0.3715 - val_acc: 0.8492\n",
      "Epoch 624/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3940 - acc: 0.8160 - val_loss: 0.3453 - val_acc: 0.8603\n",
      "Epoch 625/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3858 - acc: 0.8329 - val_loss: 0.3613 - val_acc: 0.8547\n",
      "Epoch 626/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3969 - acc: 0.8202 - val_loss: 0.3314 - val_acc: 0.8771\n",
      "Epoch 627/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3952 - acc: 0.8371 - val_loss: 0.3819 - val_acc: 0.8436\n",
      "Epoch 628/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4003 - acc: 0.8357 - val_loss: 0.3360 - val_acc: 0.8715\n",
      "Epoch 629/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3871 - acc: 0.8216 - val_loss: 0.3529 - val_acc: 0.8659\n",
      "Epoch 630/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3889 - acc: 0.8244 - val_loss: 0.3665 - val_acc: 0.8547\n",
      "Epoch 631/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3936 - acc: 0.8202 - val_loss: 0.3560 - val_acc: 0.8492\n",
      "Epoch 632/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3875 - acc: 0.8413 - val_loss: 0.3211 - val_acc: 0.8659\n",
      "Epoch 633/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3938 - acc: 0.8413 - val_loss: 0.3568 - val_acc: 0.8492\n",
      "Epoch 634/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3890 - acc: 0.8287 - val_loss: 0.3596 - val_acc: 0.8380\n",
      "Epoch 635/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3889 - acc: 0.8146 - val_loss: 0.3681 - val_acc: 0.8547\n",
      "Epoch 636/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3981 - acc: 0.8160 - val_loss: 0.3696 - val_acc: 0.8324\n",
      "Epoch 637/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3918 - acc: 0.8343 - val_loss: 0.3714 - val_acc: 0.8436\n",
      "Epoch 638/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3979 - acc: 0.8132 - val_loss: 0.3652 - val_acc: 0.8492\n",
      "Epoch 639/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3923 - acc: 0.8315 - val_loss: 0.3540 - val_acc: 0.8547\n",
      "Epoch 640/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3898 - acc: 0.8244 - val_loss: 0.3609 - val_acc: 0.8436\n",
      "Epoch 641/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3900 - acc: 0.8146 - val_loss: 0.3905 - val_acc: 0.8603\n",
      "Epoch 642/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3784 - acc: 0.8343 - val_loss: 0.3251 - val_acc: 0.8715\n",
      "Epoch 643/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3778 - acc: 0.8315 - val_loss: 0.3313 - val_acc: 0.8492\n",
      "Epoch 644/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3920 - acc: 0.8399 - val_loss: 0.3889 - val_acc: 0.8380\n",
      "Epoch 645/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.4023 - acc: 0.8174 - val_loss: 0.3593 - val_acc: 0.8380\n",
      "Epoch 646/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3851 - acc: 0.8413 - val_loss: 0.3387 - val_acc: 0.8603\n",
      "Epoch 647/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3888 - acc: 0.8287 - val_loss: 0.3601 - val_acc: 0.8492\n",
      "Epoch 648/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3860 - acc: 0.8272 - val_loss: 0.3656 - val_acc: 0.8436\n",
      "Epoch 649/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3795 - acc: 0.8244 - val_loss: 0.3492 - val_acc: 0.8324\n",
      "Epoch 650/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4025 - acc: 0.8216 - val_loss: 0.3863 - val_acc: 0.8436\n",
      "Epoch 651/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4037 - acc: 0.8188 - val_loss: 0.3419 - val_acc: 0.8380\n",
      "Epoch 652/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.3840 - acc: 0.8315 - val_loss: 0.3593 - val_acc: 0.8659\n",
      "Epoch 653/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3784 - acc: 0.8315 - val_loss: 0.3795 - val_acc: 0.7989\n",
      "Epoch 654/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.4085 - acc: 0.8048 - val_loss: 0.3482 - val_acc: 0.8492\n",
      "Epoch 655/1000\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.3859 - acc: 0.8357 - val_loss: 0.3342 - val_acc: 0.8603\n",
      "Epoch 656/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3806 - acc: 0.8399 - val_loss: 0.3358 - val_acc: 0.8659\n",
      "Epoch 657/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.3854 - acc: 0.8343 - val_loss: 0.3387 - val_acc: 0.8603\n",
      "Epoch 658/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3867 - acc: 0.8188 - val_loss: 0.3348 - val_acc: 0.8659\n",
      "Epoch 659/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3901 - acc: 0.8244 - val_loss: 0.3476 - val_acc: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3863 - acc: 0.8272 - val_loss: 0.3549 - val_acc: 0.8324\n",
      "Epoch 661/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3945 - acc: 0.8343 - val_loss: 0.3721 - val_acc: 0.8212\n",
      "Epoch 662/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3979 - acc: 0.8272 - val_loss: 0.3864 - val_acc: 0.8547\n",
      "Epoch 663/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3902 - acc: 0.8371 - val_loss: 0.3472 - val_acc: 0.8324\n",
      "Epoch 664/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3848 - acc: 0.8146 - val_loss: 0.3587 - val_acc: 0.8380\n",
      "Epoch 665/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.3875 - acc: 0.8188 - val_loss: 0.3549 - val_acc: 0.8436\n",
      "Epoch 666/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3852 - acc: 0.8427 - val_loss: 0.3827 - val_acc: 0.8212\n",
      "Epoch 667/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4039 - acc: 0.8258 - val_loss: 0.3844 - val_acc: 0.8212\n",
      "Epoch 668/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3811 - acc: 0.8301 - val_loss: 0.3844 - val_acc: 0.8212\n",
      "Epoch 669/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4015 - acc: 0.8258 - val_loss: 0.3867 - val_acc: 0.8324\n",
      "Epoch 670/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3752 - acc: 0.8315 - val_loss: 0.4071 - val_acc: 0.8101\n",
      "Epoch 671/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3916 - acc: 0.8385 - val_loss: 0.3479 - val_acc: 0.8603\n",
      "Epoch 672/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4012 - acc: 0.8258 - val_loss: 0.3799 - val_acc: 0.8324\n",
      "Epoch 673/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3952 - acc: 0.8244 - val_loss: 0.3732 - val_acc: 0.8436\n",
      "Epoch 674/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3882 - acc: 0.8399 - val_loss: 0.3521 - val_acc: 0.8268\n",
      "Epoch 675/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3889 - acc: 0.8371 - val_loss: 0.3581 - val_acc: 0.8268\n",
      "Epoch 676/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3943 - acc: 0.8216 - val_loss: 0.3726 - val_acc: 0.8324\n",
      "Epoch 677/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3944 - acc: 0.8329 - val_loss: 0.3306 - val_acc: 0.8771\n",
      "Epoch 678/1000\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.3992 - acc: 0.8062 - val_loss: 0.3809 - val_acc: 0.8659\n",
      "Epoch 679/1000\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.3903 - acc: 0.8441 - val_loss: 0.3948 - val_acc: 0.8436\n",
      "Epoch 680/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3915 - acc: 0.8132 - val_loss: 0.3550 - val_acc: 0.8492\n",
      "Epoch 681/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3947 - acc: 0.8287 - val_loss: 0.3767 - val_acc: 0.8547\n",
      "Epoch 682/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3959 - acc: 0.8371 - val_loss: 0.3843 - val_acc: 0.8436\n",
      "Epoch 683/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3924 - acc: 0.8315 - val_loss: 0.3755 - val_acc: 0.8547\n",
      "Epoch 684/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3993 - acc: 0.8301 - val_loss: 0.3608 - val_acc: 0.8547\n",
      "Epoch 685/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3880 - acc: 0.8230 - val_loss: 0.3535 - val_acc: 0.8547\n",
      "Epoch 686/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3983 - acc: 0.8287 - val_loss: 0.3646 - val_acc: 0.8659\n",
      "Epoch 687/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3937 - acc: 0.8301 - val_loss: 0.3509 - val_acc: 0.8659\n",
      "Epoch 688/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3807 - acc: 0.8357 - val_loss: 0.3531 - val_acc: 0.8436\n",
      "Epoch 689/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3891 - acc: 0.8371 - val_loss: 0.3431 - val_acc: 0.8492\n",
      "Epoch 690/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3823 - acc: 0.8399 - val_loss: 0.3815 - val_acc: 0.8603\n",
      "Epoch 691/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3970 - acc: 0.8371 - val_loss: 0.3664 - val_acc: 0.8603\n",
      "Epoch 692/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3969 - acc: 0.8315 - val_loss: 0.3680 - val_acc: 0.8436\n",
      "Epoch 693/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3811 - acc: 0.8427 - val_loss: 0.3299 - val_acc: 0.8547\n",
      "Epoch 694/1000\n",
      "712/712 [==============================] - 0s 30us/step - loss: 0.3860 - acc: 0.8202 - val_loss: 0.3417 - val_acc: 0.8380\n",
      "Epoch 695/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.4001 - acc: 0.8272 - val_loss: 0.3481 - val_acc: 0.8492\n",
      "Epoch 696/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3798 - acc: 0.8413 - val_loss: 0.3424 - val_acc: 0.8547\n",
      "Epoch 697/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8244 - val_loss: 0.3833 - val_acc: 0.8268\n",
      "Epoch 698/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3831 - acc: 0.8287 - val_loss: 0.3556 - val_acc: 0.8324\n",
      "Epoch 699/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3807 - acc: 0.8371 - val_loss: 0.3709 - val_acc: 0.8212\n",
      "Epoch 700/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3877 - acc: 0.8174 - val_loss: 0.3617 - val_acc: 0.8436\n",
      "Epoch 701/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3882 - acc: 0.8329 - val_loss: 0.3598 - val_acc: 0.8380\n",
      "Epoch 702/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3798 - acc: 0.8272 - val_loss: 0.3615 - val_acc: 0.8492\n",
      "Epoch 703/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3903 - acc: 0.8272 - val_loss: 0.3754 - val_acc: 0.8324\n",
      "Epoch 704/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3860 - acc: 0.8399 - val_loss: 0.3498 - val_acc: 0.8492\n",
      "Epoch 705/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3883 - acc: 0.8343 - val_loss: 0.3623 - val_acc: 0.8380\n",
      "Epoch 706/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3947 - acc: 0.8188 - val_loss: 0.3659 - val_acc: 0.8268\n",
      "Epoch 707/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3849 - acc: 0.8315 - val_loss: 0.3592 - val_acc: 0.8324\n",
      "Epoch 708/1000\n",
      "712/712 [==============================] - 0s 30us/step - loss: 0.3839 - acc: 0.8427 - val_loss: 0.3715 - val_acc: 0.8436\n",
      "Epoch 709/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3895 - acc: 0.8315 - val_loss: 0.3414 - val_acc: 0.8547\n",
      "Epoch 710/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3881 - acc: 0.8216 - val_loss: 0.3725 - val_acc: 0.8380\n",
      "Epoch 711/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4065 - acc: 0.8174 - val_loss: 0.3666 - val_acc: 0.8324\n",
      "Epoch 712/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3794 - acc: 0.8188 - val_loss: 0.3611 - val_acc: 0.8492\n",
      "Epoch 713/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3990 - acc: 0.8301 - val_loss: 0.3801 - val_acc: 0.8380\n",
      "Epoch 714/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3802 - acc: 0.8399 - val_loss: 0.3576 - val_acc: 0.8324\n",
      "Epoch 715/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3730 - acc: 0.8258 - val_loss: 0.3621 - val_acc: 0.8380\n",
      "Epoch 716/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3803 - acc: 0.8357 - val_loss: 0.3574 - val_acc: 0.8547\n",
      "Epoch 717/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3819 - acc: 0.8385 - val_loss: 0.3347 - val_acc: 0.8659\n",
      "Epoch 718/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3782 - acc: 0.8399 - val_loss: 0.3521 - val_acc: 0.8436\n",
      "Epoch 719/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3878 - acc: 0.8230 - val_loss: 0.3728 - val_acc: 0.8324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3928 - acc: 0.8104 - val_loss: 0.3637 - val_acc: 0.8380\n",
      "Epoch 721/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3760 - acc: 0.8315 - val_loss: 0.3485 - val_acc: 0.8603\n",
      "Epoch 722/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3813 - acc: 0.8385 - val_loss: 0.4163 - val_acc: 0.8268\n",
      "Epoch 723/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3854 - acc: 0.8160 - val_loss: 0.3606 - val_acc: 0.8324\n",
      "Epoch 724/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3757 - acc: 0.8357 - val_loss: 0.3518 - val_acc: 0.8380\n",
      "Epoch 725/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3916 - acc: 0.8287 - val_loss: 0.3794 - val_acc: 0.8436\n",
      "Epoch 726/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3859 - acc: 0.8413 - val_loss: 0.3862 - val_acc: 0.8380\n",
      "Epoch 727/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3944 - acc: 0.8230 - val_loss: 0.3822 - val_acc: 0.8324\n",
      "Epoch 728/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3835 - acc: 0.8174 - val_loss: 0.3570 - val_acc: 0.8492\n",
      "Epoch 729/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3913 - acc: 0.8132 - val_loss: 0.3502 - val_acc: 0.8547\n",
      "Epoch 730/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3802 - acc: 0.8413 - val_loss: 0.3756 - val_acc: 0.8436\n",
      "Epoch 731/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4077 - acc: 0.8301 - val_loss: 0.4135 - val_acc: 0.8324\n",
      "Epoch 732/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3877 - acc: 0.8160 - val_loss: 0.3943 - val_acc: 0.8547\n",
      "Epoch 733/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3882 - acc: 0.8160 - val_loss: 0.3418 - val_acc: 0.8659\n",
      "Epoch 734/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3803 - acc: 0.8258 - val_loss: 0.3381 - val_acc: 0.8715\n",
      "Epoch 735/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3773 - acc: 0.8385 - val_loss: 0.3568 - val_acc: 0.8547\n",
      "Epoch 736/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3805 - acc: 0.8272 - val_loss: 0.3425 - val_acc: 0.8492\n",
      "Epoch 737/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3759 - acc: 0.8427 - val_loss: 0.3784 - val_acc: 0.8547\n",
      "Epoch 738/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3883 - acc: 0.8399 - val_loss: 0.3799 - val_acc: 0.8380\n",
      "Epoch 739/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3751 - acc: 0.8315 - val_loss: 0.3676 - val_acc: 0.8659\n",
      "Epoch 740/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3800 - acc: 0.8301 - val_loss: 0.3683 - val_acc: 0.8547\n",
      "Epoch 741/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3972 - acc: 0.8216 - val_loss: 0.3530 - val_acc: 0.8547\n",
      "Epoch 742/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3873 - acc: 0.8343 - val_loss: 0.3413 - val_acc: 0.8436\n",
      "Epoch 743/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3833 - acc: 0.8385 - val_loss: 0.3485 - val_acc: 0.8436\n",
      "Epoch 744/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3828 - acc: 0.8371 - val_loss: 0.3504 - val_acc: 0.8547\n",
      "Epoch 745/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3744 - acc: 0.8385 - val_loss: 0.3826 - val_acc: 0.8603\n",
      "Epoch 746/1000\n",
      "712/712 [==============================] - 0s 30us/step - loss: 0.3875 - acc: 0.8258 - val_loss: 0.4026 - val_acc: 0.8268\n",
      "Epoch 747/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3844 - acc: 0.8202 - val_loss: 0.3402 - val_acc: 0.8547\n",
      "Epoch 748/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3984 - acc: 0.8118 - val_loss: 0.3415 - val_acc: 0.8436\n",
      "Epoch 749/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3834 - acc: 0.8329 - val_loss: 0.3362 - val_acc: 0.8603\n",
      "Epoch 750/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3797 - acc: 0.8357 - val_loss: 0.3570 - val_acc: 0.8603\n",
      "Epoch 751/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3812 - acc: 0.8343 - val_loss: 0.3501 - val_acc: 0.8547\n",
      "Epoch 752/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.4009 - acc: 0.8343 - val_loss: 0.3656 - val_acc: 0.8659\n",
      "Epoch 753/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3769 - acc: 0.8272 - val_loss: 0.3554 - val_acc: 0.8603\n",
      "Epoch 754/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3818 - acc: 0.8399 - val_loss: 0.4004 - val_acc: 0.8436\n",
      "Epoch 755/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3725 - acc: 0.8399 - val_loss: 0.3934 - val_acc: 0.8547\n",
      "Epoch 756/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3831 - acc: 0.8329 - val_loss: 0.3860 - val_acc: 0.8492\n",
      "Epoch 757/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3922 - acc: 0.8329 - val_loss: 0.3502 - val_acc: 0.8547\n",
      "Epoch 758/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3808 - acc: 0.8357 - val_loss: 0.4030 - val_acc: 0.8380\n",
      "Epoch 759/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3919 - acc: 0.8329 - val_loss: 0.3671 - val_acc: 0.8492\n",
      "Epoch 760/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3747 - acc: 0.8413 - val_loss: 0.3539 - val_acc: 0.8492\n",
      "Epoch 761/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3713 - acc: 0.8371 - val_loss: 0.3632 - val_acc: 0.8492\n",
      "Epoch 762/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3838 - acc: 0.8455 - val_loss: 0.3731 - val_acc: 0.8380\n",
      "Epoch 763/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3816 - acc: 0.8244 - val_loss: 0.3926 - val_acc: 0.8492\n",
      "Epoch 764/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3913 - acc: 0.8329 - val_loss: 0.3740 - val_acc: 0.8436\n",
      "Epoch 765/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3911 - acc: 0.8315 - val_loss: 0.3505 - val_acc: 0.8380\n",
      "Epoch 766/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3880 - acc: 0.8301 - val_loss: 0.3492 - val_acc: 0.8547\n",
      "Epoch 767/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3881 - acc: 0.8272 - val_loss: 0.3486 - val_acc: 0.8603\n",
      "Epoch 768/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3883 - acc: 0.8104 - val_loss: 0.3509 - val_acc: 0.8492\n",
      "Epoch 769/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3816 - acc: 0.8202 - val_loss: 0.3410 - val_acc: 0.8771\n",
      "Epoch 770/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3992 - acc: 0.8216 - val_loss: 0.3770 - val_acc: 0.8547\n",
      "Epoch 771/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3986 - acc: 0.8272 - val_loss: 0.3651 - val_acc: 0.8380\n",
      "Epoch 772/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3712 - acc: 0.8357 - val_loss: 0.3347 - val_acc: 0.8659\n",
      "Epoch 773/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3758 - acc: 0.8371 - val_loss: 0.3887 - val_acc: 0.8380\n",
      "Epoch 774/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3844 - acc: 0.8258 - val_loss: 0.3524 - val_acc: 0.8547\n",
      "Epoch 775/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3810 - acc: 0.8272 - val_loss: 0.4139 - val_acc: 0.8268\n",
      "Epoch 776/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3897 - acc: 0.8258 - val_loss: 0.3642 - val_acc: 0.8324\n",
      "Epoch 777/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3713 - acc: 0.8258 - val_loss: 0.3646 - val_acc: 0.8324\n",
      "Epoch 778/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3914 - acc: 0.8188 - val_loss: 0.3373 - val_acc: 0.8715\n",
      "Epoch 779/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3804 - acc: 0.8329 - val_loss: 0.3715 - val_acc: 0.8492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3844 - acc: 0.8272 - val_loss: 0.3333 - val_acc: 0.8715\n",
      "Epoch 781/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3825 - acc: 0.8427 - val_loss: 0.3378 - val_acc: 0.8492\n",
      "Epoch 782/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3893 - acc: 0.8272 - val_loss: 0.3376 - val_acc: 0.8492\n",
      "Epoch 783/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3730 - acc: 0.8315 - val_loss: 0.3800 - val_acc: 0.8268\n",
      "Epoch 784/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3803 - acc: 0.8357 - val_loss: 0.4557 - val_acc: 0.8268\n",
      "Epoch 785/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4083 - acc: 0.8329 - val_loss: 0.3647 - val_acc: 0.8268\n",
      "Epoch 786/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3781 - acc: 0.8511 - val_loss: 0.3389 - val_acc: 0.8547\n",
      "Epoch 787/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3678 - acc: 0.8413 - val_loss: 0.3612 - val_acc: 0.8547\n",
      "Epoch 788/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3723 - acc: 0.8427 - val_loss: 0.3591 - val_acc: 0.8603\n",
      "Epoch 789/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3762 - acc: 0.8427 - val_loss: 0.4033 - val_acc: 0.8156\n",
      "Epoch 790/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3815 - acc: 0.8483 - val_loss: 0.4202 - val_acc: 0.8268\n",
      "Epoch 791/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3782 - acc: 0.8427 - val_loss: 0.3500 - val_acc: 0.8380\n",
      "Epoch 792/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3855 - acc: 0.8301 - val_loss: 0.3360 - val_acc: 0.8492\n",
      "Epoch 793/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3805 - acc: 0.8230 - val_loss: 0.3188 - val_acc: 0.8771\n",
      "Epoch 794/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3847 - acc: 0.8230 - val_loss: 0.3582 - val_acc: 0.8603\n",
      "Epoch 795/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3780 - acc: 0.8385 - val_loss: 0.3449 - val_acc: 0.8547\n",
      "Epoch 796/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3622 - acc: 0.8497 - val_loss: 0.3455 - val_acc: 0.8771\n",
      "Epoch 797/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.4062 - acc: 0.8399 - val_loss: 0.3596 - val_acc: 0.8492\n",
      "Epoch 798/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3813 - acc: 0.8287 - val_loss: 0.3575 - val_acc: 0.8492\n",
      "Epoch 799/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3891 - acc: 0.8202 - val_loss: 0.3764 - val_acc: 0.8436\n",
      "Epoch 800/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3684 - acc: 0.8427 - val_loss: 0.3768 - val_acc: 0.8212\n",
      "Epoch 801/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3785 - acc: 0.8315 - val_loss: 0.3738 - val_acc: 0.8212\n",
      "Epoch 802/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3931 - acc: 0.8258 - val_loss: 0.3801 - val_acc: 0.8324\n",
      "Epoch 803/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3918 - acc: 0.8315 - val_loss: 0.3899 - val_acc: 0.8156\n",
      "Epoch 804/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3626 - acc: 0.8427 - val_loss: 0.3930 - val_acc: 0.8212\n",
      "Epoch 805/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3670 - acc: 0.8469 - val_loss: 0.3818 - val_acc: 0.8547\n",
      "Epoch 806/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3976 - acc: 0.8244 - val_loss: 0.3806 - val_acc: 0.8380\n",
      "Epoch 807/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3687 - acc: 0.8455 - val_loss: 0.4063 - val_acc: 0.7989\n",
      "Epoch 808/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3773 - acc: 0.8287 - val_loss: 0.3447 - val_acc: 0.8547\n",
      "Epoch 809/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3705 - acc: 0.8329 - val_loss: 0.3722 - val_acc: 0.8380\n",
      "Epoch 810/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3759 - acc: 0.8315 - val_loss: 0.3299 - val_acc: 0.8827\n",
      "Epoch 811/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3925 - acc: 0.8230 - val_loss: 0.4545 - val_acc: 0.8156\n",
      "Epoch 812/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3868 - acc: 0.8343 - val_loss: 0.3619 - val_acc: 0.8324\n",
      "Epoch 813/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3634 - acc: 0.8371 - val_loss: 0.3526 - val_acc: 0.8492\n",
      "Epoch 814/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3754 - acc: 0.8483 - val_loss: 0.3602 - val_acc: 0.8436\n",
      "Epoch 815/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3869 - acc: 0.8357 - val_loss: 0.3805 - val_acc: 0.8492\n",
      "Epoch 816/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3766 - acc: 0.8343 - val_loss: 0.3707 - val_acc: 0.8436\n",
      "Epoch 817/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3797 - acc: 0.8287 - val_loss: 0.3714 - val_acc: 0.8380\n",
      "Epoch 818/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3663 - acc: 0.8441 - val_loss: 0.3760 - val_acc: 0.8659\n",
      "Epoch 819/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3873 - acc: 0.8357 - val_loss: 0.3574 - val_acc: 0.8492\n",
      "Epoch 820/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3885 - acc: 0.8287 - val_loss: 0.3765 - val_acc: 0.8436\n",
      "Epoch 821/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3890 - acc: 0.8329 - val_loss: 0.4061 - val_acc: 0.8436\n",
      "Epoch 822/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3770 - acc: 0.8399 - val_loss: 0.3775 - val_acc: 0.8156\n",
      "Epoch 823/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3835 - acc: 0.8315 - val_loss: 0.3711 - val_acc: 0.8436\n",
      "Epoch 824/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3799 - acc: 0.8301 - val_loss: 0.3599 - val_acc: 0.8659\n",
      "Epoch 825/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3775 - acc: 0.8287 - val_loss: 0.3805 - val_acc: 0.8380\n",
      "Epoch 826/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3666 - acc: 0.8469 - val_loss: 0.3788 - val_acc: 0.8380\n",
      "Epoch 827/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3836 - acc: 0.8371 - val_loss: 0.3800 - val_acc: 0.8212\n",
      "Epoch 828/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3716 - acc: 0.8413 - val_loss: 0.3663 - val_acc: 0.8547\n",
      "Epoch 829/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3777 - acc: 0.8343 - val_loss: 0.3773 - val_acc: 0.8492\n",
      "Epoch 830/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3888 - acc: 0.8174 - val_loss: 0.3423 - val_acc: 0.8771\n",
      "Epoch 831/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3700 - acc: 0.8357 - val_loss: 0.3537 - val_acc: 0.8715\n",
      "Epoch 832/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3772 - acc: 0.8329 - val_loss: 0.4034 - val_acc: 0.8212\n",
      "Epoch 833/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3819 - acc: 0.8301 - val_loss: 0.3441 - val_acc: 0.8492\n",
      "Epoch 834/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3691 - acc: 0.8357 - val_loss: 0.3823 - val_acc: 0.8380\n",
      "Epoch 835/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3700 - acc: 0.8469 - val_loss: 0.3592 - val_acc: 0.8547\n",
      "Epoch 836/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3787 - acc: 0.8385 - val_loss: 0.3653 - val_acc: 0.8380\n",
      "Epoch 837/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3943 - acc: 0.8188 - val_loss: 0.3439 - val_acc: 0.8547\n",
      "Epoch 838/1000\n",
      "712/712 [==============================] - 0s 29us/step - loss: 0.3886 - acc: 0.8202 - val_loss: 0.3781 - val_acc: 0.8380\n",
      "Epoch 839/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3606 - acc: 0.8469 - val_loss: 0.3459 - val_acc: 0.8659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3757 - acc: 0.8287 - val_loss: 0.3728 - val_acc: 0.8380\n",
      "Epoch 841/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3879 - acc: 0.8258 - val_loss: 0.3829 - val_acc: 0.8324\n",
      "Epoch 842/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3822 - acc: 0.8329 - val_loss: 0.3674 - val_acc: 0.8547\n",
      "Epoch 843/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3818 - acc: 0.8301 - val_loss: 0.3738 - val_acc: 0.8547\n",
      "Epoch 844/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3841 - acc: 0.8287 - val_loss: 0.3547 - val_acc: 0.8603\n",
      "Epoch 845/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3787 - acc: 0.8343 - val_loss: 0.3462 - val_acc: 0.8715\n",
      "Epoch 846/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3679 - acc: 0.8455 - val_loss: 0.3813 - val_acc: 0.8603\n",
      "Epoch 847/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3840 - acc: 0.8427 - val_loss: 0.3599 - val_acc: 0.8547\n",
      "Epoch 848/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3812 - acc: 0.8244 - val_loss: 0.3494 - val_acc: 0.8547\n",
      "Epoch 849/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3869 - acc: 0.8315 - val_loss: 0.3690 - val_acc: 0.8659\n",
      "Epoch 850/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3790 - acc: 0.8287 - val_loss: 0.3436 - val_acc: 0.8715\n",
      "Epoch 851/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3783 - acc: 0.8315 - val_loss: 0.3766 - val_acc: 0.8547\n",
      "Epoch 852/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3767 - acc: 0.8399 - val_loss: 0.3648 - val_acc: 0.8492\n",
      "Epoch 853/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3694 - acc: 0.8385 - val_loss: 0.3577 - val_acc: 0.8659\n",
      "Epoch 854/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3808 - acc: 0.8343 - val_loss: 0.3670 - val_acc: 0.8715\n",
      "Epoch 855/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3765 - acc: 0.8357 - val_loss: 0.3351 - val_acc: 0.8827\n",
      "Epoch 856/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3759 - acc: 0.8441 - val_loss: 0.4199 - val_acc: 0.8324\n",
      "Epoch 857/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3799 - acc: 0.8385 - val_loss: 0.3837 - val_acc: 0.8324\n",
      "Epoch 858/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3921 - acc: 0.8202 - val_loss: 0.3589 - val_acc: 0.8436\n",
      "Epoch 859/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3826 - acc: 0.8272 - val_loss: 0.3631 - val_acc: 0.8436\n",
      "Epoch 860/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3571 - acc: 0.8413 - val_loss: 0.3744 - val_acc: 0.8603\n",
      "Epoch 861/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3960 - acc: 0.8343 - val_loss: 0.3819 - val_acc: 0.8547\n",
      "Epoch 862/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3853 - acc: 0.8455 - val_loss: 0.3575 - val_acc: 0.8436\n",
      "Epoch 863/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3676 - acc: 0.8301 - val_loss: 0.3410 - val_acc: 0.8659\n",
      "Epoch 864/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3620 - acc: 0.8441 - val_loss: 0.4126 - val_acc: 0.8547\n",
      "Epoch 865/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3791 - acc: 0.8427 - val_loss: 0.3754 - val_acc: 0.8268\n",
      "Epoch 866/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3966 - acc: 0.8315 - val_loss: 0.3369 - val_acc: 0.8715\n",
      "Epoch 867/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3824 - acc: 0.8272 - val_loss: 0.3406 - val_acc: 0.8883\n",
      "Epoch 868/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3822 - acc: 0.8385 - val_loss: 0.3637 - val_acc: 0.8492\n",
      "Epoch 869/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3796 - acc: 0.8329 - val_loss: 0.3846 - val_acc: 0.8659\n",
      "Epoch 870/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3915 - acc: 0.8301 - val_loss: 0.3530 - val_acc: 0.8547\n",
      "Epoch 871/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3908 - acc: 0.8329 - val_loss: 0.3662 - val_acc: 0.8380\n",
      "Epoch 872/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3713 - acc: 0.8315 - val_loss: 0.3805 - val_acc: 0.8603\n",
      "Epoch 873/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3726 - acc: 0.8272 - val_loss: 0.3428 - val_acc: 0.8547\n",
      "Epoch 874/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3793 - acc: 0.8399 - val_loss: 0.3753 - val_acc: 0.8492\n",
      "Epoch 875/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3850 - acc: 0.8301 - val_loss: 0.3525 - val_acc: 0.8659\n",
      "Epoch 876/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3683 - acc: 0.8525 - val_loss: 0.3713 - val_acc: 0.8380\n",
      "Epoch 877/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3763 - acc: 0.8525 - val_loss: 0.3619 - val_acc: 0.8547\n",
      "Epoch 878/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3662 - acc: 0.8525 - val_loss: 0.3419 - val_acc: 0.8603\n",
      "Epoch 879/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3800 - acc: 0.8357 - val_loss: 0.3695 - val_acc: 0.8547\n",
      "Epoch 880/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3733 - acc: 0.8469 - val_loss: 0.3351 - val_acc: 0.8771\n",
      "Epoch 881/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3644 - acc: 0.8469 - val_loss: 0.3609 - val_acc: 0.8603\n",
      "Epoch 882/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3758 - acc: 0.8315 - val_loss: 0.3498 - val_acc: 0.8547\n",
      "Epoch 883/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3655 - acc: 0.8399 - val_loss: 0.4029 - val_acc: 0.8380\n",
      "Epoch 884/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3902 - acc: 0.8427 - val_loss: 0.3580 - val_acc: 0.8715\n",
      "Epoch 885/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3785 - acc: 0.8371 - val_loss: 0.3382 - val_acc: 0.8715\n",
      "Epoch 886/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3723 - acc: 0.8301 - val_loss: 0.3534 - val_acc: 0.8547\n",
      "Epoch 887/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3659 - acc: 0.8455 - val_loss: 0.3801 - val_acc: 0.8603\n",
      "Epoch 888/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3574 - acc: 0.8371 - val_loss: 0.3827 - val_acc: 0.8659\n",
      "Epoch 889/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3812 - acc: 0.8272 - val_loss: 0.3751 - val_acc: 0.8603\n",
      "Epoch 890/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3700 - acc: 0.8287 - val_loss: 0.3562 - val_acc: 0.8492\n",
      "Epoch 891/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3665 - acc: 0.8427 - val_loss: 0.3466 - val_acc: 0.8659\n",
      "Epoch 892/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.4035 - acc: 0.8132 - val_loss: 0.3694 - val_acc: 0.8492\n",
      "Epoch 893/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3683 - acc: 0.8385 - val_loss: 0.3855 - val_acc: 0.8268\n",
      "Epoch 894/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3838 - acc: 0.8301 - val_loss: 0.4090 - val_acc: 0.8324\n",
      "Epoch 895/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3794 - acc: 0.8357 - val_loss: 0.3735 - val_acc: 0.8603\n",
      "Epoch 896/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3728 - acc: 0.8287 - val_loss: 0.3712 - val_acc: 0.8492\n",
      "Epoch 897/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3883 - acc: 0.8230 - val_loss: 0.3766 - val_acc: 0.8324\n",
      "Epoch 898/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3684 - acc: 0.8399 - val_loss: 0.3666 - val_acc: 0.8492\n",
      "Epoch 899/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3864 - acc: 0.8301 - val_loss: 0.4434 - val_acc: 0.8045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3965 - acc: 0.8244 - val_loss: 0.3711 - val_acc: 0.8436\n",
      "Epoch 901/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3711 - acc: 0.8455 - val_loss: 0.4094 - val_acc: 0.8156\n",
      "Epoch 902/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3793 - acc: 0.8399 - val_loss: 0.3426 - val_acc: 0.8492\n",
      "Epoch 903/1000\n",
      "712/712 [==============================] - 0s 30us/step - loss: 0.3773 - acc: 0.8399 - val_loss: 0.3690 - val_acc: 0.8492\n",
      "Epoch 904/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3972 - acc: 0.8202 - val_loss: 0.3862 - val_acc: 0.8324\n",
      "Epoch 905/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3609 - acc: 0.8511 - val_loss: 0.3816 - val_acc: 0.8324\n",
      "Epoch 906/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3735 - acc: 0.8301 - val_loss: 0.3446 - val_acc: 0.8492\n",
      "Epoch 907/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3820 - acc: 0.8272 - val_loss: 0.3508 - val_acc: 0.8492\n",
      "Epoch 908/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3968 - acc: 0.8188 - val_loss: 0.3893 - val_acc: 0.8156\n",
      "Epoch 909/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3905 - acc: 0.8329 - val_loss: 0.3620 - val_acc: 0.8547\n",
      "Epoch 910/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3756 - acc: 0.8329 - val_loss: 0.3630 - val_acc: 0.8436\n",
      "Epoch 911/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3756 - acc: 0.8357 - val_loss: 0.3544 - val_acc: 0.8659\n",
      "Epoch 912/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3712 - acc: 0.8329 - val_loss: 0.3593 - val_acc: 0.8547\n",
      "Epoch 913/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3796 - acc: 0.8413 - val_loss: 0.3591 - val_acc: 0.8659\n",
      "Epoch 914/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3788 - acc: 0.8244 - val_loss: 0.3612 - val_acc: 0.8547\n",
      "Epoch 915/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3747 - acc: 0.8301 - val_loss: 0.3680 - val_acc: 0.8715\n",
      "Epoch 916/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3947 - acc: 0.8343 - val_loss: 0.3458 - val_acc: 0.8715\n",
      "Epoch 917/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3736 - acc: 0.8413 - val_loss: 0.3751 - val_acc: 0.8380\n",
      "Epoch 918/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3749 - acc: 0.8399 - val_loss: 0.3502 - val_acc: 0.8547\n",
      "Epoch 919/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3771 - acc: 0.8469 - val_loss: 0.3665 - val_acc: 0.8492\n",
      "Epoch 920/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3588 - acc: 0.8413 - val_loss: 0.3567 - val_acc: 0.8547\n",
      "Epoch 921/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3739 - acc: 0.8371 - val_loss: 0.3615 - val_acc: 0.8659\n",
      "Epoch 922/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3786 - acc: 0.8399 - val_loss: 0.3698 - val_acc: 0.8436\n",
      "Epoch 923/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3651 - acc: 0.8371 - val_loss: 0.3798 - val_acc: 0.8324\n",
      "Epoch 924/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3812 - acc: 0.8202 - val_loss: 0.3510 - val_acc: 0.8715\n",
      "Epoch 925/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3744 - acc: 0.8413 - val_loss: 0.3529 - val_acc: 0.8715\n",
      "Epoch 926/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3817 - acc: 0.8315 - val_loss: 0.3523 - val_acc: 0.8715\n",
      "Epoch 927/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3721 - acc: 0.8427 - val_loss: 0.3957 - val_acc: 0.8492\n",
      "Epoch 928/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3991 - acc: 0.8427 - val_loss: 0.3459 - val_acc: 0.8771\n",
      "Epoch 929/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3861 - acc: 0.8202 - val_loss: 0.3358 - val_acc: 0.8883\n",
      "Epoch 930/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3712 - acc: 0.8455 - val_loss: 0.3615 - val_acc: 0.8659\n",
      "Epoch 931/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3720 - acc: 0.8413 - val_loss: 0.3763 - val_acc: 0.8380\n",
      "Epoch 932/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3687 - acc: 0.8455 - val_loss: 0.3795 - val_acc: 0.8492\n",
      "Epoch 933/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3816 - acc: 0.8441 - val_loss: 0.3475 - val_acc: 0.8659\n",
      "Epoch 934/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3717 - acc: 0.8357 - val_loss: 0.4131 - val_acc: 0.8380\n",
      "Epoch 935/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3799 - acc: 0.8371 - val_loss: 0.3748 - val_acc: 0.8659\n",
      "Epoch 936/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3752 - acc: 0.8301 - val_loss: 0.3657 - val_acc: 0.8659\n",
      "Epoch 937/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3704 - acc: 0.8329 - val_loss: 0.3684 - val_acc: 0.8380\n",
      "Epoch 938/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3840 - acc: 0.8244 - val_loss: 0.3545 - val_acc: 0.8547\n",
      "Epoch 939/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3664 - acc: 0.8329 - val_loss: 0.3802 - val_acc: 0.8603\n",
      "Epoch 940/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3905 - acc: 0.8258 - val_loss: 0.3691 - val_acc: 0.8603\n",
      "Epoch 941/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3580 - acc: 0.8497 - val_loss: 0.3410 - val_acc: 0.8603\n",
      "Epoch 942/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3622 - acc: 0.8287 - val_loss: 0.3395 - val_acc: 0.8715\n",
      "Epoch 943/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3909 - acc: 0.8329 - val_loss: 0.3572 - val_acc: 0.8659\n",
      "Epoch 944/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3717 - acc: 0.8469 - val_loss: 0.3597 - val_acc: 0.8659\n",
      "Epoch 945/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3811 - acc: 0.8244 - val_loss: 0.3517 - val_acc: 0.8603\n",
      "Epoch 946/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3731 - acc: 0.8455 - val_loss: 0.3452 - val_acc: 0.8715\n",
      "Epoch 947/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3622 - acc: 0.8441 - val_loss: 0.3574 - val_acc: 0.8547\n",
      "Epoch 948/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3639 - acc: 0.8385 - val_loss: 0.4039 - val_acc: 0.8324\n",
      "Epoch 949/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3888 - acc: 0.8371 - val_loss: 0.3644 - val_acc: 0.8492\n",
      "Epoch 950/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3739 - acc: 0.8315 - val_loss: 0.3657 - val_acc: 0.8436\n",
      "Epoch 951/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3702 - acc: 0.8385 - val_loss: 0.4257 - val_acc: 0.7933\n",
      "Epoch 952/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3936 - acc: 0.8301 - val_loss: 0.3949 - val_acc: 0.8324\n",
      "Epoch 953/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3769 - acc: 0.8258 - val_loss: 0.3901 - val_acc: 0.8268\n",
      "Epoch 954/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8244 - val_loss: 0.3845 - val_acc: 0.8212\n",
      "Epoch 955/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3822 - acc: 0.8413 - val_loss: 0.4570 - val_acc: 0.8212\n",
      "Epoch 956/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3919 - acc: 0.8385 - val_loss: 0.3654 - val_acc: 0.8380\n",
      "Epoch 957/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3845 - acc: 0.8244 - val_loss: 0.3575 - val_acc: 0.8492\n",
      "Epoch 958/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3961 - acc: 0.8525 - val_loss: 0.3837 - val_acc: 0.8436\n",
      "Epoch 959/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3846 - acc: 0.8132 - val_loss: 0.3436 - val_acc: 0.8715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3666 - acc: 0.8258 - val_loss: 0.3570 - val_acc: 0.8659\n",
      "Epoch 961/1000\n",
      "712/712 [==============================] - 0s 37us/step - loss: 0.3709 - acc: 0.8287 - val_loss: 0.3623 - val_acc: 0.8324\n",
      "Epoch 962/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3852 - acc: 0.8188 - val_loss: 0.3599 - val_acc: 0.8436\n",
      "Epoch 963/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3779 - acc: 0.8385 - val_loss: 0.4532 - val_acc: 0.8045\n",
      "Epoch 964/1000\n",
      "712/712 [==============================] - 0s 35us/step - loss: 0.3922 - acc: 0.8174 - val_loss: 0.3714 - val_acc: 0.8492\n",
      "Epoch 965/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3618 - acc: 0.8455 - val_loss: 0.3570 - val_acc: 0.8492\n",
      "Epoch 966/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3849 - acc: 0.8329 - val_loss: 0.3731 - val_acc: 0.8045\n",
      "Epoch 967/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3720 - acc: 0.8413 - val_loss: 0.4214 - val_acc: 0.8492\n",
      "Epoch 968/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3744 - acc: 0.8315 - val_loss: 0.4157 - val_acc: 0.8492\n",
      "Epoch 969/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3913 - acc: 0.8371 - val_loss: 0.3433 - val_acc: 0.8715\n",
      "Epoch 970/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3895 - acc: 0.8343 - val_loss: 0.3688 - val_acc: 0.8659\n",
      "Epoch 971/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3782 - acc: 0.8357 - val_loss: 0.3437 - val_acc: 0.8603\n",
      "Epoch 972/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3770 - acc: 0.8272 - val_loss: 0.3498 - val_acc: 0.8436\n",
      "Epoch 973/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3831 - acc: 0.8315 - val_loss: 0.3484 - val_acc: 0.8659\n",
      "Epoch 974/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3756 - acc: 0.8455 - val_loss: 0.3508 - val_acc: 0.8547\n",
      "Epoch 975/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3729 - acc: 0.8427 - val_loss: 0.4276 - val_acc: 0.8324\n",
      "Epoch 976/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3965 - acc: 0.8188 - val_loss: 0.3547 - val_acc: 0.8492\n",
      "Epoch 977/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3687 - acc: 0.8343 - val_loss: 0.3383 - val_acc: 0.8659\n",
      "Epoch 978/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3716 - acc: 0.8427 - val_loss: 0.3348 - val_acc: 0.8492\n",
      "Epoch 979/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3770 - acc: 0.8371 - val_loss: 0.3579 - val_acc: 0.8492\n",
      "Epoch 980/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3878 - acc: 0.8357 - val_loss: 0.3523 - val_acc: 0.8547\n",
      "Epoch 981/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3740 - acc: 0.8343 - val_loss: 0.3446 - val_acc: 0.8547\n",
      "Epoch 982/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3567 - acc: 0.8469 - val_loss: 0.3274 - val_acc: 0.8603\n",
      "Epoch 983/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.4062 - acc: 0.8315 - val_loss: 0.3795 - val_acc: 0.8547\n",
      "Epoch 984/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3788 - acc: 0.8301 - val_loss: 0.3443 - val_acc: 0.8659\n",
      "Epoch 985/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3677 - acc: 0.8511 - val_loss: 0.4394 - val_acc: 0.8101\n",
      "Epoch 986/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3906 - acc: 0.8301 - val_loss: 0.3838 - val_acc: 0.8492\n",
      "Epoch 987/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3872 - acc: 0.8301 - val_loss: 0.3856 - val_acc: 0.8436\n",
      "Epoch 988/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3935 - acc: 0.8343 - val_loss: 0.3738 - val_acc: 0.8380\n",
      "Epoch 989/1000\n",
      "712/712 [==============================] - 0s 31us/step - loss: 0.3613 - acc: 0.8483 - val_loss: 0.3954 - val_acc: 0.8324\n",
      "Epoch 990/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3616 - acc: 0.8539 - val_loss: 0.3677 - val_acc: 0.8547\n",
      "Epoch 991/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3685 - acc: 0.8441 - val_loss: 0.3589 - val_acc: 0.8436\n",
      "Epoch 992/1000\n",
      "712/712 [==============================] - 0s 38us/step - loss: 0.3655 - acc: 0.8357 - val_loss: 0.3566 - val_acc: 0.8436\n",
      "Epoch 993/1000\n",
      "712/712 [==============================] - 0s 40us/step - loss: 0.3817 - acc: 0.8385 - val_loss: 0.3680 - val_acc: 0.8492\n",
      "Epoch 994/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3770 - acc: 0.8413 - val_loss: 0.3582 - val_acc: 0.8547\n",
      "Epoch 995/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3588 - acc: 0.8441 - val_loss: 0.3697 - val_acc: 0.8324\n",
      "Epoch 996/1000\n",
      "712/712 [==============================] - 0s 34us/step - loss: 0.3675 - acc: 0.8441 - val_loss: 0.3802 - val_acc: 0.8436\n",
      "Epoch 997/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3877 - acc: 0.8301 - val_loss: 0.3726 - val_acc: 0.8380\n",
      "Epoch 998/1000\n",
      "712/712 [==============================] - 0s 32us/step - loss: 0.3595 - acc: 0.8427 - val_loss: 0.3669 - val_acc: 0.8380\n",
      "Epoch 999/1000\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.3956 - acc: 0.8258 - val_loss: 0.3749 - val_acc: 0.8380\n",
      "Epoch 1000/1000\n",
      "712/712 [==============================] - 0s 33us/step - loss: 0.3754 - acc: 0.8455 - val_loss: 0.3828 - val_acc: 0.8436\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# #%% create model\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(units=64, activation='relu', input_dim=10))\n",
    "# model.add(layers.Dense(units=32, activation='relu'))\n",
    "# model.add(layers.Dropout(rate=0.5))\n",
    "# model.add(layers.Dense(units=16, activation='relu'))\n",
    "# model.add(layers.Dense(units=8, activation='relu'))\n",
    "# model.add(layers.Dense(units=4, activation='relu'))\n",
    "# model.add(layers.Dense(units=2, activation='relu'))\n",
    "# model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# # utils.plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "# #%% fitting\n",
    "# # early_stopping = callbacks.EarlyStopping(monitor='val_acc')\n",
    "# fit_history = model.fit(x_train, y_train, epochs=1000, validation_split=0.2, shuffle=True, batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x1a259fd4e0>>\n",
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/500\n",
      "801/801 [==============================] - 1s 673us/step - loss: 0.9937 - acc: 0.3958 - val_loss: 0.6945 - val_acc: 0.3778\n",
      "Epoch 2/500\n",
      "801/801 [==============================] - 0s 82us/step - loss: 0.8259 - acc: 0.4132 - val_loss: 0.6785 - val_acc: 0.5111\n",
      "Epoch 3/500\n",
      "801/801 [==============================] - 0s 74us/step - loss: 0.7439 - acc: 0.4544 - val_loss: 0.6835 - val_acc: 0.6444\n",
      "Epoch 4/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.7067 - acc: 0.5293 - val_loss: 0.6837 - val_acc: 0.6667\n",
      "Epoch 5/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6913 - acc: 0.5581 - val_loss: 0.6845 - val_acc: 0.6667\n",
      "Epoch 6/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6888 - acc: 0.5618 - val_loss: 0.6842 - val_acc: 0.6778\n",
      "Epoch 7/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6865 - acc: 0.6142 - val_loss: 0.6839 - val_acc: 0.6778\n",
      "Epoch 8/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6894 - acc: 0.6267 - val_loss: 0.6830 - val_acc: 0.6778\n",
      "Epoch 9/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6863 - acc: 0.6142 - val_loss: 0.6825 - val_acc: 0.6778\n",
      "Epoch 10/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6870 - acc: 0.6517 - val_loss: 0.6818 - val_acc: 0.6778\n",
      "Epoch 11/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6873 - acc: 0.6105 - val_loss: 0.6813 - val_acc: 0.6778\n",
      "Epoch 12/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6837 - acc: 0.6504 - val_loss: 0.6806 - val_acc: 0.6778\n",
      "Epoch 13/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6868 - acc: 0.6317 - val_loss: 0.6807 - val_acc: 0.6778\n",
      "Epoch 14/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6840 - acc: 0.6155 - val_loss: 0.6801 - val_acc: 0.6778\n",
      "Epoch 15/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6886 - acc: 0.6155 - val_loss: 0.6791 - val_acc: 0.6778\n",
      "Epoch 16/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6907 - acc: 0.6205 - val_loss: 0.6792 - val_acc: 0.6778\n",
      "Epoch 17/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6858 - acc: 0.6305 - val_loss: 0.6793 - val_acc: 0.6778\n",
      "Epoch 18/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6824 - acc: 0.6205 - val_loss: 0.6790 - val_acc: 0.6778\n",
      "Epoch 19/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6837 - acc: 0.6267 - val_loss: 0.6783 - val_acc: 0.6778\n",
      "Epoch 20/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6740 - acc: 0.6754 - val_loss: 0.6780 - val_acc: 0.6778\n",
      "Epoch 21/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6774 - acc: 0.6404 - val_loss: 0.6777 - val_acc: 0.6778\n",
      "Epoch 22/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6794 - acc: 0.6429 - val_loss: 0.6793 - val_acc: 0.6778\n",
      "Epoch 23/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6805 - acc: 0.6504 - val_loss: 0.6794 - val_acc: 0.6778\n",
      "Epoch 24/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6793 - acc: 0.6242 - val_loss: 0.6793 - val_acc: 0.6667\n",
      "Epoch 25/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6773 - acc: 0.6492 - val_loss: 0.6789 - val_acc: 0.6667\n",
      "Epoch 26/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6845 - acc: 0.6167 - val_loss: 0.6784 - val_acc: 0.6778\n",
      "Epoch 27/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6773 - acc: 0.6479 - val_loss: 0.6782 - val_acc: 0.6667\n",
      "Epoch 28/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6801 - acc: 0.6255 - val_loss: 0.6783 - val_acc: 0.6667\n",
      "Epoch 29/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6831 - acc: 0.6442 - val_loss: 0.6779 - val_acc: 0.6667\n",
      "Epoch 30/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6822 - acc: 0.6454 - val_loss: 0.6777 - val_acc: 0.6667\n",
      "Epoch 31/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6742 - acc: 0.6617 - val_loss: 0.6772 - val_acc: 0.6667\n",
      "Epoch 32/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6768 - acc: 0.6454 - val_loss: 0.6768 - val_acc: 0.6667\n",
      "Epoch 33/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6783 - acc: 0.6529 - val_loss: 0.6767 - val_acc: 0.6667\n",
      "Epoch 34/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6812 - acc: 0.6255 - val_loss: 0.6766 - val_acc: 0.6667\n",
      "Epoch 35/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6731 - acc: 0.6617 - val_loss: 0.6765 - val_acc: 0.6667\n",
      "Epoch 36/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6768 - acc: 0.6479 - val_loss: 0.6765 - val_acc: 0.6667\n",
      "Epoch 37/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6821 - acc: 0.6180 - val_loss: 0.6764 - val_acc: 0.6556\n",
      "Epoch 38/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6832 - acc: 0.6442 - val_loss: 0.6763 - val_acc: 0.6556\n",
      "Epoch 39/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6752 - acc: 0.6479 - val_loss: 0.6766 - val_acc: 0.6556\n",
      "Epoch 40/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6762 - acc: 0.6442 - val_loss: 0.6766 - val_acc: 0.6556\n",
      "Epoch 41/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6792 - acc: 0.6317 - val_loss: 0.6764 - val_acc: 0.6556\n",
      "Epoch 42/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6756 - acc: 0.6404 - val_loss: 0.6763 - val_acc: 0.6556\n",
      "Epoch 43/500\n",
      "801/801 [==============================] - 0s 41us/step - loss: 0.6791 - acc: 0.6517 - val_loss: 0.6762 - val_acc: 0.6556\n",
      "Epoch 44/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6768 - acc: 0.6492 - val_loss: 0.6761 - val_acc: 0.6556\n",
      "Epoch 45/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6788 - acc: 0.6367 - val_loss: 0.6761 - val_acc: 0.6556\n",
      "Epoch 46/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6821 - acc: 0.6342 - val_loss: 0.6761 - val_acc: 0.6556\n",
      "Epoch 47/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6782 - acc: 0.6429 - val_loss: 0.6761 - val_acc: 0.6556\n",
      "Epoch 48/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6777 - acc: 0.6429 - val_loss: 0.6760 - val_acc: 0.6444\n",
      "Epoch 49/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6805 - acc: 0.6092 - val_loss: 0.6758 - val_acc: 0.6444\n",
      "Epoch 50/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6734 - acc: 0.6404 - val_loss: 0.6756 - val_acc: 0.6444\n",
      "Epoch 51/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6768 - acc: 0.6492 - val_loss: 0.6754 - val_acc: 0.6444\n",
      "Epoch 52/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6830 - acc: 0.6504 - val_loss: 0.6752 - val_acc: 0.6444\n",
      "Epoch 53/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6795 - acc: 0.6529 - val_loss: 0.6752 - val_acc: 0.6444\n",
      "Epoch 54/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6774 - acc: 0.6367 - val_loss: 0.6752 - val_acc: 0.6444\n",
      "Epoch 55/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6787 - acc: 0.6492 - val_loss: 0.6752 - val_acc: 0.6444\n",
      "Epoch 56/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6753 - acc: 0.6567 - val_loss: 0.6752 - val_acc: 0.6444\n",
      "Epoch 57/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6778 - acc: 0.6429 - val_loss: 0.6752 - val_acc: 0.6444\n",
      "Epoch 58/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6748 - acc: 0.6604 - val_loss: 0.6752 - val_acc: 0.6444\n",
      "Epoch 59/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6777 - acc: 0.6504 - val_loss: 0.6751 - val_acc: 0.6444\n",
      "Epoch 60/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6735 - acc: 0.6342 - val_loss: 0.6749 - val_acc: 0.6444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6754 - acc: 0.6380 - val_loss: 0.6750 - val_acc: 0.6444\n",
      "Epoch 62/500\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6777 - acc: 0.6367 - val_loss: 0.6751 - val_acc: 0.6444\n",
      "Epoch 63/500\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.6767 - acc: 0.6142 - val_loss: 0.6751 - val_acc: 0.6444\n",
      "Epoch 64/500\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6780 - acc: 0.6392 - val_loss: 0.6750 - val_acc: 0.6444\n",
      "Epoch 65/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6767 - acc: 0.6404 - val_loss: 0.6749 - val_acc: 0.6444\n",
      "Epoch 66/500\n",
      "801/801 [==============================] - 0s 71us/step - loss: 0.6780 - acc: 0.6155 - val_loss: 0.6748 - val_acc: 0.6444\n",
      "Epoch 67/500\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6693 - acc: 0.6429 - val_loss: 0.6746 - val_acc: 0.6444\n",
      "Epoch 68/500\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6775 - acc: 0.6467 - val_loss: 0.6746 - val_acc: 0.6444\n",
      "Epoch 69/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6724 - acc: 0.6442 - val_loss: 0.6745 - val_acc: 0.6444\n",
      "Epoch 70/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6742 - acc: 0.6429 - val_loss: 0.6743 - val_acc: 0.6444\n",
      "Epoch 71/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6781 - acc: 0.6355 - val_loss: 0.6741 - val_acc: 0.6444\n",
      "Epoch 72/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6756 - acc: 0.6355 - val_loss: 0.6738 - val_acc: 0.6444\n",
      "Epoch 73/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6675 - acc: 0.6579 - val_loss: 0.6736 - val_acc: 0.6444\n",
      "Epoch 74/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6748 - acc: 0.6205 - val_loss: 0.6730 - val_acc: 0.6444\n",
      "Epoch 75/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6776 - acc: 0.6404 - val_loss: 0.6729 - val_acc: 0.6444\n",
      "Epoch 76/500\n",
      "801/801 [==============================] - 0s 67us/step - loss: 0.6788 - acc: 0.6330 - val_loss: 0.6729 - val_acc: 0.6444\n",
      "Epoch 77/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6734 - acc: 0.6342 - val_loss: 0.6729 - val_acc: 0.6444\n",
      "Epoch 78/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6708 - acc: 0.6404 - val_loss: 0.6729 - val_acc: 0.6444\n",
      "Epoch 79/500\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6818 - acc: 0.6417 - val_loss: 0.6730 - val_acc: 0.6444\n",
      "Epoch 80/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6741 - acc: 0.6342 - val_loss: 0.6731 - val_acc: 0.6444\n",
      "Epoch 81/500\n",
      "801/801 [==============================] - 0s 44us/step - loss: 0.6729 - acc: 0.6542 - val_loss: 0.6731 - val_acc: 0.6444\n",
      "Epoch 82/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6747 - acc: 0.6479 - val_loss: 0.6730 - val_acc: 0.6444\n",
      "Epoch 83/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6817 - acc: 0.6230 - val_loss: 0.6726 - val_acc: 0.6444\n",
      "Epoch 84/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6722 - acc: 0.6380 - val_loss: 0.6726 - val_acc: 0.6444\n",
      "Epoch 85/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6756 - acc: 0.6342 - val_loss: 0.6726 - val_acc: 0.6444\n",
      "Epoch 86/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6714 - acc: 0.6267 - val_loss: 0.6725 - val_acc: 0.6444\n",
      "Epoch 87/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6709 - acc: 0.6355 - val_loss: 0.6725 - val_acc: 0.6667\n",
      "Epoch 88/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6716 - acc: 0.6355 - val_loss: 0.6722 - val_acc: 0.6667\n",
      "Epoch 89/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6780 - acc: 0.6404 - val_loss: 0.6721 - val_acc: 0.6667\n",
      "Epoch 90/500\n",
      "801/801 [==============================] - 0s 68us/step - loss: 0.6716 - acc: 0.6429 - val_loss: 0.6721 - val_acc: 0.6667\n",
      "Epoch 91/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6669 - acc: 0.6654 - val_loss: 0.6721 - val_acc: 0.6667\n",
      "Epoch 92/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6762 - acc: 0.6404 - val_loss: 0.6720 - val_acc: 0.6667\n",
      "Epoch 93/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6745 - acc: 0.6504 - val_loss: 0.6719 - val_acc: 0.6667\n",
      "Epoch 94/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6745 - acc: 0.6592 - val_loss: 0.6718 - val_acc: 0.6667\n",
      "Epoch 95/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6756 - acc: 0.6242 - val_loss: 0.6719 - val_acc: 0.6667\n",
      "Epoch 96/500\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6736 - acc: 0.6554 - val_loss: 0.6718 - val_acc: 0.6667\n",
      "Epoch 97/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6742 - acc: 0.6292 - val_loss: 0.6718 - val_acc: 0.6667\n",
      "Epoch 98/500\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6711 - acc: 0.6479 - val_loss: 0.6717 - val_acc: 0.6667\n",
      "Epoch 99/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6741 - acc: 0.6517 - val_loss: 0.6717 - val_acc: 0.6778\n",
      "Epoch 100/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6747 - acc: 0.6504 - val_loss: 0.6718 - val_acc: 0.6778\n",
      "Epoch 101/500\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6720 - acc: 0.6330 - val_loss: 0.6716 - val_acc: 0.6778\n",
      "Epoch 102/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6733 - acc: 0.6392 - val_loss: 0.6715 - val_acc: 0.6778\n",
      "Epoch 103/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6687 - acc: 0.6604 - val_loss: 0.6715 - val_acc: 0.6778\n",
      "Epoch 104/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6727 - acc: 0.6429 - val_loss: 0.6713 - val_acc: 0.6778\n",
      "Epoch 105/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6764 - acc: 0.6529 - val_loss: 0.6713 - val_acc: 0.6778\n",
      "Epoch 106/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6756 - acc: 0.6667 - val_loss: 0.6713 - val_acc: 0.6778\n",
      "Epoch 107/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6697 - acc: 0.6355 - val_loss: 0.6712 - val_acc: 0.6778\n",
      "Epoch 108/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6713 - acc: 0.6542 - val_loss: 0.6711 - val_acc: 0.6778\n",
      "Epoch 109/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6761 - acc: 0.6342 - val_loss: 0.6711 - val_acc: 0.6778\n",
      "Epoch 110/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6726 - acc: 0.6442 - val_loss: 0.6711 - val_acc: 0.6778\n",
      "Epoch 111/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6684 - acc: 0.6654 - val_loss: 0.6711 - val_acc: 0.6778\n",
      "Epoch 112/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6720 - acc: 0.6442 - val_loss: 0.6716 - val_acc: 0.6889\n",
      "Epoch 113/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6754 - acc: 0.6242 - val_loss: 0.6717 - val_acc: 0.6889\n",
      "Epoch 114/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6711 - acc: 0.6342 - val_loss: 0.6716 - val_acc: 0.6889\n",
      "Epoch 115/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6758 - acc: 0.6554 - val_loss: 0.6714 - val_acc: 0.6889\n",
      "Epoch 116/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6757 - acc: 0.6479 - val_loss: 0.6712 - val_acc: 0.6889\n",
      "Epoch 117/500\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6732 - acc: 0.6492 - val_loss: 0.6711 - val_acc: 0.6889\n",
      "Epoch 118/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6724 - acc: 0.6130 - val_loss: 0.6711 - val_acc: 0.6889\n",
      "Epoch 119/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6710 - acc: 0.6392 - val_loss: 0.6710 - val_acc: 0.6889\n",
      "Epoch 120/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6764 - acc: 0.6255 - val_loss: 0.6709 - val_acc: 0.6889\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 52us/step - loss: 0.6685 - acc: 0.6429 - val_loss: 0.6708 - val_acc: 0.6889\n",
      "Epoch 122/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6718 - acc: 0.6230 - val_loss: 0.6707 - val_acc: 0.6889\n",
      "Epoch 123/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6748 - acc: 0.6417 - val_loss: 0.6706 - val_acc: 0.6889\n",
      "Epoch 124/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6704 - acc: 0.6317 - val_loss: 0.6705 - val_acc: 0.6889\n",
      "Epoch 125/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6733 - acc: 0.6367 - val_loss: 0.6701 - val_acc: 0.6778\n",
      "Epoch 126/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6738 - acc: 0.6342 - val_loss: 0.6701 - val_acc: 0.6778\n",
      "Epoch 127/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6753 - acc: 0.6205 - val_loss: 0.6700 - val_acc: 0.6778\n",
      "Epoch 128/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6718 - acc: 0.6404 - val_loss: 0.6700 - val_acc: 0.6778\n",
      "Epoch 129/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6691 - acc: 0.6654 - val_loss: 0.6700 - val_acc: 0.6778\n",
      "Epoch 130/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6737 - acc: 0.6305 - val_loss: 0.6699 - val_acc: 0.6778\n",
      "Epoch 131/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6738 - acc: 0.6429 - val_loss: 0.6698 - val_acc: 0.6778\n",
      "Epoch 132/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6696 - acc: 0.6417 - val_loss: 0.6696 - val_acc: 0.6778\n",
      "Epoch 133/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6737 - acc: 0.6267 - val_loss: 0.6695 - val_acc: 0.6778\n",
      "Epoch 134/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6728 - acc: 0.6604 - val_loss: 0.6695 - val_acc: 0.6778\n",
      "Epoch 135/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6676 - acc: 0.6492 - val_loss: 0.6695 - val_acc: 0.6778\n",
      "Epoch 136/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6758 - acc: 0.6280 - val_loss: 0.6694 - val_acc: 0.6778\n",
      "Epoch 137/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6738 - acc: 0.6380 - val_loss: 0.6694 - val_acc: 0.6778\n",
      "Epoch 138/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6741 - acc: 0.6317 - val_loss: 0.6694 - val_acc: 0.6889\n",
      "Epoch 139/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6719 - acc: 0.6454 - val_loss: 0.6694 - val_acc: 0.6778\n",
      "Epoch 140/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6718 - acc: 0.6355 - val_loss: 0.6693 - val_acc: 0.6778\n",
      "Epoch 141/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6691 - acc: 0.6542 - val_loss: 0.6692 - val_acc: 0.6778\n",
      "Epoch 142/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6778 - acc: 0.6267 - val_loss: 0.6691 - val_acc: 0.6778\n",
      "Epoch 143/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6730 - acc: 0.6504 - val_loss: 0.6691 - val_acc: 0.6889\n",
      "Epoch 144/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6682 - acc: 0.6504 - val_loss: 0.6690 - val_acc: 0.6889\n",
      "Epoch 145/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6731 - acc: 0.6492 - val_loss: 0.6689 - val_acc: 0.6889\n",
      "Epoch 146/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6769 - acc: 0.6217 - val_loss: 0.6689 - val_acc: 0.6889\n",
      "Epoch 147/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6687 - acc: 0.6417 - val_loss: 0.6689 - val_acc: 0.6889\n",
      "Epoch 148/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6734 - acc: 0.6167 - val_loss: 0.6689 - val_acc: 0.6889\n",
      "Epoch 149/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6706 - acc: 0.6492 - val_loss: 0.6688 - val_acc: 0.6889\n",
      "Epoch 150/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6723 - acc: 0.6292 - val_loss: 0.6688 - val_acc: 0.6889\n",
      "Epoch 151/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6714 - acc: 0.6417 - val_loss: 0.6688 - val_acc: 0.6889\n",
      "Epoch 152/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6715 - acc: 0.6342 - val_loss: 0.6688 - val_acc: 0.6889\n",
      "Epoch 153/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6751 - acc: 0.6292 - val_loss: 0.6688 - val_acc: 0.6889\n",
      "Epoch 154/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6722 - acc: 0.6380 - val_loss: 0.6689 - val_acc: 0.6889\n",
      "Epoch 155/500\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.6709 - acc: 0.6629 - val_loss: 0.6686 - val_acc: 0.6889\n",
      "Epoch 156/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6726 - acc: 0.6529 - val_loss: 0.6685 - val_acc: 0.6889\n",
      "Epoch 157/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6710 - acc: 0.6442 - val_loss: 0.6685 - val_acc: 0.6889\n",
      "Epoch 158/500\n",
      "801/801 [==============================] - 0s 45us/step - loss: 0.6666 - acc: 0.6305 - val_loss: 0.6685 - val_acc: 0.6889\n",
      "Epoch 159/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6723 - acc: 0.6417 - val_loss: 0.6685 - val_acc: 0.6889\n",
      "Epoch 160/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6667 - acc: 0.6367 - val_loss: 0.6685 - val_acc: 0.6889\n",
      "Epoch 161/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6709 - acc: 0.6305 - val_loss: 0.6684 - val_acc: 0.6889\n",
      "Epoch 162/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6684 - acc: 0.6479 - val_loss: 0.6684 - val_acc: 0.6889\n",
      "Epoch 163/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6696 - acc: 0.6604 - val_loss: 0.6683 - val_acc: 0.6889\n",
      "Epoch 164/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6667 - acc: 0.6567 - val_loss: 0.6682 - val_acc: 0.6889\n",
      "Epoch 165/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6710 - acc: 0.6442 - val_loss: 0.6681 - val_acc: 0.6889\n",
      "Epoch 166/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6699 - acc: 0.6554 - val_loss: 0.6680 - val_acc: 0.6889\n",
      "Epoch 167/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6683 - acc: 0.6554 - val_loss: 0.6680 - val_acc: 0.6889\n",
      "Epoch 168/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6735 - acc: 0.6517 - val_loss: 0.6679 - val_acc: 0.6889\n",
      "Epoch 169/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6771 - acc: 0.6404 - val_loss: 0.6679 - val_acc: 0.6889\n",
      "Epoch 170/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6714 - acc: 0.6417 - val_loss: 0.6679 - val_acc: 0.6889\n",
      "Epoch 171/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6703 - acc: 0.6467 - val_loss: 0.6677 - val_acc: 0.6889\n",
      "Epoch 172/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6711 - acc: 0.6330 - val_loss: 0.6676 - val_acc: 0.6889\n",
      "Epoch 173/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6716 - acc: 0.6429 - val_loss: 0.6674 - val_acc: 0.6889\n",
      "Epoch 174/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6708 - acc: 0.6492 - val_loss: 0.6673 - val_acc: 0.6889\n",
      "Epoch 175/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6705 - acc: 0.6667 - val_loss: 0.6672 - val_acc: 0.6889\n",
      "Epoch 176/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6656 - acc: 0.6380 - val_loss: 0.6671 - val_acc: 0.6889\n",
      "Epoch 177/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6708 - acc: 0.6192 - val_loss: 0.6674 - val_acc: 0.6889\n",
      "Epoch 178/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6702 - acc: 0.6442 - val_loss: 0.6673 - val_acc: 0.6889\n",
      "Epoch 179/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6691 - acc: 0.6529 - val_loss: 0.6673 - val_acc: 0.6889\n",
      "Epoch 180/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6702 - acc: 0.6617 - val_loss: 0.6672 - val_acc: 0.6889\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 47us/step - loss: 0.6695 - acc: 0.6542 - val_loss: 0.6670 - val_acc: 0.6889\n",
      "Epoch 182/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6632 - acc: 0.6442 - val_loss: 0.6669 - val_acc: 0.6889\n",
      "Epoch 183/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6632 - acc: 0.6529 - val_loss: 0.6668 - val_acc: 0.6889\n",
      "Epoch 184/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6726 - acc: 0.6404 - val_loss: 0.6667 - val_acc: 0.6889\n",
      "Epoch 185/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6707 - acc: 0.6454 - val_loss: 0.6667 - val_acc: 0.6889\n",
      "Epoch 186/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6696 - acc: 0.6292 - val_loss: 0.6666 - val_acc: 0.6889\n",
      "Epoch 187/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6650 - acc: 0.6579 - val_loss: 0.6666 - val_acc: 0.6889\n",
      "Epoch 188/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6738 - acc: 0.6305 - val_loss: 0.6666 - val_acc: 0.6889\n",
      "Epoch 189/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6718 - acc: 0.6717 - val_loss: 0.6666 - val_acc: 0.6889\n",
      "Epoch 190/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6670 - acc: 0.6479 - val_loss: 0.6665 - val_acc: 0.6889\n",
      "Epoch 191/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6689 - acc: 0.6380 - val_loss: 0.6664 - val_acc: 0.6889\n",
      "Epoch 192/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6709 - acc: 0.6305 - val_loss: 0.6664 - val_acc: 0.6889\n",
      "Epoch 193/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6741 - acc: 0.6167 - val_loss: 0.6664 - val_acc: 0.6889\n",
      "Epoch 194/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6755 - acc: 0.6542 - val_loss: 0.6663 - val_acc: 0.6889\n",
      "Epoch 195/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6699 - acc: 0.6367 - val_loss: 0.6663 - val_acc: 0.6889\n",
      "Epoch 196/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6706 - acc: 0.6367 - val_loss: 0.6663 - val_acc: 0.6889\n",
      "Epoch 197/500\n",
      "801/801 [==============================] - 0s 44us/step - loss: 0.6675 - acc: 0.6629 - val_loss: 0.6662 - val_acc: 0.6889\n",
      "Epoch 198/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6680 - acc: 0.6554 - val_loss: 0.6661 - val_acc: 0.6889\n",
      "Epoch 199/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6689 - acc: 0.6579 - val_loss: 0.6660 - val_acc: 0.6889\n",
      "Epoch 200/500\n",
      "801/801 [==============================] - 0s 42us/step - loss: 0.6659 - acc: 0.6305 - val_loss: 0.6658 - val_acc: 0.6889\n",
      "Epoch 201/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6674 - acc: 0.6679 - val_loss: 0.6658 - val_acc: 0.6889\n",
      "Epoch 202/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6703 - acc: 0.6255 - val_loss: 0.6658 - val_acc: 0.6889\n",
      "Epoch 203/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6740 - acc: 0.6330 - val_loss: 0.6658 - val_acc: 0.6889\n",
      "Epoch 204/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6676 - acc: 0.6255 - val_loss: 0.6658 - val_acc: 0.6889\n",
      "Epoch 205/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6697 - acc: 0.6429 - val_loss: 0.6658 - val_acc: 0.6889\n",
      "Epoch 206/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6672 - acc: 0.6554 - val_loss: 0.6657 - val_acc: 0.6889\n",
      "Epoch 207/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6698 - acc: 0.6517 - val_loss: 0.6656 - val_acc: 0.6889\n",
      "Epoch 208/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6655 - acc: 0.6554 - val_loss: 0.6655 - val_acc: 0.6889\n",
      "Epoch 209/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6708 - acc: 0.6392 - val_loss: 0.6655 - val_acc: 0.6889\n",
      "Epoch 210/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6745 - acc: 0.6355 - val_loss: 0.6655 - val_acc: 0.6889\n",
      "Epoch 211/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6696 - acc: 0.6642 - val_loss: 0.6655 - val_acc: 0.6889\n",
      "Epoch 212/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6681 - acc: 0.6567 - val_loss: 0.6655 - val_acc: 0.6889\n",
      "Epoch 213/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6684 - acc: 0.6604 - val_loss: 0.6654 - val_acc: 0.6889\n",
      "Epoch 214/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6650 - acc: 0.6230 - val_loss: 0.6653 - val_acc: 0.6889\n",
      "Epoch 215/500\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6699 - acc: 0.6529 - val_loss: 0.6653 - val_acc: 0.6889\n",
      "Epoch 216/500\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6700 - acc: 0.6292 - val_loss: 0.6653 - val_acc: 0.6889\n",
      "Epoch 217/500\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6662 - acc: 0.6579 - val_loss: 0.6652 - val_acc: 0.6889\n",
      "Epoch 218/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6706 - acc: 0.6417 - val_loss: 0.6651 - val_acc: 0.6889\n",
      "Epoch 219/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6708 - acc: 0.6392 - val_loss: 0.6650 - val_acc: 0.6889\n",
      "Epoch 220/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6711 - acc: 0.6404 - val_loss: 0.6650 - val_acc: 0.6889\n",
      "Epoch 221/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6657 - acc: 0.6679 - val_loss: 0.6650 - val_acc: 0.6889\n",
      "Epoch 222/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6651 - acc: 0.6742 - val_loss: 0.6650 - val_acc: 0.6889\n",
      "Epoch 223/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6677 - acc: 0.6429 - val_loss: 0.6650 - val_acc: 0.6889\n",
      "Epoch 224/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6702 - acc: 0.6517 - val_loss: 0.6649 - val_acc: 0.6889\n",
      "Epoch 225/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6706 - acc: 0.6404 - val_loss: 0.6649 - val_acc: 0.6889\n",
      "Epoch 226/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6642 - acc: 0.6567 - val_loss: 0.6649 - val_acc: 0.6889\n",
      "Epoch 227/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6726 - acc: 0.6355 - val_loss: 0.6649 - val_acc: 0.6889\n",
      "Epoch 228/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6668 - acc: 0.6554 - val_loss: 0.6649 - val_acc: 0.6889\n",
      "Epoch 229/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6683 - acc: 0.6442 - val_loss: 0.6648 - val_acc: 0.6889\n",
      "Epoch 230/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6683 - acc: 0.6429 - val_loss: 0.6648 - val_acc: 0.6889\n",
      "Epoch 231/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6652 - acc: 0.6579 - val_loss: 0.6647 - val_acc: 0.6889\n",
      "Epoch 232/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6600 - acc: 0.6554 - val_loss: 0.6646 - val_acc: 0.6889\n",
      "Epoch 233/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6684 - acc: 0.6454 - val_loss: 0.6646 - val_acc: 0.6889\n",
      "Epoch 234/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6666 - acc: 0.6667 - val_loss: 0.6646 - val_acc: 0.6889\n",
      "Epoch 235/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6676 - acc: 0.6454 - val_loss: 0.6646 - val_acc: 0.6889\n",
      "Epoch 236/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6650 - acc: 0.6442 - val_loss: 0.6645 - val_acc: 0.6889\n",
      "Epoch 237/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6689 - acc: 0.6292 - val_loss: 0.6645 - val_acc: 0.6889\n",
      "Epoch 238/500\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.6682 - acc: 0.6504 - val_loss: 0.6644 - val_acc: 0.6889\n",
      "Epoch 239/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6677 - acc: 0.6517 - val_loss: 0.6643 - val_acc: 0.6889\n",
      "Epoch 240/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6652 - acc: 0.6604 - val_loss: 0.6643 - val_acc: 0.6889\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 52us/step - loss: 0.6662 - acc: 0.6567 - val_loss: 0.6642 - val_acc: 0.6889\n",
      "Epoch 242/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6692 - acc: 0.6467 - val_loss: 0.6642 - val_acc: 0.6889\n",
      "Epoch 243/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6772 - acc: 0.6529 - val_loss: 0.6642 - val_acc: 0.6889\n",
      "Epoch 244/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6649 - acc: 0.6754 - val_loss: 0.6641 - val_acc: 0.6889\n",
      "Epoch 245/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6668 - acc: 0.6380 - val_loss: 0.6641 - val_acc: 0.6889\n",
      "Epoch 246/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6632 - acc: 0.6454 - val_loss: 0.6641 - val_acc: 0.6889\n",
      "Epoch 247/500\n",
      "801/801 [==============================] - 0s 45us/step - loss: 0.6656 - acc: 0.6617 - val_loss: 0.6640 - val_acc: 0.6889\n",
      "Epoch 248/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6641 - acc: 0.6454 - val_loss: 0.6639 - val_acc: 0.6889\n",
      "Epoch 249/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6673 - acc: 0.6454 - val_loss: 0.6639 - val_acc: 0.6889\n",
      "Epoch 250/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6737 - acc: 0.6267 - val_loss: 0.6638 - val_acc: 0.6889\n",
      "Epoch 251/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6657 - acc: 0.6417 - val_loss: 0.6638 - val_acc: 0.6889\n",
      "Epoch 252/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6716 - acc: 0.6342 - val_loss: 0.6638 - val_acc: 0.6889\n",
      "Epoch 253/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6661 - acc: 0.6454 - val_loss: 0.6638 - val_acc: 0.6889\n",
      "Epoch 254/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6639 - acc: 0.6317 - val_loss: 0.6639 - val_acc: 0.6889\n",
      "Epoch 255/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6677 - acc: 0.6467 - val_loss: 0.6638 - val_acc: 0.6889\n",
      "Epoch 256/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6669 - acc: 0.6454 - val_loss: 0.6637 - val_acc: 0.6889\n",
      "Epoch 257/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6674 - acc: 0.6380 - val_loss: 0.6637 - val_acc: 0.6889\n",
      "Epoch 258/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6656 - acc: 0.6479 - val_loss: 0.6637 - val_acc: 0.6889\n",
      "Epoch 259/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6716 - acc: 0.6342 - val_loss: 0.6637 - val_acc: 0.6889\n",
      "Epoch 260/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6625 - acc: 0.6642 - val_loss: 0.6637 - val_acc: 0.6889\n",
      "Epoch 261/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6676 - acc: 0.6404 - val_loss: 0.6636 - val_acc: 0.6889\n",
      "Epoch 262/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6622 - acc: 0.6617 - val_loss: 0.6636 - val_acc: 0.6889\n",
      "Epoch 263/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6689 - acc: 0.6592 - val_loss: 0.6636 - val_acc: 0.6889\n",
      "Epoch 264/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6690 - acc: 0.6529 - val_loss: 0.6635 - val_acc: 0.6889\n",
      "Epoch 265/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6679 - acc: 0.6317 - val_loss: 0.6634 - val_acc: 0.6889\n",
      "Epoch 266/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6706 - acc: 0.6579 - val_loss: 0.6634 - val_acc: 0.6889\n",
      "Epoch 267/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6654 - acc: 0.6517 - val_loss: 0.6634 - val_acc: 0.6889\n",
      "Epoch 268/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6693 - acc: 0.6492 - val_loss: 0.6632 - val_acc: 0.6889\n",
      "Epoch 269/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6677 - acc: 0.6404 - val_loss: 0.6630 - val_acc: 0.6889\n",
      "Epoch 270/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6692 - acc: 0.6417 - val_loss: 0.6629 - val_acc: 0.6889\n",
      "Epoch 271/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6700 - acc: 0.6442 - val_loss: 0.6629 - val_acc: 0.6889\n",
      "Epoch 272/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6604 - acc: 0.6492 - val_loss: 0.6628 - val_acc: 0.6889\n",
      "Epoch 273/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6690 - acc: 0.6392 - val_loss: 0.6628 - val_acc: 0.6889\n",
      "Epoch 274/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6628 - acc: 0.6754 - val_loss: 0.6628 - val_acc: 0.6889\n",
      "Epoch 275/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6669 - acc: 0.6504 - val_loss: 0.6628 - val_acc: 0.6889\n",
      "Epoch 276/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6679 - acc: 0.6492 - val_loss: 0.6628 - val_acc: 0.6889\n",
      "Epoch 277/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6666 - acc: 0.6767 - val_loss: 0.6628 - val_acc: 0.6889\n",
      "Epoch 278/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6661 - acc: 0.6255 - val_loss: 0.6627 - val_acc: 0.6889\n",
      "Epoch 279/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6644 - acc: 0.6679 - val_loss: 0.6627 - val_acc: 0.6889\n",
      "Epoch 280/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6683 - acc: 0.6542 - val_loss: 0.6626 - val_acc: 0.6889\n",
      "Epoch 281/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6695 - acc: 0.6342 - val_loss: 0.6625 - val_acc: 0.6889\n",
      "Epoch 282/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6646 - acc: 0.6467 - val_loss: 0.6624 - val_acc: 0.6889\n",
      "Epoch 283/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6672 - acc: 0.6604 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 284/500\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6689 - acc: 0.6367 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 285/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6679 - acc: 0.6529 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 286/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6651 - acc: 0.6504 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 287/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6660 - acc: 0.6642 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 288/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6675 - acc: 0.6604 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 289/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6662 - acc: 0.6442 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 290/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6684 - acc: 0.6380 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 291/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6647 - acc: 0.6579 - val_loss: 0.6623 - val_acc: 0.6889\n",
      "Epoch 292/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6666 - acc: 0.6542 - val_loss: 0.6622 - val_acc: 0.6889\n",
      "Epoch 293/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6647 - acc: 0.6617 - val_loss: 0.6622 - val_acc: 0.6889\n",
      "Epoch 294/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6670 - acc: 0.6392 - val_loss: 0.6622 - val_acc: 0.6889\n",
      "Epoch 295/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6705 - acc: 0.6517 - val_loss: 0.6621 - val_acc: 0.6889\n",
      "Epoch 296/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6716 - acc: 0.6392 - val_loss: 0.6621 - val_acc: 0.6889\n",
      "Epoch 297/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6673 - acc: 0.6604 - val_loss: 0.6621 - val_acc: 0.6889\n",
      "Epoch 298/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6661 - acc: 0.6479 - val_loss: 0.6621 - val_acc: 0.6889\n",
      "Epoch 299/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6658 - acc: 0.6492 - val_loss: 0.6621 - val_acc: 0.6889\n",
      "Epoch 300/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6632 - acc: 0.6542 - val_loss: 0.6621 - val_acc: 0.6889\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 51us/step - loss: 0.6657 - acc: 0.6417 - val_loss: 0.6620 - val_acc: 0.6889\n",
      "Epoch 302/500\n",
      "801/801 [==============================] - 0s 40us/step - loss: 0.6616 - acc: 0.6579 - val_loss: 0.6620 - val_acc: 0.6889\n",
      "Epoch 303/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6622 - acc: 0.6330 - val_loss: 0.6619 - val_acc: 0.6889\n",
      "Epoch 304/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6634 - acc: 0.6529 - val_loss: 0.6619 - val_acc: 0.6889\n",
      "Epoch 305/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6702 - acc: 0.6404 - val_loss: 0.6618 - val_acc: 0.6889\n",
      "Epoch 306/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6698 - acc: 0.6504 - val_loss: 0.6618 - val_acc: 0.6889\n",
      "Epoch 307/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6649 - acc: 0.6342 - val_loss: 0.6618 - val_acc: 0.6889\n",
      "Epoch 308/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6644 - acc: 0.6629 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 309/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6608 - acc: 0.6592 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 310/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6703 - acc: 0.6467 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 311/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6669 - acc: 0.6554 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 312/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6656 - acc: 0.6592 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 313/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6704 - acc: 0.6267 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 314/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6628 - acc: 0.6367 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 315/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6614 - acc: 0.6679 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 316/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6680 - acc: 0.6542 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 317/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6592 - acc: 0.6654 - val_loss: 0.6617 - val_acc: 0.6889\n",
      "Epoch 318/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6664 - acc: 0.6479 - val_loss: 0.6616 - val_acc: 0.6889\n",
      "Epoch 319/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6559 - acc: 0.6454 - val_loss: 0.6616 - val_acc: 0.6889\n",
      "Epoch 320/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6687 - acc: 0.6392 - val_loss: 0.6616 - val_acc: 0.6889\n",
      "Epoch 321/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6627 - acc: 0.6792 - val_loss: 0.6615 - val_acc: 0.6889\n",
      "Epoch 322/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6616 - acc: 0.6479 - val_loss: 0.6615 - val_acc: 0.6889\n",
      "Epoch 323/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6726 - acc: 0.6479 - val_loss: 0.6615 - val_acc: 0.6889\n",
      "Epoch 324/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6641 - acc: 0.6579 - val_loss: 0.6615 - val_acc: 0.6889\n",
      "Epoch 325/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6695 - acc: 0.6467 - val_loss: 0.6614 - val_acc: 0.6889\n",
      "Epoch 326/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6611 - acc: 0.6617 - val_loss: 0.6614 - val_acc: 0.6889\n",
      "Epoch 327/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6643 - acc: 0.6429 - val_loss: 0.6614 - val_acc: 0.6889\n",
      "Epoch 328/500\n",
      "801/801 [==============================] - 0s 41us/step - loss: 0.6624 - acc: 0.6579 - val_loss: 0.6613 - val_acc: 0.6889\n",
      "Epoch 329/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6668 - acc: 0.6592 - val_loss: 0.6613 - val_acc: 0.6889\n",
      "Epoch 330/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6676 - acc: 0.6417 - val_loss: 0.6612 - val_acc: 0.6889\n",
      "Epoch 331/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6599 - acc: 0.6816 - val_loss: 0.6612 - val_acc: 0.6889\n",
      "Epoch 332/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6633 - acc: 0.6492 - val_loss: 0.6611 - val_acc: 0.6889\n",
      "Epoch 333/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6700 - acc: 0.6429 - val_loss: 0.6611 - val_acc: 0.6889\n",
      "Epoch 334/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6653 - acc: 0.6504 - val_loss: 0.6611 - val_acc: 0.6889\n",
      "Epoch 335/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6649 - acc: 0.6492 - val_loss: 0.6609 - val_acc: 0.6889\n",
      "Epoch 336/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6659 - acc: 0.6442 - val_loss: 0.6608 - val_acc: 0.6889\n",
      "Epoch 337/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6647 - acc: 0.6467 - val_loss: 0.6607 - val_acc: 0.6889\n",
      "Epoch 338/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6608 - acc: 0.6604 - val_loss: 0.6607 - val_acc: 0.6889\n",
      "Epoch 339/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6622 - acc: 0.6704 - val_loss: 0.6606 - val_acc: 0.6889\n",
      "Epoch 340/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6701 - acc: 0.6255 - val_loss: 0.6606 - val_acc: 0.6889\n",
      "Epoch 341/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6578 - acc: 0.7004 - val_loss: 0.6605 - val_acc: 0.6889\n",
      "Epoch 342/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6746 - acc: 0.6442 - val_loss: 0.6605 - val_acc: 0.6889\n",
      "Epoch 343/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6690 - acc: 0.6404 - val_loss: 0.6605 - val_acc: 0.6889\n",
      "Epoch 344/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6665 - acc: 0.6442 - val_loss: 0.6605 - val_acc: 0.6889\n",
      "Epoch 345/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6682 - acc: 0.6542 - val_loss: 0.6605 - val_acc: 0.6889\n",
      "Epoch 346/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6578 - acc: 0.6742 - val_loss: 0.6604 - val_acc: 0.6889\n",
      "Epoch 347/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6607 - acc: 0.6542 - val_loss: 0.6604 - val_acc: 0.6889\n",
      "Epoch 348/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6678 - acc: 0.6554 - val_loss: 0.6603 - val_acc: 0.6889\n",
      "Epoch 349/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6594 - acc: 0.6654 - val_loss: 0.6603 - val_acc: 0.6889\n",
      "Epoch 350/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6613 - acc: 0.6617 - val_loss: 0.6602 - val_acc: 0.6889\n",
      "Epoch 351/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6660 - acc: 0.6567 - val_loss: 0.6602 - val_acc: 0.6889\n",
      "Epoch 352/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6619 - acc: 0.6642 - val_loss: 0.6602 - val_acc: 0.6889\n",
      "Epoch 353/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6640 - acc: 0.6667 - val_loss: 0.6602 - val_acc: 0.6889\n",
      "Epoch 354/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6599 - acc: 0.6592 - val_loss: 0.6601 - val_acc: 0.6889\n",
      "Epoch 355/500\n",
      "801/801 [==============================] - 0s 59us/step - loss: 0.6554 - acc: 0.6779 - val_loss: 0.6601 - val_acc: 0.6889\n",
      "Epoch 356/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6642 - acc: 0.6417 - val_loss: 0.6600 - val_acc: 0.6889\n",
      "Epoch 357/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6633 - acc: 0.6492 - val_loss: 0.6600 - val_acc: 0.6889\n",
      "Epoch 358/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6625 - acc: 0.6642 - val_loss: 0.6600 - val_acc: 0.6889\n",
      "Epoch 359/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6644 - acc: 0.6517 - val_loss: 0.6600 - val_acc: 0.6889\n",
      "Epoch 360/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6680 - acc: 0.6492 - val_loss: 0.6600 - val_acc: 0.6889\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 49us/step - loss: 0.6676 - acc: 0.6380 - val_loss: 0.6600 - val_acc: 0.6889\n",
      "Epoch 362/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6627 - acc: 0.6604 - val_loss: 0.6600 - val_acc: 0.6889\n",
      "Epoch 363/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6673 - acc: 0.6529 - val_loss: 0.6600 - val_acc: 0.6889\n",
      "Epoch 364/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6619 - acc: 0.6392 - val_loss: 0.6599 - val_acc: 0.6889\n",
      "Epoch 365/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6612 - acc: 0.6679 - val_loss: 0.6599 - val_acc: 0.6889\n",
      "Epoch 366/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6594 - acc: 0.6642 - val_loss: 0.6599 - val_acc: 0.6889\n",
      "Epoch 367/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6590 - acc: 0.6829 - val_loss: 0.6599 - val_acc: 0.6889\n",
      "Epoch 368/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6636 - acc: 0.6479 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 369/500\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6645 - acc: 0.6617 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 370/500\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6621 - acc: 0.6704 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 371/500\n",
      "801/801 [==============================] - 0s 70us/step - loss: 0.6695 - acc: 0.6417 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 372/500\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6669 - acc: 0.6679 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 373/500\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6648 - acc: 0.6417 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 374/500\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6629 - acc: 0.6717 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 375/500\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6672 - acc: 0.6717 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 376/500\n",
      "801/801 [==============================] - 0s 75us/step - loss: 0.6607 - acc: 0.6729 - val_loss: 0.6598 - val_acc: 0.6889\n",
      "Epoch 377/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6608 - acc: 0.6517 - val_loss: 0.6597 - val_acc: 0.6889\n",
      "Epoch 378/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6624 - acc: 0.6717 - val_loss: 0.6597 - val_acc: 0.6889\n",
      "Epoch 379/500\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6669 - acc: 0.6629 - val_loss: 0.6597 - val_acc: 0.6889\n",
      "Epoch 380/500\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.6678 - acc: 0.6504 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 381/500\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6617 - acc: 0.6592 - val_loss: 0.6597 - val_acc: 0.6889\n",
      "Epoch 382/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6663 - acc: 0.6542 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 383/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6707 - acc: 0.6442 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 384/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6667 - acc: 0.6592 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 385/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6621 - acc: 0.6629 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 386/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6669 - acc: 0.6529 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 387/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6619 - acc: 0.6542 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 388/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6650 - acc: 0.6517 - val_loss: 0.6595 - val_acc: 0.6889\n",
      "Epoch 389/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6621 - acc: 0.6692 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 390/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6630 - acc: 0.6504 - val_loss: 0.6596 - val_acc: 0.6889\n",
      "Epoch 391/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6622 - acc: 0.6504 - val_loss: 0.6595 - val_acc: 0.6889\n",
      "Epoch 392/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6660 - acc: 0.6792 - val_loss: 0.6595 - val_acc: 0.6889\n",
      "Epoch 393/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6623 - acc: 0.6542 - val_loss: 0.6595 - val_acc: 0.6889\n",
      "Epoch 394/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6662 - acc: 0.6492 - val_loss: 0.6595 - val_acc: 0.6889\n",
      "Epoch 395/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6606 - acc: 0.6742 - val_loss: 0.6594 - val_acc: 0.6889\n",
      "Epoch 396/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6596 - acc: 0.6642 - val_loss: 0.6594 - val_acc: 0.6889\n",
      "Epoch 397/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6667 - acc: 0.6554 - val_loss: 0.6593 - val_acc: 0.6889\n",
      "Epoch 398/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6612 - acc: 0.6467 - val_loss: 0.6593 - val_acc: 0.6889\n",
      "Epoch 399/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6659 - acc: 0.6592 - val_loss: 0.6592 - val_acc: 0.6889\n",
      "Epoch 400/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6595 - acc: 0.6654 - val_loss: 0.6592 - val_acc: 0.6889\n",
      "Epoch 401/500\n",
      "801/801 [==============================] - 0s 69us/step - loss: 0.6628 - acc: 0.6579 - val_loss: 0.6592 - val_acc: 0.6889\n",
      "Epoch 402/500\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6639 - acc: 0.6642 - val_loss: 0.6591 - val_acc: 0.6889\n",
      "Epoch 403/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6651 - acc: 0.6604 - val_loss: 0.6591 - val_acc: 0.6889\n",
      "Epoch 404/500\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6665 - acc: 0.6454 - val_loss: 0.6591 - val_acc: 0.6889\n",
      "Epoch 405/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6622 - acc: 0.6529 - val_loss: 0.6591 - val_acc: 0.6889\n",
      "Epoch 406/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6569 - acc: 0.6704 - val_loss: 0.6591 - val_acc: 0.6889\n",
      "Epoch 407/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6617 - acc: 0.6529 - val_loss: 0.6590 - val_acc: 0.6889\n",
      "Epoch 408/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6640 - acc: 0.6704 - val_loss: 0.6590 - val_acc: 0.6889\n",
      "Epoch 409/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6614 - acc: 0.6729 - val_loss: 0.6589 - val_acc: 0.6889\n",
      "Epoch 410/500\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6589 - acc: 0.6779 - val_loss: 0.6589 - val_acc: 0.6889\n",
      "Epoch 411/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6635 - acc: 0.6604 - val_loss: 0.6588 - val_acc: 0.6889\n",
      "Epoch 412/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6662 - acc: 0.6479 - val_loss: 0.6588 - val_acc: 0.6889\n",
      "Epoch 413/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6654 - acc: 0.6579 - val_loss: 0.6588 - val_acc: 0.6889\n",
      "Epoch 414/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6612 - acc: 0.6529 - val_loss: 0.6588 - val_acc: 0.6889\n",
      "Epoch 415/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6639 - acc: 0.6667 - val_loss: 0.6588 - val_acc: 0.6889\n",
      "Epoch 416/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6659 - acc: 0.6429 - val_loss: 0.6587 - val_acc: 0.6889\n",
      "Epoch 417/500\n",
      "801/801 [==============================] - 0s 66us/step - loss: 0.6599 - acc: 0.6617 - val_loss: 0.6587 - val_acc: 0.6889\n",
      "Epoch 418/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6670 - acc: 0.6442 - val_loss: 0.6587 - val_acc: 0.6889\n",
      "Epoch 419/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6658 - acc: 0.6679 - val_loss: 0.6587 - val_acc: 0.6889\n",
      "Epoch 420/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6578 - acc: 0.6816 - val_loss: 0.6587 - val_acc: 0.6889\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 55us/step - loss: 0.6674 - acc: 0.6517 - val_loss: 0.6587 - val_acc: 0.6889\n",
      "Epoch 422/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6643 - acc: 0.6479 - val_loss: 0.6587 - val_acc: 0.6889\n",
      "Epoch 423/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6660 - acc: 0.6367 - val_loss: 0.6586 - val_acc: 0.6889\n",
      "Epoch 424/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6626 - acc: 0.6467 - val_loss: 0.6586 - val_acc: 0.6889\n",
      "Epoch 425/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6689 - acc: 0.6442 - val_loss: 0.6586 - val_acc: 0.6889\n",
      "Epoch 426/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6634 - acc: 0.6517 - val_loss: 0.6586 - val_acc: 0.6889\n",
      "Epoch 427/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6596 - acc: 0.6629 - val_loss: 0.6586 - val_acc: 0.6889\n",
      "Epoch 428/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6621 - acc: 0.6467 - val_loss: 0.6586 - val_acc: 0.6889\n",
      "Epoch 429/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6630 - acc: 0.6529 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 430/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6567 - acc: 0.6729 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 431/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6655 - acc: 0.6330 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 432/500\n",
      "801/801 [==============================] - 0s 43us/step - loss: 0.6578 - acc: 0.6579 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 433/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6622 - acc: 0.6617 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 434/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6626 - acc: 0.6717 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 435/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6662 - acc: 0.6479 - val_loss: 0.6586 - val_acc: 0.6889\n",
      "Epoch 436/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6572 - acc: 0.6704 - val_loss: 0.6586 - val_acc: 0.6889\n",
      "Epoch 437/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6630 - acc: 0.6679 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 438/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6694 - acc: 0.6504 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 439/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6650 - acc: 0.6567 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 440/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6655 - acc: 0.6467 - val_loss: 0.6585 - val_acc: 0.6889\n",
      "Epoch 441/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6632 - acc: 0.6667 - val_loss: 0.6584 - val_acc: 0.6889\n",
      "Epoch 442/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6638 - acc: 0.6704 - val_loss: 0.6584 - val_acc: 0.6889\n",
      "Epoch 443/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6686 - acc: 0.6330 - val_loss: 0.6584 - val_acc: 0.6889\n",
      "Epoch 444/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6568 - acc: 0.6804 - val_loss: 0.6584 - val_acc: 0.6889\n",
      "Epoch 445/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6612 - acc: 0.6717 - val_loss: 0.6584 - val_acc: 0.6889\n",
      "Epoch 446/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6611 - acc: 0.6754 - val_loss: 0.6583 - val_acc: 0.6889\n",
      "Epoch 447/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6598 - acc: 0.6654 - val_loss: 0.6583 - val_acc: 0.6889\n",
      "Epoch 448/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6629 - acc: 0.6579 - val_loss: 0.6583 - val_acc: 0.6889\n",
      "Epoch 449/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6634 - acc: 0.6617 - val_loss: 0.6582 - val_acc: 0.6889\n",
      "Epoch 450/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6588 - acc: 0.6729 - val_loss: 0.6582 - val_acc: 0.6889\n",
      "Epoch 451/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6584 - acc: 0.6629 - val_loss: 0.6581 - val_acc: 0.6889\n",
      "Epoch 452/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6648 - acc: 0.6579 - val_loss: 0.6581 - val_acc: 0.6889\n",
      "Epoch 453/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6633 - acc: 0.6642 - val_loss: 0.6581 - val_acc: 0.6889\n",
      "Epoch 454/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6599 - acc: 0.6542 - val_loss: 0.6581 - val_acc: 0.6889\n",
      "Epoch 455/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6639 - acc: 0.6629 - val_loss: 0.6581 - val_acc: 0.6889\n",
      "Epoch 456/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6607 - acc: 0.6717 - val_loss: 0.6580 - val_acc: 0.6889\n",
      "Epoch 457/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6638 - acc: 0.6604 - val_loss: 0.6580 - val_acc: 0.6889\n",
      "Epoch 458/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6631 - acc: 0.6492 - val_loss: 0.6580 - val_acc: 0.6889\n",
      "Epoch 459/500\n",
      "801/801 [==============================] - 0s 65us/step - loss: 0.6603 - acc: 0.6567 - val_loss: 0.6580 - val_acc: 0.6889\n",
      "Epoch 460/500\n",
      "801/801 [==============================] - 0s 62us/step - loss: 0.6619 - acc: 0.6567 - val_loss: 0.6579 - val_acc: 0.6889\n",
      "Epoch 461/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6670 - acc: 0.6454 - val_loss: 0.6579 - val_acc: 0.6889\n",
      "Epoch 462/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6654 - acc: 0.6529 - val_loss: 0.6579 - val_acc: 0.6889\n",
      "Epoch 463/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6616 - acc: 0.6579 - val_loss: 0.6578 - val_acc: 0.6889\n",
      "Epoch 464/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6550 - acc: 0.6629 - val_loss: 0.6578 - val_acc: 0.6889\n",
      "Epoch 465/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6615 - acc: 0.6629 - val_loss: 0.6578 - val_acc: 0.6889\n",
      "Epoch 466/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6565 - acc: 0.6841 - val_loss: 0.6577 - val_acc: 0.6889\n",
      "Epoch 467/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6615 - acc: 0.6517 - val_loss: 0.6576 - val_acc: 0.6889\n",
      "Epoch 468/500\n",
      "801/801 [==============================] - 0s 47us/step - loss: 0.6624 - acc: 0.6479 - val_loss: 0.6576 - val_acc: 0.6889\n",
      "Epoch 469/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6676 - acc: 0.6355 - val_loss: 0.6576 - val_acc: 0.6889\n",
      "Epoch 470/500\n",
      "801/801 [==============================] - 0s 52us/step - loss: 0.6595 - acc: 0.6779 - val_loss: 0.6575 - val_acc: 0.6889\n",
      "Epoch 471/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6617 - acc: 0.6692 - val_loss: 0.6575 - val_acc: 0.6889\n",
      "Epoch 472/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6586 - acc: 0.6767 - val_loss: 0.6575 - val_acc: 0.6889\n",
      "Epoch 473/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6624 - acc: 0.6617 - val_loss: 0.6574 - val_acc: 0.6889\n",
      "Epoch 474/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6607 - acc: 0.6804 - val_loss: 0.6574 - val_acc: 0.6889\n",
      "Epoch 475/500\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.6642 - acc: 0.6542 - val_loss: 0.6574 - val_acc: 0.6889\n",
      "Epoch 476/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6618 - acc: 0.6579 - val_loss: 0.6574 - val_acc: 0.6889\n",
      "Epoch 477/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6623 - acc: 0.6479 - val_loss: 0.6574 - val_acc: 0.6889\n",
      "Epoch 478/500\n",
      "801/801 [==============================] - 0s 61us/step - loss: 0.6642 - acc: 0.6429 - val_loss: 0.6574 - val_acc: 0.6889\n",
      "Epoch 479/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6566 - acc: 0.6567 - val_loss: 0.6574 - val_acc: 0.6889\n",
      "Epoch 480/500\n",
      "801/801 [==============================] - 0s 55us/step - loss: 0.6664 - acc: 0.6642 - val_loss: 0.6573 - val_acc: 0.6889\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 57us/step - loss: 0.6645 - acc: 0.6629 - val_loss: 0.6573 - val_acc: 0.6889\n",
      "Epoch 482/500\n",
      "801/801 [==============================] - 0s 54us/step - loss: 0.6657 - acc: 0.6617 - val_loss: 0.6574 - val_acc: 0.6889\n",
      "Epoch 483/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6583 - acc: 0.6479 - val_loss: 0.6573 - val_acc: 0.6889\n",
      "Epoch 484/500\n",
      "801/801 [==============================] - 0s 48us/step - loss: 0.6596 - acc: 0.6717 - val_loss: 0.6573 - val_acc: 0.6889\n",
      "Epoch 485/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6649 - acc: 0.6617 - val_loss: 0.6573 - val_acc: 0.6889\n",
      "Epoch 486/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6622 - acc: 0.6567 - val_loss: 0.6573 - val_acc: 0.6889\n",
      "Epoch 487/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6595 - acc: 0.6579 - val_loss: 0.6573 - val_acc: 0.6889\n",
      "Epoch 488/500\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.6608 - acc: 0.6479 - val_loss: 0.6572 - val_acc: 0.6889\n",
      "Epoch 489/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6637 - acc: 0.6629 - val_loss: 0.6572 - val_acc: 0.6889\n",
      "Epoch 490/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6608 - acc: 0.6729 - val_loss: 0.6572 - val_acc: 0.6889\n",
      "Epoch 491/500\n",
      "801/801 [==============================] - 0s 50us/step - loss: 0.6639 - acc: 0.6542 - val_loss: 0.6572 - val_acc: 0.6889\n",
      "Epoch 492/500\n",
      "801/801 [==============================] - 0s 49us/step - loss: 0.6572 - acc: 0.6816 - val_loss: 0.6571 - val_acc: 0.6889\n",
      "Epoch 493/500\n",
      "801/801 [==============================] - 0s 58us/step - loss: 0.6600 - acc: 0.6642 - val_loss: 0.6571 - val_acc: 0.6889\n",
      "Epoch 494/500\n",
      "801/801 [==============================] - 0s 56us/step - loss: 0.6593 - acc: 0.6529 - val_loss: 0.6571 - val_acc: 0.6889\n",
      "Epoch 495/500\n",
      "801/801 [==============================] - 0s 60us/step - loss: 0.6693 - acc: 0.6554 - val_loss: 0.6571 - val_acc: 0.6889\n",
      "Epoch 496/500\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6630 - acc: 0.6467 - val_loss: 0.6571 - val_acc: 0.6889\n",
      "Epoch 497/500\n",
      "801/801 [==============================] - 0s 64us/step - loss: 0.6612 - acc: 0.6629 - val_loss: 0.6570 - val_acc: 0.6889\n",
      "Epoch 498/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6596 - acc: 0.6604 - val_loss: 0.6570 - val_acc: 0.6889\n",
      "Epoch 499/500\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.6631 - acc: 0.6667 - val_loss: 0.6570 - val_acc: 0.6889\n",
      "Epoch 500/500\n",
      "801/801 [==============================] - 0s 53us/step - loss: 0.6640 - acc: 0.6380 - val_loss: 0.6570 - val_acc: 0.6889\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_dim=len(x_train.columns)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.5)) # 과적합방지 Dropout. \n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# opt = optimizers.Adam(lr=0.001, beta_1=0.5, beta_2=0.99, epsilon=None, decay=0.0, amsgrad=False)\n",
    "opt = optimizers.Adam(lr=0.0001, decay=0.01, amsgrad=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary)\n",
    "\n",
    "fit_history = model.fit(x_train, y_train, epochs=500, batch_size=50,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% let's visualize\n",
    "acc = fit_history.history['acc']\n",
    "val_acc = fit_history.history['val_acc']\n",
    "loss = fit_history.history['loss']\n",
    "val_loss = fit_history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'g', label='acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
    "plt.plot(epochs, loss, 'y', label='loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% predict\n",
    "prediction = model.predict_classes(x_test)\n",
    "ids = testing['PassengerId'].copy()\n",
    "new_output = ids.to_frame()\n",
    "new_output['Survived'] = prediction\n",
    "new_output.to_csv('./UsingKeras_py.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
