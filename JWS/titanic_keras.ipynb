{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "\n",
    "train = pd.read_csv(\"../data/titanic/train.csv\")\n",
    "test = pd.read_csv(\"../data/titanic/test.csv\")\n",
    "train = train.append(test) ## test 데이터도 학습에 이용.\n",
    "\n",
    "# inplace=True 로 해야 모든 컬럼에 대해 fillna 가 이뤄짐.\n",
    "# train.fillna(0, inplace=True) \n",
    "# test.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 8)\n",
      "(418, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  Pclass  SibSp  0_x  1  2  0_y\n",
       "0  22.0   7.2500      0       3      1    0  0  1    1\n",
       "1  38.0  71.2833      0       1      1    1  0  0    0\n",
       "2  26.0   7.9250      0       3      0    0  0  1    0\n",
       "3  35.0  53.1000      0       1      1    0  0  1    0\n",
       "4  35.0   8.0500      0       3      0    0  0  1    1"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# cols = PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "\n",
    "# 데이터 전처리 : 학습에 필요없는 column 제거.\n",
    "train.pop('Name'), test.pop('Name')\n",
    "train.pop('Ticket'), test.pop('Ticket')\n",
    "train.pop('Cabin'), test.pop('Cabin')\n",
    "train.pop('PassengerId'), test.pop('PassengerId') # 제거하지 않으면 passengerId 가 높을수록 predicton value 가 높은 현상\n",
    "\n",
    "train.dropna(inplace=True)\n",
    "# test.dropna(inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# 데이터 전처리 : One Hot Encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "enc = encoder.fit(train[['Embarked']].astype(str))\n",
    "train = pd.merge(train, pd.DataFrame(enc.transform(train[['Embarked']].astype(str))) , right_index=True, left_index=True)\n",
    "test = pd.merge(test, pd.DataFrame(enc.transform(test[['Embarked']].astype(str))) , right_index=True, left_index=True)\n",
    "enc = encoder.fit(train[['Sex']].astype(str))\n",
    "train = pd.merge(train, pd.DataFrame(enc.transform(train[['Sex']].astype(str))) , right_index=True, left_index=True)\n",
    "test = pd.merge(test, pd.DataFrame(enc.transform(test[['Sex']].astype(str))) , right_index=True, left_index=True)\n",
    "train.pop('Embarked'), test.pop('Embarked')\n",
    "train.pop('Sex'), test.pop('Sex')\n",
    "\n",
    "# label\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "# feature\n",
    "train.pop('Survived')\n",
    "x_train = train\n",
    "x_test = test\n",
    "\n",
    "x_train.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import DBSCAN\n",
    "# outlier_detection = DBSCAN(\n",
    "#     eps = 0.5,\n",
    "#     metric=\"euclidean\",\n",
    "#     n_jobs = -1)\n",
    "# clusters = outlier_detection.fit_predict(train[['Fare']])\n",
    "# clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live :  182\n",
      "death :  264\n",
      "생존률 :  0.4080717488789238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0       0.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       0.0"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live = len(y_train[y_train['Survived']==1])\n",
    "death = len(y_train[y_train['Survived']==0])\n",
    "print(\"live : \" , live)\n",
    "print(\"death : \" , death)\n",
    "print(\n",
    "    \"생존률 : \" , live / (live + death)\n",
    ")\n",
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  0_x  1  2  0_y\n",
       "0       3  34.5      0      0   7.8292    0  1  0    1\n",
       "1       3  47.0      1      0   7.0000    0  0  1    0\n",
       "2       2  62.0      0      0   9.6875    0  1  0    1\n",
       "3       3  27.0      0      0   8.6625    0  0  1    1\n",
       "4       3  22.0      1      1  12.2875    0  0  1    0"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x1a4c7f7710>>\n",
      "Train on 356 samples, validate on 90 samples\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 8s 23ms/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 0s 264us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 0s 262us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 0s 248us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 0s 250us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 0s 267us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 0s 284us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 0s 255us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 0s 220us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 0s 247us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 0s 247us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 0s 205us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 0s 209us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 0s 222us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 0s 208us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 0s 193us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 0s 209us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 0s 225us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 0s 222us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 0s 207us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 0s 216us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 0s 220us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 0s 218us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 0s 214us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 0s 208us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 0s 209us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 0s 207us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6932 - val_acc: 0.5222\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 0s 220us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 0s 203us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 0s 194us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 0s 209us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 0s 203us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 0s 193us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 0s 214us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 0s 209us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 0s 214us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 0s 212us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 0s 216us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 0s 211us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 0s 215us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 0s 214us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 0s 206us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 0s 209us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 0s 207us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 0s 213us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 0s 209us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 0s 212us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 0s 207us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 0s 214us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 0s 206us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 0s 210us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 0s 212us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 0s 208us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 0s 220us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 0s 215us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 0s 204us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 0s 208us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 0s 255us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 0s 216us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 0s 222us/step - loss: 0.6931 - acc: 0.6096 - val_loss: 0.6931 - val_acc: 0.5222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(9, kernel_initializer = 'uniform',activation='relu', input_dim=len(x_train.columns)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(9, kernel_initializer = 'uniform',activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer = 'uniform',activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer = 'uniform',activation='sigmoid'))\n",
    "\n",
    "# opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# opt = optimizers.Adam(lr=0.001, beta_1=0.5, beta_2=0.99, epsilon=None, decay=0.0, amsgrad=False)\n",
    "opt = optimizers.Adam(lr=0.0000005)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "print(model.summary)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=100, batch_size=30,validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='lower left')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49984848],\n",
       "       [ 0.49983937],\n",
       "       [ 0.49982852],\n",
       "       [ 0.49985328],\n",
       "       [ 0.49985638],\n",
       "       [ 0.49986258],\n",
       "       [ 0.49985227],\n",
       "       [ 0.49985656],\n",
       "       [ 0.49986079],\n",
       "       [ 0.49986026],\n",
       "       [        nan],\n",
       "       [ 0.49983865],\n",
       "       [ 0.49985513],\n",
       "       [ 0.49982625],\n",
       "       [ 0.49984699],\n",
       "       [ 0.4998596 ],\n",
       "       [ 0.49984789],\n",
       "       [ 0.49985805],\n",
       "       [ 0.49985376],\n",
       "       [ 0.49984127],\n",
       "       [ 0.49984032],\n",
       "       [ 0.49986592],\n",
       "       [        nan],\n",
       "       [ 0.49985734],\n",
       "       [ 0.49981302],\n",
       "       [ 0.49983627],\n",
       "       [ 0.49985698],\n",
       "       [ 0.49985698],\n",
       "       [ 0.49984419],\n",
       "       [        nan],\n",
       "       [ 0.49983567],\n",
       "       [ 0.49985912],\n",
       "       [ 0.49984711],\n",
       "       [        nan],\n",
       "       [ 0.49985483],\n",
       "       [ 0.49985984],\n",
       "       [        nan],\n",
       "       [ 0.49985817],\n",
       "       [ 0.49985471],\n",
       "       [        nan],\n",
       "       [ 0.49984396],\n",
       "       [        nan],\n",
       "       [ 0.4998433 ],\n",
       "       [ 0.4998515 ],\n",
       "       [ 0.49984711],\n",
       "       [ 0.49985483],\n",
       "       [ 0.49983972],\n",
       "       [        nan],\n",
       "       [ 0.49984008],\n",
       "       [ 0.49984545],\n",
       "       [ 0.4998571 ],\n",
       "       [ 0.49985328],\n",
       "       [ 0.49986055],\n",
       "       [ 0.49980214],\n",
       "       [        nan],\n",
       "       [ 0.49986538],\n",
       "       [ 0.49984759],\n",
       "       [ 0.49985483],\n",
       "       [        nan],\n",
       "       [ 0.49981248],\n",
       "       [ 0.49986055],\n",
       "       [ 0.4998495 ],\n",
       "       [ 0.49985984],\n",
       "       [ 0.49985805],\n",
       "       [ 0.49979898],\n",
       "       [        nan],\n",
       "       [ 0.49986091],\n",
       "       [ 0.49984348],\n",
       "       [ 0.49985388],\n",
       "       [ 0.4998166 ],\n",
       "       [ 0.49985662],\n",
       "       [ 0.49985769],\n",
       "       [ 0.49985245],\n",
       "       [ 0.49985567],\n",
       "       [ 0.49982542],\n",
       "       [ 0.49982423],\n",
       "       [        nan],\n",
       "       [ 0.49983251],\n",
       "       [ 0.4998509 ],\n",
       "       [ 0.49985662],\n",
       "       [ 0.49986771],\n",
       "       [ 0.49982226],\n",
       "       [ 0.4998365 ],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985442],\n",
       "       [ 0.49986044],\n",
       "       [        nan],\n",
       "       [ 0.49986389],\n",
       "       [ 0.49985698],\n",
       "       [        nan],\n",
       "       [ 0.49985614],\n",
       "       [        nan],\n",
       "       [ 0.49985805],\n",
       "       [ 0.49985483],\n",
       "       [ 0.49982756],\n",
       "       [ 0.49985191],\n",
       "       [ 0.49985901],\n",
       "       [ 0.49984902],\n",
       "       [ 0.4998495 ],\n",
       "       [ 0.49985602],\n",
       "       [        nan],\n",
       "       [ 0.49985412],\n",
       "       [ 0.49986127],\n",
       "       [ 0.49985388],\n",
       "       [ 0.49985817],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985918],\n",
       "       [ 0.49984318],\n",
       "       [        nan],\n",
       "       [ 0.49985108],\n",
       "       [ 0.49986055],\n",
       "       [ 0.49982399],\n",
       "       [ 0.49986103],\n",
       "       [        nan],\n",
       "       [ 0.4998655 ],\n",
       "       [ 0.49985027],\n",
       "       [ 0.49985507],\n",
       "       [ 0.49986616],\n",
       "       [        nan],\n",
       "       [ 0.49985293],\n",
       "       [ 0.49985269],\n",
       "       [        nan],\n",
       "       [ 0.49986169],\n",
       "       [ 0.49985698],\n",
       "       [        nan],\n",
       "       [ 0.49984229],\n",
       "       [ 0.49985555],\n",
       "       [ 0.49984974],\n",
       "       [ 0.49983376],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49984181],\n",
       "       [ 0.49985555],\n",
       "       [ 0.49985412],\n",
       "       [ 0.49985382],\n",
       "       [ 0.49985674],\n",
       "       [ 0.49984497],\n",
       "       [ 0.49986067],\n",
       "       [ 0.49984199],\n",
       "       [ 0.49981874],\n",
       "       [ 0.49985549],\n",
       "       [ 0.49984139],\n",
       "       [ 0.4998495 ],\n",
       "       [        nan],\n",
       "       [ 0.49985698],\n",
       "       [        nan],\n",
       "       [ 0.49985275],\n",
       "       [ 0.49985424],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49984568],\n",
       "       [ 0.49986365],\n",
       "       [ 0.49985555],\n",
       "       [ 0.49982017],\n",
       "       [ 0.4998568 ],\n",
       "       [ 0.49984139],\n",
       "       [ 0.49985281],\n",
       "       [        nan],\n",
       "       [ 0.49986747],\n",
       "       [ 0.49985436],\n",
       "       [        nan],\n",
       "       [ 0.499843  ],\n",
       "       [ 0.49985507],\n",
       "       [ 0.49984449],\n",
       "       [ 0.49986103],\n",
       "       [        nan],\n",
       "       [ 0.49985746],\n",
       "       [        nan],\n",
       "       [ 0.4998537 ],\n",
       "       [ 0.49985573],\n",
       "       [        nan],\n",
       "       [ 0.49984014],\n",
       "       [ 0.49986163],\n",
       "       [ 0.49986067],\n",
       "       [ 0.49984044],\n",
       "       [ 0.49984974],\n",
       "       [ 0.49983662],\n",
       "       [ 0.4998509 ],\n",
       "       [ 0.4998489 ],\n",
       "       [ 0.49986032],\n",
       "       [        nan],\n",
       "       [ 0.49981076],\n",
       "       [ 0.49984354],\n",
       "       [ 0.49985984],\n",
       "       [ 0.49986032],\n",
       "       [        nan],\n",
       "       [ 0.49984378],\n",
       "       [ 0.49984938],\n",
       "       [        nan],\n",
       "       [ 0.49986544],\n",
       "       [ 0.49982911],\n",
       "       [ 0.49986336],\n",
       "       [ 0.49984902],\n",
       "       [ 0.49983323],\n",
       "       [ 0.49986044],\n",
       "       [ 0.49985614],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49986383],\n",
       "       [ 0.49982601],\n",
       "       [ 0.49986646],\n",
       "       [ 0.49985471],\n",
       "       [        nan],\n",
       "       [ 0.49984866],\n",
       "       [ 0.49985543],\n",
       "       [ 0.49985233],\n",
       "       [ 0.49985483],\n",
       "       [ 0.49984938],\n",
       "       [        nan],\n",
       "       [ 0.49985746],\n",
       "       [ 0.49982899],\n",
       "       [ 0.49984401],\n",
       "       [ 0.49984735],\n",
       "       [        nan],\n",
       "       [ 0.49983209],\n",
       "       [ 0.49982971],\n",
       "       [        nan],\n",
       "       [ 0.49985161],\n",
       "       [ 0.49985769],\n",
       "       [ 0.4998574 ],\n",
       "       [ 0.49985769],\n",
       "       [ 0.49983442],\n",
       "       [        nan],\n",
       "       [ 0.49985626],\n",
       "       [        nan],\n",
       "       [ 0.49984318],\n",
       "       [ 0.49984664],\n",
       "       [ 0.49985859],\n",
       "       [ 0.49986145],\n",
       "       [ 0.49985769],\n",
       "       [        nan],\n",
       "       [ 0.4998498 ],\n",
       "       [ 0.49985841],\n",
       "       [ 0.49983603],\n",
       "       [ 0.49985877],\n",
       "       [ 0.49985912],\n",
       "       [ 0.49984246],\n",
       "       [ 0.49983293],\n",
       "       [ 0.49983793],\n",
       "       [ 0.49984008],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.4998495 ],\n",
       "       [ 0.49985984],\n",
       "       [ 0.49984306],\n",
       "       [ 0.49985507],\n",
       "       [        nan],\n",
       "       [ 0.49986103],\n",
       "       [ 0.49985841],\n",
       "       [ 0.49984437],\n",
       "       [ 0.49985543],\n",
       "       [ 0.49984932],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985263],\n",
       "       [ 0.4998593 ],\n",
       "       [ 0.49985769],\n",
       "       [ 0.49984586],\n",
       "       [ 0.49985769],\n",
       "       [ 0.49985126],\n",
       "       [ 0.49986699],\n",
       "       [ 0.49985126],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49986055],\n",
       "       [ 0.49984628],\n",
       "       [        nan],\n",
       "       [ 0.49984449],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49986199],\n",
       "       [ 0.49985257],\n",
       "       [ 0.4998427 ],\n",
       "       [ 0.49985096],\n",
       "       [ 0.49985686],\n",
       "       [ 0.49985674],\n",
       "       [ 0.49986568],\n",
       "       [        nan],\n",
       "       [ 0.49986681],\n",
       "       [ 0.49986497],\n",
       "       [ 0.49984688],\n",
       "       [        nan],\n",
       "       [ 0.49985459],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985233],\n",
       "       [        nan],\n",
       "       [ 0.49984282],\n",
       "       [ 0.49984676],\n",
       "       [ 0.49985412],\n",
       "       [ 0.49985757],\n",
       "       [        nan],\n",
       "       [ 0.49985602],\n",
       "       [ 0.49985191],\n",
       "       [ 0.49984974],\n",
       "       [        nan],\n",
       "       [ 0.49984032],\n",
       "       [ 0.49985549],\n",
       "       [        nan],\n",
       "       [ 0.4998253 ],\n",
       "       [ 0.49983811],\n",
       "       [ 0.49986711],\n",
       "       [ 0.4998408 ],\n",
       "       [ 0.49984044],\n",
       "       [ 0.49985984],\n",
       "       [ 0.49985734],\n",
       "       [        nan],\n",
       "       [ 0.49984723],\n",
       "       [ 0.49983627],\n",
       "       [ 0.49986163],\n",
       "       [ 0.49983436],\n",
       "       [ 0.49985901],\n",
       "       [ 0.4998534 ],\n",
       "       [ 0.49986067],\n",
       "       [ 0.49985412],\n",
       "       [ 0.49985519],\n",
       "       [ 0.49985382],\n",
       "       [ 0.4998509 ],\n",
       "       [ 0.49982643],\n",
       "       [ 0.49985626],\n",
       "       [ 0.49986377],\n",
       "       [ 0.49984592],\n",
       "       [ 0.49985448],\n",
       "       [ 0.49985734],\n",
       "       [ 0.49983788],\n",
       "       [ 0.49984646],\n",
       "       [        nan],\n",
       "       [ 0.49985984],\n",
       "       [ 0.4998534 ],\n",
       "       [ 0.49985388],\n",
       "       [ 0.4998495 ],\n",
       "       [ 0.49984354],\n",
       "       [ 0.49985877],\n",
       "       [        nan],\n",
       "       [ 0.49985972],\n",
       "       [ 0.4998498 ],\n",
       "       [        nan],\n",
       "       [ 0.49975026],\n",
       "       [        nan],\n",
       "       [ 0.49986187],\n",
       "       [ 0.49985382],\n",
       "       [ 0.49984634],\n",
       "       [ 0.49985525],\n",
       "       [ 0.49985009],\n",
       "       [ 0.49984777],\n",
       "       [ 0.49985471],\n",
       "       [ 0.49985734],\n",
       "       [ 0.49984413],\n",
       "       [ 0.49986246],\n",
       "       [ 0.49983579],\n",
       "       [ 0.49983591],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985114],\n",
       "       [ 0.49985579],\n",
       "       [ 0.49985889],\n",
       "       [ 0.49985009],\n",
       "       [ 0.49985328],\n",
       "       [ 0.49985716],\n",
       "       [        nan],\n",
       "       [        nan],\n",
       "       [ 0.49985924],\n",
       "       [ 0.49984807],\n",
       "       [ 0.49985197],\n",
       "       [ 0.49985746],\n",
       "       [ 0.4998458 ],\n",
       "       [ 0.4998427 ],\n",
       "       [ 0.49984086],\n",
       "       [ 0.49984258],\n",
       "       [ 0.49981451],\n",
       "       [ 0.49985722],\n",
       "       [ 0.49985752],\n",
       "       [ 0.49983859],\n",
       "       [ 0.49986175],\n",
       "       [        nan],\n",
       "       [ 0.49985459],\n",
       "       [        nan],\n",
       "       [ 0.49986061],\n",
       "       [        nan],\n",
       "       [ 0.49985549],\n",
       "       [ 0.49985555],\n",
       "       [ 0.49983144],\n",
       "       [ 0.49985823],\n",
       "       [ 0.49986699],\n",
       "       [ 0.49985352],\n",
       "       [ 0.49983728],\n",
       "       [ 0.49986401],\n",
       "       [ 0.49983883],\n",
       "       [ 0.49985161],\n",
       "       [ 0.4998596 ],\n",
       "       [ 0.49985608],\n",
       "       [ 0.49984509],\n",
       "       [ 0.49985698],\n",
       "       [ 0.49985102],\n",
       "       [ 0.49983644],\n",
       "       [ 0.49984461],\n",
       "       [ 0.49985722],\n",
       "       [ 0.49986103],\n",
       "       [ 0.49984092],\n",
       "       [ 0.49985853],\n",
       "       [ 0.49985602],\n",
       "       [ 0.49982959],\n",
       "       [        nan],\n",
       "       [ 0.49986783],\n",
       "       [        nan],\n",
       "       [ 0.49984878],\n",
       "       [ 0.49985316],\n",
       "       [        nan],\n",
       "       [ 0.4998455 ],\n",
       "       [ 0.49984509],\n",
       "       [        nan],\n",
       "       [        nan]], dtype=float32)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live :  0\n",
      "death :  418\n",
      "생존율 :  0.0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(x_test)\n",
    "live = len([x for x in pred.ravel() if x==1])\n",
    "death = len([x for x in pred.ravel() if x==0])\n",
    "print(\"live : \" , live)\n",
    "print(\"death : \" , death)\n",
    "print(\"생존율 : \", live / (live + death))\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../data/titanic/gender_submission.csv\")\n",
    "df_pred[['Survived']] = pred\n",
    "# df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
