{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 12)\n",
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.0</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PP 9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>58.0</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>248706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>382652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34.0</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>248698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28.0</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19.0</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Canavan, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Master. Paul Folke</td>\n",
       "      <td>1</td>\n",
       "      <td>1281</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>23.0</td>\n",
       "      <td>B24</td>\n",
       "      <td>S</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>Payne, Mr. Vivian Ponsonby</td>\n",
       "      <td>0</td>\n",
       "      <td>1282</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>51.0</td>\n",
       "      <td>D28</td>\n",
       "      <td>S</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>Lines, Mrs. Ernest H (Elizabeth Lindsey James)</td>\n",
       "      <td>1</td>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>Abbott, Master. Eugene Joseph</td>\n",
       "      <td>2</td>\n",
       "      <td>1284</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.A. 2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Gilbert, Mr. William</td>\n",
       "      <td>0</td>\n",
       "      <td>1285</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.A. 30769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>Kink-Heilmann, Mr. Anton</td>\n",
       "      <td>1</td>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>18.0</td>\n",
       "      <td>C31</td>\n",
       "      <td>S</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>Smith, Mrs. Lucien Philip (Mary Eloise Hughes)</td>\n",
       "      <td>0</td>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Colbert, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>1288</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>48.0</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Larsson-Rondberg, Mr. Edvard A</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Conlon, Mr. Thomas Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>1291</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C7</td>\n",
       "      <td>S</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>Bonnell, Miss. Caroline</td>\n",
       "      <td>0</td>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>Gale, Mr. Harry</td>\n",
       "      <td>0</td>\n",
       "      <td>1293</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>Gibson, Miss. Dorothy Winifred</td>\n",
       "      <td>1</td>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>Carrau, Mr. Jose Pedro</td>\n",
       "      <td>0</td>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>43.0</td>\n",
       "      <td>D40</td>\n",
       "      <td>C</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>Frauenthal, Mr. Isaac Gerald</td>\n",
       "      <td>0</td>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>20.0</td>\n",
       "      <td>D38</td>\n",
       "      <td>C</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>Nourney, Mr. Alfred (Baron von Drachstedt\")\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SC/PARIS 2166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Ware, Mr. William Jeffery</td>\n",
       "      <td>0</td>\n",
       "      <td>1298</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>50.0</td>\n",
       "      <td>C80</td>\n",
       "      <td>C</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>Widener, Mr. George Dunton</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>Riordan, Miss. Johanna Hannah\"\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>1</td>\n",
       "      <td>1301</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Naughton, Miss. Hannah</td>\n",
       "      <td>0</td>\n",
       "      <td>1302</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>37.0</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>Minahan, Mrs. William Edward (Lillian E Thorpe)</td>\n",
       "      <td>0</td>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Henriksson, Miss. Jenny Lovisa</td>\n",
       "      <td>0</td>\n",
       "      <td>1304</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A.5. 3236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>39.0</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>0</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>38.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>0</td>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>0</td>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>1</td>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age        Cabin Embarked      Fare  \\\n",
       "0    22.0          NaN        S    7.2500   \n",
       "1    38.0          C85        C   71.2833   \n",
       "2    26.0          NaN        S    7.9250   \n",
       "3    35.0         C123        S   53.1000   \n",
       "4    35.0          NaN        S    8.0500   \n",
       "5     NaN          NaN        Q    8.4583   \n",
       "6    54.0          E46        S   51.8625   \n",
       "7     2.0          NaN        S   21.0750   \n",
       "8    27.0          NaN        S   11.1333   \n",
       "9    14.0          NaN        C   30.0708   \n",
       "10    4.0           G6        S   16.7000   \n",
       "11   58.0         C103        S   26.5500   \n",
       "12   20.0          NaN        S    8.0500   \n",
       "13   39.0          NaN        S   31.2750   \n",
       "14   14.0          NaN        S    7.8542   \n",
       "15   55.0          NaN        S   16.0000   \n",
       "16    2.0          NaN        Q   29.1250   \n",
       "17    NaN          NaN        S   13.0000   \n",
       "18   31.0          NaN        S   18.0000   \n",
       "19    NaN          NaN        C    7.2250   \n",
       "20   35.0          NaN        S   26.0000   \n",
       "21   34.0          D56        S   13.0000   \n",
       "22   15.0          NaN        Q    8.0292   \n",
       "23   28.0           A6        S   35.5000   \n",
       "24    8.0          NaN        S   21.0750   \n",
       "25   38.0          NaN        S   31.3875   \n",
       "26    NaN          NaN        C    7.2250   \n",
       "27   19.0  C23 C25 C27        S  263.0000   \n",
       "28    NaN          NaN        Q    7.8792   \n",
       "29    NaN          NaN        S    7.8958   \n",
       "..    ...          ...      ...       ...   \n",
       "388  21.0          NaN        Q    7.7500   \n",
       "389   6.0          NaN        S   21.0750   \n",
       "390  23.0          B24        S   93.5000   \n",
       "391  51.0          D28        S   39.4000   \n",
       "392  13.0          NaN        S   20.2500   \n",
       "393  47.0          NaN        S   10.5000   \n",
       "394  29.0          NaN        S   22.0250   \n",
       "395  18.0          C31        S   60.0000   \n",
       "396  24.0          NaN        Q    7.2500   \n",
       "397  48.0          B41        C   79.2000   \n",
       "398  22.0          NaN        S    7.7750   \n",
       "399  31.0          NaN        Q    7.7333   \n",
       "400  30.0           C7        S  164.8667   \n",
       "401  38.0          NaN        S   21.0000   \n",
       "402  22.0          NaN        C   59.4000   \n",
       "403  17.0          NaN        S   47.1000   \n",
       "404  43.0          D40        C   27.7208   \n",
       "405  20.0          D38        C   13.8625   \n",
       "406  23.0          NaN        S   10.5000   \n",
       "407  50.0          C80        C  211.5000   \n",
       "408   NaN          NaN        Q    7.7208   \n",
       "409   3.0          NaN        S   13.7750   \n",
       "410   NaN          NaN        Q    7.7500   \n",
       "411  37.0          C78        Q   90.0000   \n",
       "412  28.0          NaN        S    7.7750   \n",
       "413   NaN          NaN        S    8.0500   \n",
       "414  39.0         C105        C  108.9000   \n",
       "415  38.5          NaN        S    7.2500   \n",
       "416   NaN          NaN        S    8.0500   \n",
       "417   NaN          NaN        C   22.3583   \n",
       "\n",
       "                                                  Name  Parch  PassengerId  \\\n",
       "0                              Braund, Mr. Owen Harris      0            1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                               Heikkinen, Miss. Laina      0            3   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                             Allen, Mr. William Henry      0            5   \n",
       "5                                     Moran, Mr. James      0            6   \n",
       "6                              McCarthy, Mr. Timothy J      0            7   \n",
       "7                       Palsson, Master. Gosta Leonard      1            8   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      2            9   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)      0           10   \n",
       "10                     Sandstrom, Miss. Marguerite Rut      1           11   \n",
       "11                            Bonnell, Miss. Elizabeth      0           12   \n",
       "12                      Saundercock, Mr. William Henry      0           13   \n",
       "13                         Andersson, Mr. Anders Johan      5           14   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina      0           15   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)       0           16   \n",
       "16                                Rice, Master. Eugene      1           17   \n",
       "17                        Williams, Mr. Charles Eugene      0           18   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...      0           19   \n",
       "19                             Masselmani, Mrs. Fatima      0           20   \n",
       "20                                Fynney, Mr. Joseph J      0           21   \n",
       "21                               Beesley, Mr. Lawrence      0           22   \n",
       "22                         McGowan, Miss. Anna \"Annie\"      0           23   \n",
       "23                        Sloper, Mr. William Thompson      0           24   \n",
       "24                       Palsson, Miss. Torborg Danira      1           25   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...      5           26   \n",
       "26                             Emir, Mr. Farred Chehab      0           27   \n",
       "27                      Fortune, Mr. Charles Alexander      2           28   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"      0           29   \n",
       "29                                 Todoroff, Mr. Lalio      0           30   \n",
       "..                                                 ...    ...          ...   \n",
       "388                               Canavan, Mr. Patrick      0         1280   \n",
       "389                        Palsson, Master. Paul Folke      1         1281   \n",
       "390                         Payne, Mr. Vivian Ponsonby      0         1282   \n",
       "391     Lines, Mrs. Ernest H (Elizabeth Lindsey James)      1         1283   \n",
       "392                      Abbott, Master. Eugene Joseph      2         1284   \n",
       "393                               Gilbert, Mr. William      0         1285   \n",
       "394                           Kink-Heilmann, Mr. Anton      1         1286   \n",
       "395     Smith, Mrs. Lucien Philip (Mary Eloise Hughes)      0         1287   \n",
       "396                               Colbert, Mr. Patrick      0         1288   \n",
       "397  Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...      1         1289   \n",
       "398                     Larsson-Rondberg, Mr. Edvard A      0         1290   \n",
       "399                           Conlon, Mr. Thomas Henry      0         1291   \n",
       "400                            Bonnell, Miss. Caroline      0         1292   \n",
       "401                                    Gale, Mr. Harry      0         1293   \n",
       "402                     Gibson, Miss. Dorothy Winifred      1         1294   \n",
       "403                             Carrau, Mr. Jose Pedro      0         1295   \n",
       "404                       Frauenthal, Mr. Isaac Gerald      0         1296   \n",
       "405       Nourney, Mr. Alfred (Baron von Drachstedt\")\"      0         1297   \n",
       "406                          Ware, Mr. William Jeffery      0         1298   \n",
       "407                         Widener, Mr. George Dunton      1         1299   \n",
       "408                    Riordan, Miss. Johanna Hannah\"\"      0         1300   \n",
       "409                          Peacock, Miss. Treasteall      1         1301   \n",
       "410                             Naughton, Miss. Hannah      0         1302   \n",
       "411    Minahan, Mrs. William Edward (Lillian E Thorpe)      0         1303   \n",
       "412                     Henriksson, Miss. Jenny Lovisa      0         1304   \n",
       "413                                 Spector, Mr. Woolf      0         1305   \n",
       "414                       Oliva y Ocana, Dona. Fermina      0         1306   \n",
       "415                       Saether, Mr. Simon Sivertsen      0         1307   \n",
       "416                                Ware, Mr. Frederick      0         1308   \n",
       "417                           Peter, Master. Michael J      1         1309   \n",
       "\n",
       "     Pclass     Sex  SibSp  Survived              Ticket  \n",
       "0         3    male      1       0.0           A/5 21171  \n",
       "1         1  female      1       1.0            PC 17599  \n",
       "2         3  female      0       1.0    STON/O2. 3101282  \n",
       "3         1  female      1       1.0              113803  \n",
       "4         3    male      0       0.0              373450  \n",
       "5         3    male      0       0.0              330877  \n",
       "6         1    male      0       0.0               17463  \n",
       "7         3    male      3       0.0              349909  \n",
       "8         3  female      0       1.0              347742  \n",
       "9         2  female      1       1.0              237736  \n",
       "10        3  female      1       1.0             PP 9549  \n",
       "11        1  female      0       1.0              113783  \n",
       "12        3    male      0       0.0           A/5. 2151  \n",
       "13        3    male      1       0.0              347082  \n",
       "14        3  female      0       0.0              350406  \n",
       "15        2  female      0       1.0              248706  \n",
       "16        3    male      4       0.0              382652  \n",
       "17        2    male      0       1.0              244373  \n",
       "18        3  female      1       0.0              345763  \n",
       "19        3  female      0       1.0                2649  \n",
       "20        2    male      0       0.0              239865  \n",
       "21        2    male      0       1.0              248698  \n",
       "22        3  female      0       1.0              330923  \n",
       "23        1    male      0       1.0              113788  \n",
       "24        3  female      3       0.0              349909  \n",
       "25        3  female      1       1.0              347077  \n",
       "26        3    male      0       0.0                2631  \n",
       "27        1    male      3       0.0               19950  \n",
       "28        3  female      0       1.0              330959  \n",
       "29        3    male      0       0.0              349216  \n",
       "..      ...     ...    ...       ...                 ...  \n",
       "388       3    male      0       NaN              364858  \n",
       "389       3    male      3       NaN              349909  \n",
       "390       1    male      0       NaN               12749  \n",
       "391       1  female      0       NaN            PC 17592  \n",
       "392       3    male      0       NaN           C.A. 2673  \n",
       "393       2    male      0       NaN          C.A. 30769  \n",
       "394       3    male      3       NaN              315153  \n",
       "395       1  female      1       NaN               13695  \n",
       "396       3    male      0       NaN              371109  \n",
       "397       1  female      1       NaN               13567  \n",
       "398       3    male      0       NaN              347065  \n",
       "399       3    male      0       NaN               21332  \n",
       "400       1  female      0       NaN               36928  \n",
       "401       2    male      1       NaN               28664  \n",
       "402       1  female      0       NaN              112378  \n",
       "403       1    male      0       NaN              113059  \n",
       "404       1    male      1       NaN               17765  \n",
       "405       2    male      0       NaN       SC/PARIS 2166  \n",
       "406       2    male      1       NaN               28666  \n",
       "407       1    male      1       NaN              113503  \n",
       "408       3  female      0       NaN              334915  \n",
       "409       3  female      1       NaN  SOTON/O.Q. 3101315  \n",
       "410       3  female      0       NaN              365237  \n",
       "411       1  female      1       NaN               19928  \n",
       "412       3  female      0       NaN              347086  \n",
       "413       3    male      0       NaN           A.5. 3236  \n",
       "414       1  female      0       NaN            PC 17758  \n",
       "415       3    male      0       NaN  SOTON/O.Q. 3101262  \n",
       "416       3    male      0       NaN              359309  \n",
       "417       3    male      1       NaN                2668  \n",
       "\n",
       "[1309 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv(\"../data/titanic/train.csv\")\n",
    "test = pd.read_csv(\"../data/titanic/test.csv\")\n",
    "train = train.append(test) ## test 데이터도 학습에 이용.\n",
    "\n",
    "# inplace=True 로 해야 모든 컬럼에 대해 fillna 가 이뤄짐.\n",
    "# train.fillna(0, inplace=True) \n",
    "# test.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 8)\n",
      "(418, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  Pclass  SibSp  0_x  1  2  0_y\n",
       "0  22.0   7.2500      0       3      1    0  0  1    1\n",
       "1  38.0  71.2833      0       1      1    1  0  0    0\n",
       "2  26.0   7.9250      0       3      0    0  0  1    0\n",
       "3  35.0  53.1000      0       1      1    0  0  1    0\n",
       "4  35.0   8.0500      0       3      0    0  0  1    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# cols = PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "\n",
    "# 데이터 전처리 : 학습에 필요없는 column 제거.\n",
    "train.pop('Name'), test.pop('Name')\n",
    "train.pop('Ticket'), test.pop('Ticket')\n",
    "train.pop('Cabin'), test.pop('Cabin')\n",
    "train.pop('PassengerId'), test.pop('PassengerId') # 제거하지 않으면 passengerId 가 높을수록 predicton value 가 높은 현상\n",
    "\n",
    "# train 은 Nan data 제거하고, test 는 row 수를 유지하기 위해 drop 대신 fill.\n",
    "train.dropna(inplace=True)\n",
    "test.fillna(0, inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# 데이터 전처리 : One Hot Encoding\n",
    "# 성별, 승선지 는 String data. -> labelBinarizer를 이용해서 자동으로 one-hot-encoding\n",
    "# 컬럼의 data 종류 학습.\n",
    "# one-hot-encode 형태의 컬럼 추가.\n",
    "# 구 컬럼 삭제 ( DataFrame.pop() )\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "enc = encoder.fit(train[['Embarked']].astype(str))\n",
    "train = pd.merge(train, pd.DataFrame(enc.transform(train[['Embarked']].astype(str))) , right_index=True, left_index=True)\n",
    "test = pd.merge(test, pd.DataFrame(enc.transform(test[['Embarked']].astype(str))) , right_index=True, left_index=True)\n",
    "enc = encoder.fit(train[['Sex']].astype(str))\n",
    "train = pd.merge(train, pd.DataFrame(enc.transform(train[['Sex']].astype(str))) , right_index=True, left_index=True)\n",
    "test = pd.merge(test, pd.DataFrame(enc.transform(test[['Sex']].astype(str))) , right_index=True, left_index=True)\n",
    "train.pop('Embarked'), test.pop('Embarked')\n",
    "train.pop('Sex'), test.pop('Sex')\n",
    "\n",
    "# label\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "# feature\n",
    "train.pop('Survived')\n",
    "x_train = train\n",
    "x_test = test\n",
    "\n",
    "x_train.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### outlier detection #####\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# outlier_detection = DBSCAN(\n",
    "#     eps = 50,\n",
    "#     metric=\"euclidean\",\n",
    "#     n_jobs = -1)\n",
    "# clusters = outlier_detection.fit_predict(train[['Fare']])\n",
    "# clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixmax scaler, normalizer 등의 전처리 아직 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 264.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  182.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 대강의 label 분포 보기\n",
    "plt.hist(y_train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  0_x  1  2  0_y\n",
       "0       3  34.5      0      0   7.8292    0  1  0    1\n",
       "1       3  47.0      1      0   7.0000    0  0  1    0\n",
       "2       2  62.0      0      0   9.6875    0  1  0    1\n",
       "3       3  27.0      0      0   8.6625    0  0  1    1\n",
       "4       3  22.0      1      1  12.2875    0  0  1    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x1a2b58e1d0>>\n",
      "Train on 401 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "401/401 [==============================] - 1s 2ms/step - loss: 0.7134 - acc: 0.5287 - val_loss: 0.6940 - val_acc: 0.4667\n",
      "Epoch 2/500\n",
      "401/401 [==============================] - 0s 160us/step - loss: 0.6924 - acc: 0.5935 - val_loss: 0.6946 - val_acc: 0.4667\n",
      "Epoch 3/500\n",
      "401/401 [==============================] - 0s 163us/step - loss: 0.6893 - acc: 0.6010 - val_loss: 0.6948 - val_acc: 0.4667\n",
      "Epoch 4/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6895 - acc: 0.5960 - val_loss: 0.6949 - val_acc: 0.4667\n",
      "Epoch 5/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6884 - acc: 0.6060 - val_loss: 0.6954 - val_acc: 0.4667\n",
      "Epoch 6/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6873 - acc: 0.6060 - val_loss: 0.6956 - val_acc: 0.4667\n",
      "Epoch 7/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6870 - acc: 0.6060 - val_loss: 0.6961 - val_acc: 0.4667\n",
      "Epoch 8/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6860 - acc: 0.6060 - val_loss: 0.6968 - val_acc: 0.4667\n",
      "Epoch 9/500\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.6850 - acc: 0.6060 - val_loss: 0.6974 - val_acc: 0.4667\n",
      "Epoch 10/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6840 - acc: 0.6060 - val_loss: 0.6976 - val_acc: 0.4667\n",
      "Epoch 11/500\n",
      "401/401 [==============================] - 0s 143us/step - loss: 0.6839 - acc: 0.6060 - val_loss: 0.6977 - val_acc: 0.4667\n",
      "Epoch 12/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6836 - acc: 0.6060 - val_loss: 0.6984 - val_acc: 0.4667\n",
      "Epoch 13/500\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.6828 - acc: 0.6060 - val_loss: 0.6990 - val_acc: 0.4667\n",
      "Epoch 14/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6820 - acc: 0.6060 - val_loss: 0.6997 - val_acc: 0.4667\n",
      "Epoch 15/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6812 - acc: 0.6060 - val_loss: 0.7005 - val_acc: 0.4667\n",
      "Epoch 16/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6804 - acc: 0.6060 - val_loss: 0.7006 - val_acc: 0.4667\n",
      "Epoch 17/500\n",
      "401/401 [==============================] - 0s 134us/step - loss: 0.6803 - acc: 0.6060 - val_loss: 0.7007 - val_acc: 0.4667\n",
      "Epoch 18/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6802 - acc: 0.6060 - val_loss: 0.7014 - val_acc: 0.4667\n",
      "Epoch 19/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6795 - acc: 0.6060 - val_loss: 0.7022 - val_acc: 0.4667\n",
      "Epoch 20/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6788 - acc: 0.6060 - val_loss: 0.7030 - val_acc: 0.4667\n",
      "Epoch 21/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6781 - acc: 0.6060 - val_loss: 0.7039 - val_acc: 0.4667\n",
      "Epoch 22/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6775 - acc: 0.6060 - val_loss: 0.7047 - val_acc: 0.4667\n",
      "Epoch 23/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6769 - acc: 0.6060 - val_loss: 0.7047 - val_acc: 0.4667\n",
      "Epoch 24/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6769 - acc: 0.6060 - val_loss: 0.7047 - val_acc: 0.4667\n",
      "Epoch 25/500\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.6769 - acc: 0.6060 - val_loss: 0.7055 - val_acc: 0.4667\n",
      "Epoch 26/500\n",
      "401/401 [==============================] - 0s 152us/step - loss: 0.6764 - acc: 0.6060 - val_loss: 0.7055 - val_acc: 0.4667\n",
      "Epoch 27/500\n",
      "401/401 [==============================] - 0s 152us/step - loss: 0.6764 - acc: 0.6060 - val_loss: 0.7055 - val_acc: 0.4667\n",
      "Epoch 28/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6764 - acc: 0.6060 - val_loss: 0.7063 - val_acc: 0.4667\n",
      "Epoch 29/500\n",
      "401/401 [==============================] - 0s 134us/step - loss: 0.6759 - acc: 0.6060 - val_loss: 0.7071 - val_acc: 0.4667\n",
      "Epoch 30/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6755 - acc: 0.6060 - val_loss: 0.7080 - val_acc: 0.4667\n",
      "Epoch 31/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6750 - acc: 0.6060 - val_loss: 0.7080 - val_acc: 0.4667\n",
      "Epoch 32/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6751 - acc: 0.6060 - val_loss: 0.7079 - val_acc: 0.4667\n",
      "Epoch 33/500\n",
      "401/401 [==============================] - 0s 138us/step - loss: 0.6750 - acc: 0.6060 - val_loss: 0.7087 - val_acc: 0.4667\n",
      "Epoch 34/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6747 - acc: 0.6060 - val_loss: 0.7096 - val_acc: 0.4667\n",
      "Epoch 35/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6743 - acc: 0.6060 - val_loss: 0.7094 - val_acc: 0.4667\n",
      "Epoch 36/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6743 - acc: 0.6060 - val_loss: 0.7103 - val_acc: 0.4667\n",
      "Epoch 37/500\n",
      "401/401 [==============================] - 0s 151us/step - loss: 0.6740 - acc: 0.6060 - val_loss: 0.7111 - val_acc: 0.4667\n",
      "Epoch 38/500\n",
      "401/401 [==============================] - 0s 144us/step - loss: 0.6736 - acc: 0.6060 - val_loss: 0.7110 - val_acc: 0.4667\n",
      "Epoch 39/500\n",
      "401/401 [==============================] - 0s 146us/step - loss: 0.6737 - acc: 0.6060 - val_loss: 0.7119 - val_acc: 0.4667\n",
      "Epoch 40/500\n",
      "401/401 [==============================] - 0s 218us/step - loss: 0.6733 - acc: 0.6060 - val_loss: 0.7118 - val_acc: 0.4667\n",
      "Epoch 41/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6734 - acc: 0.6060 - val_loss: 0.7126 - val_acc: 0.4667\n",
      "Epoch 42/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6731 - acc: 0.6060 - val_loss: 0.7134 - val_acc: 0.4667\n",
      "Epoch 43/500\n",
      "401/401 [==============================] - 0s 134us/step - loss: 0.6728 - acc: 0.6060 - val_loss: 0.7143 - val_acc: 0.4667\n",
      "Epoch 44/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6725 - acc: 0.6060 - val_loss: 0.7142 - val_acc: 0.4667\n",
      "Epoch 45/500\n",
      "401/401 [==============================] - 0s 144us/step - loss: 0.6726 - acc: 0.6060 - val_loss: 0.7150 - val_acc: 0.4667\n",
      "Epoch 46/500\n",
      "401/401 [==============================] - 0s 155us/step - loss: 0.6724 - acc: 0.6060 - val_loss: 0.7158 - val_acc: 0.4667\n",
      "Epoch 47/500\n",
      "401/401 [==============================] - 0s 143us/step - loss: 0.6722 - acc: 0.6060 - val_loss: 0.7167 - val_acc: 0.4667\n",
      "Epoch 48/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6719 - acc: 0.6060 - val_loss: 0.7164 - val_acc: 0.4667\n",
      "Epoch 49/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6720 - acc: 0.6060 - val_loss: 0.7162 - val_acc: 0.4667\n",
      "Epoch 50/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6721 - acc: 0.6060 - val_loss: 0.7169 - val_acc: 0.4667\n",
      "Epoch 51/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6719 - acc: 0.6060 - val_loss: 0.7178 - val_acc: 0.4667\n",
      "Epoch 52/500\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.6717 - acc: 0.6060 - val_loss: 0.7174 - val_acc: 0.4667\n",
      "Epoch 53/500\n",
      "401/401 [==============================] - 0s 150us/step - loss: 0.6718 - acc: 0.6060 - val_loss: 0.7183 - val_acc: 0.4667\n",
      "Epoch 54/500\n",
      "401/401 [==============================] - 0s 163us/step - loss: 0.6716 - acc: 0.6060 - val_loss: 0.7192 - val_acc: 0.4667\n",
      "Epoch 55/500\n",
      "401/401 [==============================] - 0s 168us/step - loss: 0.6714 - acc: 0.6060 - val_loss: 0.7201 - val_acc: 0.4667\n",
      "Epoch 56/500\n",
      "401/401 [==============================] - 0s 152us/step - loss: 0.6713 - acc: 0.6060 - val_loss: 0.7210 - val_acc: 0.4667\n",
      "Epoch 57/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6712 - acc: 0.6060 - val_loss: 0.7218 - val_acc: 0.4667\n",
      "Epoch 58/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6711 - acc: 0.6060 - val_loss: 0.7226 - val_acc: 0.4667\n",
      "Epoch 59/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.7235 - val_acc: 0.4667\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 126us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7244 - val_acc: 0.4667\n",
      "Epoch 61/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7238 - val_acc: 0.4667\n",
      "Epoch 62/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7246 - val_acc: 0.4667\n",
      "Epoch 63/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7254 - val_acc: 0.4667\n",
      "Epoch 64/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7262 - val_acc: 0.4667\n",
      "Epoch 65/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7271 - val_acc: 0.4667\n",
      "Epoch 66/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7279 - val_acc: 0.4667\n",
      "Epoch 67/500\n",
      "401/401 [==============================] - 0s 144us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7287 - val_acc: 0.4667\n",
      "Epoch 68/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7280 - val_acc: 0.4667\n",
      "Epoch 69/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7286 - val_acc: 0.4667\n",
      "Epoch 70/500\n",
      "401/401 [==============================] - 0s 164us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7293 - val_acc: 0.4667\n",
      "Epoch 71/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7284 - val_acc: 0.4667\n",
      "Epoch 72/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7278 - val_acc: 0.4667\n",
      "Epoch 73/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7272 - val_acc: 0.4667\n",
      "Epoch 74/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7266 - val_acc: 0.4667\n",
      "Epoch 75/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7273 - val_acc: 0.4667\n",
      "Epoch 76/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7266 - val_acc: 0.4667\n",
      "Epoch 77/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7273 - val_acc: 0.4667\n",
      "Epoch 78/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7265 - val_acc: 0.4667\n",
      "Epoch 79/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7272 - val_acc: 0.4667\n",
      "Epoch 80/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7265 - val_acc: 0.4667\n",
      "Epoch 81/500\n",
      "401/401 [==============================] - 0s 110us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7272 - val_acc: 0.4667\n",
      "Epoch 82/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7266 - val_acc: 0.4667\n",
      "Epoch 83/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7272 - val_acc: 0.4667\n",
      "Epoch 84/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7280 - val_acc: 0.4667\n",
      "Epoch 85/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7273 - val_acc: 0.4667\n",
      "Epoch 86/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7280 - val_acc: 0.4667\n",
      "Epoch 87/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7273 - val_acc: 0.4667\n",
      "Epoch 88/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7266 - val_acc: 0.4667\n",
      "Epoch 89/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7260 - val_acc: 0.4667\n",
      "Epoch 90/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7267 - val_acc: 0.4667\n",
      "Epoch 91/500\n",
      "401/401 [==============================] - 0s 113us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7261 - val_acc: 0.4667\n",
      "Epoch 92/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7255 - val_acc: 0.4667\n",
      "Epoch 93/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7262 - val_acc: 0.4667\n",
      "Epoch 94/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7269 - val_acc: 0.4667\n",
      "Epoch 95/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7277 - val_acc: 0.4667\n",
      "Epoch 96/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7285 - val_acc: 0.4667\n",
      "Epoch 97/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7277 - val_acc: 0.4667\n",
      "Epoch 98/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7284 - val_acc: 0.4667\n",
      "Epoch 99/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7291 - val_acc: 0.4667\n",
      "Epoch 100/500\n",
      "401/401 [==============================] - 0s 109us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7284 - val_acc: 0.4667\n",
      "Epoch 101/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7276 - val_acc: 0.4667\n",
      "Epoch 102/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7270 - val_acc: 0.4667\n",
      "Epoch 103/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7276 - val_acc: 0.4667\n",
      "Epoch 104/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7283 - val_acc: 0.4667\n",
      "Epoch 105/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7291 - val_acc: 0.4667\n",
      "Epoch 106/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7299 - val_acc: 0.4667\n",
      "Epoch 107/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7291 - val_acc: 0.4667\n",
      "Epoch 108/500\n",
      "401/401 [==============================] - 0s 111us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7298 - val_acc: 0.4667\n",
      "Epoch 109/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7305 - val_acc: 0.4667\n",
      "Epoch 110/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7297 - val_acc: 0.4667\n",
      "Epoch 111/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7290 - val_acc: 0.4667\n",
      "Epoch 112/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7297 - val_acc: 0.4667\n",
      "Epoch 113/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7304 - val_acc: 0.4667\n",
      "Epoch 114/500\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7310 - val_acc: 0.4667\n",
      "Epoch 115/500\n",
      "401/401 [==============================] - 0s 150us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7317 - val_acc: 0.4667\n",
      "Epoch 116/500\n",
      "401/401 [==============================] - 0s 142us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7308 - val_acc: 0.4667\n",
      "Epoch 117/500\n",
      "401/401 [==============================] - 0s 154us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7315 - val_acc: 0.4667\n",
      "Epoch 118/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7307 - val_acc: 0.4667\n",
      "Epoch 119/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7313 - val_acc: 0.4667\n",
      "Epoch 120/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 142us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7319 - val_acc: 0.4667\n",
      "Epoch 121/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7311 - val_acc: 0.4667\n",
      "Epoch 122/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7318 - val_acc: 0.4667\n",
      "Epoch 123/500\n",
      "401/401 [==============================] - 0s 138us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7309 - val_acc: 0.4667\n",
      "Epoch 124/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7315 - val_acc: 0.4667\n",
      "Epoch 125/500\n",
      "401/401 [==============================] - 0s 138us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7322 - val_acc: 0.4667\n",
      "Epoch 126/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7313 - val_acc: 0.4667\n",
      "Epoch 127/500\n",
      "401/401 [==============================] - 0s 138us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7319 - val_acc: 0.4667\n",
      "Epoch 128/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7326 - val_acc: 0.4667\n",
      "Epoch 129/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7317 - val_acc: 0.4667\n",
      "Epoch 130/500\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7308 - val_acc: 0.4667\n",
      "Epoch 131/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7313 - val_acc: 0.4667\n",
      "Epoch 132/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7320 - val_acc: 0.4667\n",
      "Epoch 133/500\n",
      "401/401 [==============================] - 0s 146us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7312 - val_acc: 0.4667\n",
      "Epoch 134/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7304 - val_acc: 0.4667\n",
      "Epoch 135/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7311 - val_acc: 0.4667\n",
      "Epoch 136/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7317 - val_acc: 0.4667\n",
      "Epoch 137/500\n",
      "401/401 [==============================] - 0s 111us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7324 - val_acc: 0.4667\n",
      "Epoch 138/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7315 - val_acc: 0.4667\n",
      "Epoch 139/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7307 - val_acc: 0.4667\n",
      "Epoch 140/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7313 - val_acc: 0.4667\n",
      "Epoch 141/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7320 - val_acc: 0.4667\n",
      "Epoch 142/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7326 - val_acc: 0.4667\n",
      "Epoch 143/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7333 - val_acc: 0.4667\n",
      "Epoch 144/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7340 - val_acc: 0.4667\n",
      "Epoch 145/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7329 - val_acc: 0.4667\n",
      "Epoch 146/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7334 - val_acc: 0.4667\n",
      "Epoch 147/500\n",
      "401/401 [==============================] - 0s 152us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 148/500\n",
      "401/401 [==============================] - 0s 141us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7332 - val_acc: 0.4667\n",
      "Epoch 149/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7323 - val_acc: 0.4667\n",
      "Epoch 150/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7328 - val_acc: 0.4667\n",
      "Epoch 151/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 152/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7325 - val_acc: 0.4667\n",
      "Epoch 153/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7317 - val_acc: 0.4667\n",
      "Epoch 154/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7323 - val_acc: 0.4667\n",
      "Epoch 155/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7329 - val_acc: 0.4667\n",
      "Epoch 156/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 157/500\n",
      "401/401 [==============================] - 0s 161us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 158/500\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7332 - val_acc: 0.4667\n",
      "Epoch 159/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7324 - val_acc: 0.4667\n",
      "Epoch 160/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7330 - val_acc: 0.4667\n",
      "Epoch 161/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7337 - val_acc: 0.4667\n",
      "Epoch 162/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7343 - val_acc: 0.4667\n",
      "Epoch 163/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7333 - val_acc: 0.4667\n",
      "Epoch 164/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7338 - val_acc: 0.4667\n",
      "Epoch 165/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7328 - val_acc: 0.4667\n",
      "Epoch 166/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 167/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 168/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7331 - val_acc: 0.4667\n",
      "Epoch 169/500\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7338 - val_acc: 0.4667\n",
      "Epoch 170/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7344 - val_acc: 0.4667\n",
      "Epoch 171/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7351 - val_acc: 0.4667\n",
      "Epoch 172/500\n",
      "401/401 [==============================] - ETA: 0s - loss: 0.6271 - acc: 0.700 - 0s 127us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7340 - val_acc: 0.4667\n",
      "Epoch 173/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7346 - val_acc: 0.4667\n",
      "Epoch 174/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7353 - val_acc: 0.4667\n",
      "Epoch 175/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7359 - val_acc: 0.4667\n",
      "Epoch 176/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7349 - val_acc: 0.4667\n",
      "Epoch 177/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7354 - val_acc: 0.4667\n",
      "Epoch 178/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7360 - val_acc: 0.4667\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 124us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7349 - val_acc: 0.4667\n",
      "Epoch 180/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 181/500\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7361 - val_acc: 0.4667\n",
      "Epoch 182/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 183/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 184/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7345 - val_acc: 0.4667\n",
      "Epoch 185/500\n",
      "401/401 [==============================] - 0s 110us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7336 - val_acc: 0.4667\n",
      "Epoch 186/500\n",
      "401/401 [==============================] - 0s 112us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7328 - val_acc: 0.4667\n",
      "Epoch 187/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7319 - val_acc: 0.4667\n",
      "Epoch 188/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7326 - val_acc: 0.4667\n",
      "Epoch 189/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7333 - val_acc: 0.4667\n",
      "Epoch 190/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7323 - val_acc: 0.4667\n",
      "Epoch 191/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7328 - val_acc: 0.4667\n",
      "Epoch 192/500\n",
      "401/401 [==============================] - 0s 198us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 193/500\n",
      "401/401 [==============================] - 0s 212us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7325 - val_acc: 0.4667\n",
      "Epoch 194/500\n",
      "401/401 [==============================] - 0s 149us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7331 - val_acc: 0.4667\n",
      "Epoch 195/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7337 - val_acc: 0.4667\n",
      "Epoch 196/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7328 - val_acc: 0.4667\n",
      "Epoch 197/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7319 - val_acc: 0.4667\n",
      "Epoch 198/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7324 - val_acc: 0.4667\n",
      "Epoch 199/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7316 - val_acc: 0.4667\n",
      "Epoch 200/500\n",
      "401/401 [==============================] - 0s 141us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7309 - val_acc: 0.4667\n",
      "Epoch 201/500\n",
      "401/401 [==============================] - 0s 164us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7301 - val_acc: 0.4667\n",
      "Epoch 202/500\n",
      "401/401 [==============================] - 0s 151us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7293 - val_acc: 0.4667\n",
      "Epoch 203/500\n",
      "401/401 [==============================] - 0s 163us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7299 - val_acc: 0.4667\n",
      "Epoch 204/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7306 - val_acc: 0.4667\n",
      "Epoch 205/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7314 - val_acc: 0.4667\n",
      "Epoch 206/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7321 - val_acc: 0.4667\n",
      "Epoch 207/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7327 - val_acc: 0.4667\n",
      "Epoch 208/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7334 - val_acc: 0.4667\n",
      "Epoch 209/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7325 - val_acc: 0.4667\n",
      "Epoch 210/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7332 - val_acc: 0.4667\n",
      "Epoch 211/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7339 - val_acc: 0.4667\n",
      "Epoch 212/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7345 - val_acc: 0.4667\n",
      "Epoch 213/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 214/500\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7340 - val_acc: 0.4667\n",
      "Epoch 215/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7347 - val_acc: 0.4667\n",
      "Epoch 216/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7353 - val_acc: 0.4667\n",
      "Epoch 217/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7342 - val_acc: 0.4667\n",
      "Epoch 218/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7348 - val_acc: 0.4667\n",
      "Epoch 219/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 220/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7361 - val_acc: 0.4667\n",
      "Epoch 221/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 222/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 223/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7345 - val_acc: 0.4667\n",
      "Epoch 224/500\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7351 - val_acc: 0.4667\n",
      "Epoch 225/500\n",
      "401/401 [==============================] - 0s 154us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7357 - val_acc: 0.4667\n",
      "Epoch 226/500\n",
      "401/401 [==============================] - 0s 157us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7363 - val_acc: 0.4667\n",
      "Epoch 227/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7352 - val_acc: 0.4667\n",
      "Epoch 228/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7358 - val_acc: 0.4667\n",
      "Epoch 229/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7347 - val_acc: 0.4667\n",
      "Epoch 230/500\n",
      "401/401 [==============================] - 0s 112us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7353 - val_acc: 0.4667\n",
      "Epoch 231/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7358 - val_acc: 0.4667\n",
      "Epoch 232/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7365 - val_acc: 0.4667\n",
      "Epoch 233/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 234/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7359 - val_acc: 0.4667\n",
      "Epoch 235/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7349 - val_acc: 0.4667\n",
      "Epoch 236/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 237/500\n",
      "401/401 [==============================] - 0s 144us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7360 - val_acc: 0.4667\n",
      "Epoch 238/500\n",
      "401/401 [==============================] - 0s 146us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7366 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 240/500\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7377 - val_acc: 0.4667\n",
      "Epoch 241/500\n",
      "401/401 [==============================] - 0s 139us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7365 - val_acc: 0.4667\n",
      "Epoch 242/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 243/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7359 - val_acc: 0.4667\n",
      "Epoch 244/500\n",
      "401/401 [==============================] - 0s 112us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 245/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7356 - val_acc: 0.4667\n",
      "Epoch 246/500\n",
      "401/401 [==============================] - 0s 109us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7361 - val_acc: 0.4667\n",
      "Epoch 247/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7367 - val_acc: 0.4667\n",
      "Epoch 248/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7356 - val_acc: 0.4667\n",
      "Epoch 249/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7362 - val_acc: 0.4667\n",
      "Epoch 250/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7368 - val_acc: 0.4667\n",
      "Epoch 251/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7373 - val_acc: 0.4667\n",
      "Epoch 252/500\n",
      "401/401 [==============================] - 0s 138us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7361 - val_acc: 0.4667\n",
      "Epoch 253/500\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7367 - val_acc: 0.4667\n",
      "Epoch 254/500\n",
      "401/401 [==============================] - 0s 159us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7356 - val_acc: 0.4667\n",
      "Epoch 255/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7362 - val_acc: 0.4667\n",
      "Epoch 256/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7352 - val_acc: 0.4667\n",
      "Epoch 257/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7357 - val_acc: 0.4667\n",
      "Epoch 258/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7363 - val_acc: 0.4667\n",
      "Epoch 259/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7352 - val_acc: 0.4667\n",
      "Epoch 260/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7358 - val_acc: 0.4667\n",
      "Epoch 261/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7364 - val_acc: 0.4667\n",
      "Epoch 262/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 263/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7376 - val_acc: 0.4667\n",
      "Epoch 264/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7382 - val_acc: 0.4667\n",
      "Epoch 265/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7388 - val_acc: 0.4667\n",
      "Epoch 266/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7376 - val_acc: 0.4667\n",
      "Epoch 267/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7381 - val_acc: 0.4667\n",
      "Epoch 268/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7369 - val_acc: 0.4667\n",
      "Epoch 269/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7375 - val_acc: 0.4667\n",
      "Epoch 270/500\n",
      "401/401 [==============================] - 0s 149us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7364 - val_acc: 0.4667\n",
      "Epoch 271/500\n",
      "401/401 [==============================] - 0s 146us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 272/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7360 - val_acc: 0.4667\n",
      "Epoch 273/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 274/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7356 - val_acc: 0.4667\n",
      "Epoch 275/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7362 - val_acc: 0.4667\n",
      "Epoch 276/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7367 - val_acc: 0.4667\n",
      "Epoch 277/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7357 - val_acc: 0.4667\n",
      "Epoch 278/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7347 - val_acc: 0.4667\n",
      "Epoch 279/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7338 - val_acc: 0.4667\n",
      "Epoch 280/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7329 - val_acc: 0.4667\n",
      "Epoch 281/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 282/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 283/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7331 - val_acc: 0.4667\n",
      "Epoch 284/500\n",
      "401/401 [==============================] - 0s 173us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7337 - val_acc: 0.4667\n",
      "Epoch 285/500\n",
      "401/401 [==============================] - 0s 141us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7328 - val_acc: 0.4667\n",
      "Epoch 286/500\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7334 - val_acc: 0.4667\n",
      "Epoch 287/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7340 - val_acc: 0.4667\n",
      "Epoch 288/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7347 - val_acc: 0.4667\n",
      "Epoch 289/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7353 - val_acc: 0.4667\n",
      "Epoch 290/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7359 - val_acc: 0.4667\n",
      "Epoch 291/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7365 - val_acc: 0.4667\n",
      "Epoch 292/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 293/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7376 - val_acc: 0.4667\n",
      "Epoch 294/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7363 - val_acc: 0.4667\n",
      "Epoch 295/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7369 - val_acc: 0.4667\n",
      "Epoch 296/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7374 - val_acc: 0.4667\n",
      "Epoch 297/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7380 - val_acc: 0.4667\n",
      "Epoch 298/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7368 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7359 - val_acc: 0.4667\n",
      "Epoch 300/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7364 - val_acc: 0.4667\n",
      "Epoch 301/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 302/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7376 - val_acc: 0.4667\n",
      "Epoch 303/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7381 - val_acc: 0.4667\n",
      "Epoch 304/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 305/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7375 - val_acc: 0.4667\n",
      "Epoch 306/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7380 - val_acc: 0.4667\n",
      "Epoch 307/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7386 - val_acc: 0.4667\n",
      "Epoch 308/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7392 - val_acc: 0.4667\n",
      "Epoch 309/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7397 - val_acc: 0.4667\n",
      "Epoch 310/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.7384 - val_acc: 0.4667\n",
      "Epoch 311/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7389 - val_acc: 0.4667\n",
      "Epoch 312/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7377 - val_acc: 0.4667\n",
      "Epoch 313/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7382 - val_acc: 0.4667\n",
      "Epoch 314/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7371 - val_acc: 0.4667\n",
      "Epoch 315/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7375 - val_acc: 0.4667\n",
      "Epoch 316/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7380 - val_acc: 0.4667\n",
      "Epoch 317/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7386 - val_acc: 0.4667\n",
      "Epoch 318/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7392 - val_acc: 0.4667\n",
      "Epoch 319/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.7398 - val_acc: 0.4667\n",
      "Epoch 320/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.7385 - val_acc: 0.4667\n",
      "Epoch 321/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7390 - val_acc: 0.4667\n",
      "Epoch 322/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7377 - val_acc: 0.4667\n",
      "Epoch 323/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7382 - val_acc: 0.4667\n",
      "Epoch 324/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7371 - val_acc: 0.4667\n",
      "Epoch 325/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7376 - val_acc: 0.4667\n",
      "Epoch 326/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7382 - val_acc: 0.4667\n",
      "Epoch 327/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 328/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7375 - val_acc: 0.4667\n",
      "Epoch 329/500\n",
      "401/401 [==============================] - 0s 134us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7380 - val_acc: 0.4667\n",
      "Epoch 330/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7368 - val_acc: 0.4667\n",
      "Epoch 331/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7374 - val_acc: 0.4667\n",
      "Epoch 332/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7364 - val_acc: 0.4667\n",
      "Epoch 333/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7354 - val_acc: 0.4667\n",
      "Epoch 334/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7344 - val_acc: 0.4667\n",
      "Epoch 335/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7336 - val_acc: 0.4667\n",
      "Epoch 336/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 337/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7348 - val_acc: 0.4667\n",
      "Epoch 338/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7353 - val_acc: 0.4667\n",
      "Epoch 339/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7343 - val_acc: 0.4667\n",
      "Epoch 340/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7348 - val_acc: 0.4667\n",
      "Epoch 341/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7339 - val_acc: 0.4667\n",
      "Epoch 342/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7330 - val_acc: 0.4667\n",
      "Epoch 343/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 344/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 345/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7332 - val_acc: 0.4667\n",
      "Epoch 346/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7337 - val_acc: 0.4667\n",
      "Epoch 347/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7343 - val_acc: 0.4667\n",
      "Epoch 348/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7349 - val_acc: 0.4667\n",
      "Epoch 349/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7339 - val_acc: 0.4667\n",
      "Epoch 350/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7346 - val_acc: 0.4667\n",
      "Epoch 351/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7351 - val_acc: 0.4667\n",
      "Epoch 352/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 353/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7347 - val_acc: 0.4667\n",
      "Epoch 354/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7354 - val_acc: 0.4667\n",
      "Epoch 355/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7343 - val_acc: 0.4667\n",
      "Epoch 356/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7333 - val_acc: 0.4667\n",
      "Epoch 357/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7339 - val_acc: 0.4667\n",
      "Epoch 358/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7330 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 360/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7326 - val_acc: 0.4667\n",
      "Epoch 361/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7317 - val_acc: 0.4667\n",
      "Epoch 362/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7323 - val_acc: 0.4667\n",
      "Epoch 363/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7330 - val_acc: 0.4667\n",
      "Epoch 364/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7336 - val_acc: 0.4667\n",
      "Epoch 365/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7326 - val_acc: 0.4667\n",
      "Epoch 366/500\n",
      "401/401 [==============================] - 0s 109us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7332 - val_acc: 0.4667\n",
      "Epoch 367/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7323 - val_acc: 0.4667\n",
      "Epoch 368/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7329 - val_acc: 0.4667\n",
      "Epoch 369/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7320 - val_acc: 0.4667\n",
      "Epoch 370/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7326 - val_acc: 0.4667\n",
      "Epoch 371/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7318 - val_acc: 0.4667\n",
      "Epoch 372/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7324 - val_acc: 0.4667\n",
      "Epoch 373/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7314 - val_acc: 0.4667\n",
      "Epoch 374/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7321 - val_acc: 0.4667\n",
      "Epoch 375/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7313 - val_acc: 0.4667\n",
      "Epoch 376/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7319 - val_acc: 0.4667\n",
      "Epoch 377/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7310 - val_acc: 0.4667\n",
      "Epoch 378/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7316 - val_acc: 0.4667\n",
      "Epoch 379/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7322 - val_acc: 0.4667\n",
      "Epoch 380/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7329 - val_acc: 0.4667\n",
      "Epoch 381/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7336 - val_acc: 0.4667\n",
      "Epoch 382/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7343 - val_acc: 0.4667\n",
      "Epoch 383/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7333 - val_acc: 0.4667\n",
      "Epoch 384/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7338 - val_acc: 0.4667\n",
      "Epoch 385/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7329 - val_acc: 0.4667\n",
      "Epoch 386/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7334 - val_acc: 0.4667\n",
      "Epoch 387/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7340 - val_acc: 0.4667\n",
      "Epoch 388/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7346 - val_acc: 0.4667\n",
      "Epoch 389/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7352 - val_acc: 0.4667\n",
      "Epoch 390/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7342 - val_acc: 0.4667\n",
      "Epoch 391/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7348 - val_acc: 0.4667\n",
      "Epoch 392/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7354 - val_acc: 0.4667\n",
      "Epoch 393/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7343 - val_acc: 0.4667\n",
      "Epoch 394/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7349 - val_acc: 0.4667\n",
      "Epoch 395/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7339 - val_acc: 0.4667\n",
      "Epoch 396/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7330 - val_acc: 0.4667\n",
      "Epoch 397/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7322 - val_acc: 0.4667\n",
      "Epoch 398/500\n",
      "401/401 [==============================] - 0s 113us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7314 - val_acc: 0.4667\n",
      "Epoch 399/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7320 - val_acc: 0.4667\n",
      "Epoch 400/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7326 - val_acc: 0.4667\n",
      "Epoch 401/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7332 - val_acc: 0.4667\n",
      "Epoch 402/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7339 - val_acc: 0.4667\n",
      "Epoch 403/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7345 - val_acc: 0.4667\n",
      "Epoch 404/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7351 - val_acc: 0.4667\n",
      "Epoch 405/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7357 - val_acc: 0.4667\n",
      "Epoch 406/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7347 - val_acc: 0.4667\n",
      "Epoch 407/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7353 - val_acc: 0.4667\n",
      "Epoch 408/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7359 - val_acc: 0.4667\n",
      "Epoch 409/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7365 - val_acc: 0.4667\n",
      "Epoch 410/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7372 - val_acc: 0.4667\n",
      "Epoch 411/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7377 - val_acc: 0.4667\n",
      "Epoch 412/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7383 - val_acc: 0.4667\n",
      "Epoch 413/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7372 - val_acc: 0.4667\n",
      "Epoch 414/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7362 - val_acc: 0.4667\n",
      "Epoch 415/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7352 - val_acc: 0.4667\n",
      "Epoch 416/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7344 - val_acc: 0.4667\n",
      "Epoch 417/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7349 - val_acc: 0.4667\n",
      "Epoch 418/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7345 - val_acc: 0.4667\n",
      "Epoch 420/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 421/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7342 - val_acc: 0.4667\n",
      "Epoch 422/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7348 - val_acc: 0.4667\n",
      "Epoch 423/500\n",
      "401/401 [==============================] - 0s 148us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7354 - val_acc: 0.4667\n",
      "Epoch 424/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7344 - val_acc: 0.4667\n",
      "Epoch 425/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 426/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 427/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7345 - val_acc: 0.4667\n",
      "Epoch 428/500\n",
      "401/401 [==============================] - 0s 129us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 429/500\n",
      "401/401 [==============================] - 0s 160us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 430/500\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7348 - val_acc: 0.4667\n",
      "Epoch 431/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7338 - val_acc: 0.4667\n",
      "Epoch 432/500\n",
      "401/401 [==============================] - 0s 128us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7329 - val_acc: 0.4667\n",
      "Epoch 433/500\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7320 - val_acc: 0.4667\n",
      "Epoch 434/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7326 - val_acc: 0.4667\n",
      "Epoch 435/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6705 - acc: 0.6060 - val_loss: 0.7332 - val_acc: 0.4667\n",
      "Epoch 436/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7323 - val_acc: 0.4667\n",
      "Epoch 437/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7329 - val_acc: 0.4667\n",
      "Epoch 438/500\n",
      "401/401 [==============================] - 0s 131us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 439/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7340 - val_acc: 0.4667\n",
      "Epoch 440/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7346 - val_acc: 0.4667\n",
      "Epoch 441/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7353 - val_acc: 0.4667\n",
      "Epoch 442/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7360 - val_acc: 0.4667\n",
      "Epoch 443/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 444/500\n",
      "401/401 [==============================] - 0s 118us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7340 - val_acc: 0.4667\n",
      "Epoch 445/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7346 - val_acc: 0.4667\n",
      "Epoch 446/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7337 - val_acc: 0.4667\n",
      "Epoch 447/500\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7344 - val_acc: 0.4667\n",
      "Epoch 448/500\n",
      "401/401 [==============================] - 0s 146us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7349 - val_acc: 0.4667\n",
      "Epoch 449/500\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 450/500\n",
      "401/401 [==============================] - 0s 182us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7344 - val_acc: 0.4667\n",
      "Epoch 451/500\n",
      "401/401 [==============================] - 0s 160us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7335 - val_acc: 0.4667\n",
      "Epoch 452/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 453/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7348 - val_acc: 0.4667\n",
      "Epoch 454/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7337 - val_acc: 0.4667\n",
      "Epoch 455/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7343 - val_acc: 0.4667\n",
      "Epoch 456/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7348 - val_acc: 0.4667\n",
      "Epoch 457/500\n",
      "401/401 [==============================] - 0s 117us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7354 - val_acc: 0.4667\n",
      "Epoch 458/500\n",
      "401/401 [==============================] - 0s 109us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7361 - val_acc: 0.4667\n",
      "Epoch 459/500\n",
      "401/401 [==============================] - 0s 113us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7366 - val_acc: 0.4667\n",
      "Epoch 460/500\n",
      "401/401 [==============================] - 0s 150us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7371 - val_acc: 0.4667\n",
      "Epoch 461/500\n",
      "401/401 [==============================] - 0s 151us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7377 - val_acc: 0.4667\n",
      "Epoch 462/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7383 - val_acc: 0.4667\n",
      "Epoch 463/500\n",
      "401/401 [==============================] - 0s 122us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7388 - val_acc: 0.4667\n",
      "Epoch 464/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7393 - val_acc: 0.4667\n",
      "Epoch 465/500\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.7399 - val_acc: 0.4667\n",
      "Epoch 466/500\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.7386 - val_acc: 0.4667\n",
      "Epoch 467/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7392 - val_acc: 0.4667\n",
      "Epoch 468/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7380 - val_acc: 0.4667\n",
      "Epoch 469/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7371 - val_acc: 0.4667\n",
      "Epoch 470/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7361 - val_acc: 0.4667\n",
      "Epoch 471/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7366 - val_acc: 0.4667\n",
      "Epoch 472/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7372 - val_acc: 0.4667\n",
      "Epoch 473/500\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7360 - val_acc: 0.4667\n",
      "Epoch 474/500\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 475/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7341 - val_acc: 0.4667\n",
      "Epoch 476/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7346 - val_acc: 0.4667\n",
      "Epoch 477/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7352 - val_acc: 0.4667\n",
      "Epoch 478/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7358 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/500\n",
      "401/401 [==============================] - 0s 114us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7364 - val_acc: 0.4667\n",
      "Epoch 480/500\n",
      "401/401 [==============================] - 0s 115us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7371 - val_acc: 0.4667\n",
      "Epoch 481/500\n",
      "401/401 [==============================] - 0s 119us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7359 - val_acc: 0.4667\n",
      "Epoch 482/500\n",
      "401/401 [==============================] - 0s 126us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7364 - val_acc: 0.4667\n",
      "Epoch 483/500\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7370 - val_acc: 0.4667\n",
      "Epoch 484/500\n",
      "401/401 [==============================] - 0s 151us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7360 - val_acc: 0.4667\n",
      "Epoch 485/500\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 486/500\n",
      "401/401 [==============================] - 0s 144us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7356 - val_acc: 0.4667\n",
      "Epoch 487/500\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7346 - val_acc: 0.4667\n",
      "Epoch 488/500\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7338 - val_acc: 0.4667\n",
      "Epoch 489/500\n",
      "401/401 [==============================] - 0s 141us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7343 - val_acc: 0.4667\n",
      "Epoch 490/500\n",
      "401/401 [==============================] - 0s 124us/step - loss: 0.6706 - acc: 0.6060 - val_loss: 0.7349 - val_acc: 0.4667\n",
      "Epoch 491/500\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7355 - val_acc: 0.4667\n",
      "Epoch 492/500\n",
      "401/401 [==============================] - 0s 116us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7361 - val_acc: 0.4667\n",
      "Epoch 493/500\n",
      "401/401 [==============================] - 0s 121us/step - loss: 0.6707 - acc: 0.6060 - val_loss: 0.7367 - val_acc: 0.4667\n",
      "Epoch 494/500\n",
      "401/401 [==============================] - 0s 111us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7372 - val_acc: 0.4667\n",
      "Epoch 495/500\n",
      "401/401 [==============================] - 0s 111us/step - loss: 0.6708 - acc: 0.6060 - val_loss: 0.7378 - val_acc: 0.4667\n",
      "Epoch 496/500\n",
      "401/401 [==============================] - 0s 123us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7382 - val_acc: 0.4667\n",
      "Epoch 497/500\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7388 - val_acc: 0.4667\n",
      "Epoch 498/500\n",
      "401/401 [==============================] - 0s 144us/step - loss: 0.6709 - acc: 0.6060 - val_loss: 0.7393 - val_acc: 0.4667\n",
      "Epoch 499/500\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.7399 - val_acc: 0.4667\n",
      "Epoch 500/500\n",
      "401/401 [==============================] - 0s 136us/step - loss: 0.6710 - acc: 0.6060 - val_loss: 0.7403 - val_acc: 0.4667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=len(x_train.columns)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5)) # 과적합방지 Dropout. \n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# opt = optimizers.Adam(lr=0.001, beta_1=0.5, beta_2=0.99, epsilon=None, decay=0.0, amsgrad=False)\n",
    "opt = optimizers.Adam(lr=0.0001, decay=0.1, amsgrad=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=500, batch_size=50,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='lower left')\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.3782391 ],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.40945926],\n",
       "       [ 0.37813804],\n",
       "       [ 0.62574017],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37822151],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.42307591],\n",
       "       [ 0.37813804],\n",
       "       [ 0.4017171 ],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.73257327],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.66916215],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.82398671],\n",
       "       [ 0.3787539 ],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.50522703],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.58641541],\n",
       "       [ 0.60635263],\n",
       "       [ 0.37819514],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.3782391 ],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.38084227],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37826508],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37819514],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37803456],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.44394109],\n",
       "       [ 0.48577684],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.45096061],\n",
       "       [ 0.37813804],\n",
       "       [ 0.4017171 ],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.64587879],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.378425  ],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.39119303],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37829944],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.71380794],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.49510083],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.40065801],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37942788],\n",
       "       [ 0.37813804],\n",
       "       [ 0.61164087],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37860113],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.52118099],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.38771752],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37837672],\n",
       "       [ 0.39400855],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.41959891],\n",
       "       [ 0.37819514],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.40443707],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37824088],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.38777265],\n",
       "       [ 0.37813804],\n",
       "       [ 0.47615126],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37829944],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37782845],\n",
       "       [ 0.37813804],\n",
       "       [ 0.3782391 ],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37829944],\n",
       "       [ 0.37822151],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.47750348],\n",
       "       [ 0.37983292],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37831283],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37819514],\n",
       "       [ 0.42675054],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.40499225],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.50648206],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37829828],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.55654901],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.4241682 ],\n",
       "       [ 0.8935318 ],\n",
       "       [ 0.37793452],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37893519],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37824264],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.43503872],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.40638983],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.62814176],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37891698],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.51902992],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.42880639],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37819514],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37813804],\n",
       "       [ 0.37819514],\n",
       "       [ 0.37813804]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 402.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   16.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict_classes(x_test)\n",
    "# live = len([x for x in pred.ravel() if x==1])\n",
    "# death = len([x for x in pred.ravel() if x==0])\n",
    "# print(\"live : \" , live)\n",
    "# print(\"death : \" , death)\n",
    "# print(\"생존율 : \", live / (live + death))\n",
    "# pred\n",
    "\n",
    "plt.hist(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(\"../data/titanic/gender_submission.csv\")\n",
    "df_pred[['Survived']] = pred\n",
    "# df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
